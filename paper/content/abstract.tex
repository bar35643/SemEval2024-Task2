\begin{abstract}
	This paper focuses on the creation and utilization of a specialized dataset 
	for enhancing natural language processing models' comprehension of 
	Clinical Trial Reports (CTR). The resulting dataset, structured as 
	Single-Type and Comparison-Type, serves as the foundation for 
	training and development sets.
	We explored methodologies, utilizing BERT as the base model, 
	and delves into strategies like Sentence Embedding Architectures, 
	Adapter Tuning, and different Loss Functions. It systematically evaluates 
	factors such as learning rates, sentence permutations, 
	and dataset expansion strategies, to generalize a Model, handling,
	like a translation task, several Test Entailment Task at once.


	\keywords{Natural Language Processing (NLP)\and
		Large Language Models (LLMs)  \and
		medical \and
		BERT \and
		Transformer \and
		Machine Learning \and
		Artificial  Intelligence}
\end{abstract}