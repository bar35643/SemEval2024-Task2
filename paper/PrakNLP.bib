
@inproceedings{darji_german_2023,
	title = {German {BERT} {Model} for {Legal} {Named} {Entity} {Recognition}},
	url = {http://arxiv.org/abs/2303.05388},
	doi = {10.5220/0011749400003393},
	abstract = {The use of BERT, one of the most popular language models, has led to improvements in many Natural Language Processing (NLP) tasks. One such task is Named Entity Recognition (NER) i.e. automatic identification of named entities such as location, person, organization, etc. from a given text. It is also an important base step for many NLP tasks such as information extraction and argumentation mining. Even though there is much research done on NER using BERT and other popular language models, the same is not explored in detail when it comes to Legal NLP or Legal Tech. Legal NLP applies various NLP techniques such as sentence similarity or NER specifically on legal data. There are only a handful of models for NER tasks using BERT language models, however, none of these are aimed at legal documents in German. In this paper, we fine-tune a popular BERT language model trained on German data (German BERT) on a Legal Entity Recognition (LER) dataset. To make sure our model is not overfitting, we performed a stratified 10-fold cross-validation. The results we achieve by fine-tuning German BERT on the LER dataset outperform the BiLSTM-CRF+ model used by the authors of the same LER dataset. Finally, we make the model openly available via HuggingFace.},
	language = {en},
	urldate = {2023-10-23},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Agents} and {Artificial} {Intelligence}},
	author = {Darji, Harshil and Mitrović, Jelena and Granitzer, Michael},
	year = {2023},
	note = {arXiv:2303.05388 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	pages = {723--728},
	annote = {Comment: Presented at ICAART 2023},
	file = {Darji et al. - 2023 - German BERT Model for Legal Named Entity Recogniti.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\G8SDE2KI\\Darji et al. - 2023 - German BERT Model for Legal Named Entity Recogniti.pdf:application/pdf},
}

@misc{frei_gernermed_2022,
	title = {{GERNERMED}++: {Transfer} {Learning} in {German} {Medical} {NLP}},
	shorttitle = {{GERNERMED}++},
	url = {http://arxiv.org/abs/2206.14504},
	abstract = {We present a statistical model for German medical natural language processing trained for named entity recognition (NER) as an open, publicly available model. The work serves as a refined successor to our first GERNERMED model which is substantially outperformed by our work. We demonstrate the effectiveness of combining multiple techniques in order to achieve strong results in entity recognition performance by the means of transfer-learning on pretrained deep language models (LM), word-alignment and neural machine translation. Due to the sparse situation on open, public medical entity recognition models for German texts, this work offers benefits to the German research community on medical NLP as a baseline model. Since our model is based on public English data, its weights are provided without legal restrictions on usage and distribution. The sample code and the statistical model is available at: https://github.com/frankkramer-lab/GERNERMED-pp},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Frei, Johann and Frei-Stuber, Ludwig and Kramer, Frank},
	month = oct,
	year = {2022},
	note = {arXiv:2206.14504 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Frei et al. - 2022 - GERNERMED++ Transfer Learning in German Medical N.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\W3YFYHEU\\Frei et al. - 2022 - GERNERMED++ Transfer Learning in German Medical N.pdf:application/pdf},
}

@article{schweter_triple_nodate,
	title = {Triple {E} - {Eﬀective} {Ensembling} of {Embeddings} and {Language} {Models} for {NER} of {Historical} {German}.},
	abstract = {Named entity recognition (NER) for historical texts is a challenging task compared to NER for contemporary texts. Historical texts come with several peculiarities that diﬀer greatly from modern texts and large labeled corpora for training a neural tagger are hardly available. In this work we tackle NER for historical German with an ensembling approach, combining diﬀerent labeled and unlabeled resources of historical and contemporary texts as part of the CLEF HIPE 2020 evaluation lab. We stack diﬀerent word/subword embeddings and transformer-based language models to train a powerful NER tagger for historical German. We conduct experiments with diﬀerent word embeddings, Flair embeddings and pretrained Bert models. The named entities are classiﬁed in literal and in metonymic sense, for which we have developed a separate tagger each. Our experiments show that the usage of Bert is particularly helpful, when trained on a large amount of historical data. Our best ensemble is a combination of FastText embeddings trained on German Wikipedia, Flair embeddings trained on CLEF HIPE data (historical German) and a Bert language model trained on a large corpus of historical German. We release our code and models3.},
	language = {en},
	author = {Schweter, Stefan and Marz, Luisa},
	file = {Schweter und Marz - Triple E - Eﬀective Ensembling of Embeddings and L.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\684HIHKP\\Schweter und Marz - Triple E - Eﬀective Ensembling of Embeddings and L.pdf:application/pdf},
}

@misc{wang_document-level_2023,
	title = {Document-{Level} {Machine} {Translation} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2304.02210},
	abstract = {Large language models (LLMs) such as Chat-GPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks. Taking document-level machine translation (MT) as a testbed, this paper provides an in-depth evaluation of LLMs' ability on discourse modeling. The study fo-cuses on three aspects: 1) Effects of Discourse-Aware Prompts, where we investigate the impact of different prompts on document-level translation quality and discourse phenomena; 2) Comparison of Translation Models, where we compare the translation performance of Chat-GPT with commercial MT systems and advanced document-level MT methods; 3) Analysis of Discourse Modelling Abilities, where we further probe discourse knowledge encoded in LLMs and examine the impact of training techniques on discourse modeling. By evaluating a number of benchmarks, we surprisingly find that 1) leveraging their powerful long-text mod-eling capabilities, ChatGPT outperforms commercial MT systems in terms of human evaluation. 2) GPT-4 demonstrates a strong ability to explain discourse knowledge, even through it may select incorrect translation candidates in contrastive testing. 3) ChatGPT and GPT-4 have demonstrated superior performance and show potential to become a new and promising paradigm for document-level translation. This work highlights the challenges and opportunities of discourse modeling for LLMs, which we hope can inspire the future design and evaluation of LLMs.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Wang, Longyue and Lyu, Chenyang and Ji, Tianbo and Zhang, Zhirui and Yu, Dian and Shi, Shuming and Tu, Zhaopeng},
	month = apr,
	year = {2023},
	note = {arXiv:2304.02210 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Wang et al. - 2023 - Document-Level Machine Translation with Large Lang.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\633JVYIT\\Wang et al. - 2023 - Document-Level Machine Translation with Large Lang.pdf:application/pdf},
}

@article{xiao_example-based_nodate,
	title = {Example-{Based} {Machine} {Translation} with a {Multi}-{Sentence} {Construction} {Transformer} {Architecture}},
	language = {en},
	author = {Xiao, Haozhe and Zhou, Yifei and Lepage, Yves},
	file = {Xiao et al. - Example-Based Machine Translation with a Multi-Sen.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2SAAXFT4\\Xiao et al. - Example-Based Machine Translation with a Multi-Sen.pdf:application/pdf},
}

@misc{artemova_low-resource_2023,
	title = {Low-resource {Bilingual} {Dialect} {Lexicon} {Induction} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2304.09957},
	abstract = {Bilingual word lexicons are crucial tools for multilingual natural language understanding and machine translation tasks, as they facilitate the mapping of words in one language to their synonyms in another language. To achieve this, numerous papers have explored bilingual lexicon induction (BLI) in high-resource scenarios, using a typical pipeline consisting of two unsupervised steps: bitext mining and word alignment, both of which rely on pre-trained large language models (LLMs).},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Artemova, Ekaterina and Plank, Barbara},
	month = apr,
	year = {2023},
	note = {arXiv:2304.09957 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted to NoDaLiDa 2023},
	file = {Artemova und Plank - 2023 - Low-resource Bilingual Dialect Lexicon Induction w.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\P4E5MJL2\\Artemova und Plank - 2023 - Low-resource Bilingual Dialect Lexicon Induction w.pdf:application/pdf},
}

@misc{raunak_leveraging_2023,
	title = {Leveraging {GPT}-4 for {Automatic} {Translation} {Post}-{Editing}},
	url = {http://arxiv.org/abs/2305.14878},
	abstract = {While Neural Machine Translation (NMT) represents the leading approach to Machine Translation (MT), the outputs of NMT models still require translation post-editing to rectify errors and enhance quality, particularly under critical settings. In this work, we formalize the task of translation post-editing with Large Language Models (LLMs) and explore the use of GPT-4 to automatically post-edit NMT outputs across several language pairs. Our results demonstrate that GPT-4 is adept at translation post-editing and produces meaningful edits even when the target language is not English. Notably, we achieve state-of-the-art performance on WMT22 English-Chinese, English-German, ChineseEnglish and German-English language pairs using GPT-4 based post-editing, as evaluated by state-of-the-art MT quality metrics.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Raunak, Vikas and Sharaf, Amr and Awadallah, Hany Hassan and Menezes, Arul},
	month = may,
	year = {2023},
	note = {arXiv:2305.14878 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Raunak et al. - 2023 - Leveraging GPT-4 for Automatic Translation Post-Ed.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\YGZCJ5YA\\Raunak et al. - 2023 - Leveraging GPT-4 for Automatic Translation Post-Ed.pdf:application/pdf},
}

@misc{pluss_sds-200_2022,
	title = {{SDS}-200: {A} {Swiss} {German} {Speech} to {Standard} {German} {Text} {Corpus}},
	shorttitle = {{SDS}-200},
	url = {http://arxiv.org/abs/2205.09501},
	abstract = {We present SDS-200, a corpus of Swiss German dialectal speech with Standard German text translations, annotated with dialect, age, and gender information of the speakers. The dataset allows for training speech translation, dialect recognition, and speech synthesis systems, among others. The data was collected using a web recording tool that is open to the public. Each participant was given a text in Standard German and asked to translate it to their Swiss German dialect before recording it. To increase the corpus quality, recordings were validated by other participants. The data consists of 200 hours of speech by around 4000 different speakers and covers a large part of the Swiss German dialect landscape. We release SDS-200 alongside a baseline speech translation model, which achieves a word error rate (WER) of 30.3 and a BLEU score of 53.1 on the SDS-200 test set. Furthermore, we use SDS-200 to ﬁne-tune a pre-trained XLS-R model, achieving 21.6 WER and 64.0 BLEU.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Plüss, Michel and Hürlimann, Manuela and Cuny, Marc and Stöckli, Alla and Kapotis, Nikolaos and Hartmann, Julia and Ulasik, Malgorzata Anna and Scheller, Christian and Schraner, Yanick and Jain, Amit and Deriu, Jan and Cieliebak, Mark and Vogel, Manfred},
	month = may,
	year = {2022},
	note = {arXiv:2205.09501 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Plüss et al. - 2022 - SDS-200 A Swiss German Speech to Standard German .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\XN3PVEVH\\Plüss et al. - 2022 - SDS-200 A Swiss German Speech to Standard German .pdf:application/pdf},
}

@misc{anschutz_language_2023,
	title = {Language {Models} for {German} {Text} {Simplification}: {Overcoming} {Parallel} {Data} {Scarcity} through {Style}-specific {Pre}-training},
	shorttitle = {Language {Models} for {German} {Text} {Simplification}},
	url = {http://arxiv.org/abs/2305.12908},
	abstract = {Automatic text simpliﬁcation systems help to reduce textual information barriers on the internet. However, for languages other than English, only few parallel data to train these systems exists. We propose a two-step approach to overcome this data scarcity issue. First, we ﬁne-tuned language models on a corpus of German Easy Language, a speciﬁc style of German. Then, we used these models as decoders in a sequence-to-sequence simpliﬁcation task. We show that the language models adapt to the style characteristics of Easy Language and output more accessible texts. Moreover, with the style-speciﬁc pre-training, we reduced the number of trainable parameters in text simpliﬁcation models. Hence, less parallel data is sufﬁcient for training. Our results indicate that pre-training on unaligned data can reduce the required parallel data while improving the performance on downstream tasks.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Anschütz, Miriam and Oehms, Joshua and Wimmer, Thomas and Jezierski, Bartłomiej and Groh, Georg},
	month = may,
	year = {2023},
	note = {arXiv:2305.12908 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted to ACL Findings 2023},
	file = {Anschütz et al. - 2023 - Language Models for German Text Simplification Ov.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\FYHDMXJG\\Anschütz et al. - 2023 - Language Models for German Text Simplification Ov.pdf:application/pdf},
}

@article{frei_annotated_2023,
	title = {Annotated dataset creation through large language models for non-english medical {NLP}},
	volume = {145},
	issn = {15320464},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046423001995},
	doi = {10.1016/j.jbi.2023.104478},
	abstract = {Obtaining text datasets with semantic annotations is an effortful process, yet crucial for supervised training in natural language processing (NLP). In general, developing and applying new NLP pipelines in domainspecific contexts for tasks often requires custom-designed datasets to address NLP tasks in a supervised machine learning fashion. When operating in non-English languages for medical data processing, this exposes several minor and major, interconnected problems such as the lack of task-matching datasets as well as task-specific pre-trained models.},
	language = {en},
	urldate = {2023-10-23},
	journal = {Journal of Biomedical Informatics},
	author = {Frei, Johann and Kramer, Frank},
	month = sep,
	year = {2023},
	pages = {104478},
	file = {Frei und Kramer - 2023 - Annotated dataset creation through large language .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2P8IBYIX\\Frei und Kramer - 2023 - Annotated dataset creation through large language .pdf:application/pdf},
}

@misc{naveed_comprehensive_2023,
	title = {A {Comprehensive} {Overview} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2307.06435},
	abstract = {Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language processing tasks and beyond. This success of LLMs has led to a large influx of research contributions in this direction. These works encompass diverse topics such as architectural innovations of the underlying neural networks, context length improvements, model alignment, training datasets, benchmarking, efficiency and more. With the rapid development of techniques and regular breakthroughs in LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field. This article provides that overview to the research community. It not only focuses on a systematic treatment of the existing literature on a broad range of LLM related concept, but also pays special attention to providing comprehensive summaries with extensive details about the individual existing models, datasets and major insights. We also pay heed to aligning our overview with the emerging outlook of this research direction by accounting for the other recently materializing reviews of the broader research direction of LLMs. Our self-contained comprehensive overview of LLMs discusses relevant background concepts along with covering the advanced topics at the frontier of this research direction. This review article is intended to not only provide a systematic survey, but also a quick comprehensive reference for the researchers and practitioners to draw insights from extensive informative summaries of the existing works to advance the LLM research direction.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
	month = oct,
	year = {2023},
	note = {arXiv:2307.06435 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Work in-progress},
	file = {Naveed et al. - 2023 - A Comprehensive Overview of Large Language Models.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\5IHNB2DA\\Naveed et al. - 2023 - A Comprehensive Overview of Large Language Models.pdf:application/pdf},
}

@inproceedings{ghadekar_comparative_2023,
	address = {Ravet IN, India},
	title = {Comparative {Analysis} of {LSTM}, {GRU} and {Transformer} {Models} for {German} to {English} {Language} {Translation}},
	isbn = {9798350302288},
	url = {https://ieeexplore.ieee.org/document/10270018/},
	doi = {10.1109/ASIANCON58793.2023.10270018},
	abstract = {Natural Language Processing (NLP) encompasses a broad range of techniques and methodologies for processing and understanding human language. One of the most important NLP applications that has experienced significant advancements and has gained immense importance over the years is Neural Machine Translation. Research on German-to-English language machine translation has remained a prominent area of research within the field of Natural Language Processing and Deep. This paper presents an in-depth analysis of three significant models that are used for Neural Machine Translation namely Recurrent Neural Network with Long Short-Term Memory, Recurrent Neural Network with Gated Recurrent Unit, and the Transformer. For the implementation of each model, a large data corpus of 221,534 sentence pairs is used. Two evaluation metrics are employed to assess the performance of models i.e., the BLEU Score and the ROUGE Score. BLEU-4 Score of 0.386, 0.402, and 0.482 is obtained for RNN+LSTM, RNN+GRU, and Transformer model respectively. Precision, Recall, and F1 Score of ROUGE Score are studied which points to similar results as that Learning of the BLEU Score. Both the evaluation metrics suggest that the transformer model outperforms both variants of RNN. The study also paves the way for further investigation in this area by offering important information about how each model is implemented and the outcomes it produces.},
	language = {en},
	urldate = {2023-10-23},
	booktitle = {2023 3rd {Asian} {Conference} on {Innovation} in {Technology} ({ASIANCON})},
	publisher = {IEEE},
	author = {Ghadekar, Premanand and Malwatkar, Neel and Sontakke, Nikhil and Soni, Nirvisha},
	month = aug,
	year = {2023},
	pages = {1--7},
	file = {Ghadekar et al. - 2023 - Comparative Analysis of LSTM, GRU and Transformer .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\J3NR7WAR\\Ghadekar et al. - 2023 - Comparative Analysis of LSTM, GRU and Transformer .pdf:application/pdf},
}

@inproceedings{su_reviewriter_2023,
	address = {Toronto, Canada},
	title = {Reviewriter: {AI}-{Generated} {Instructions} {For} {Peer} {Review} {Writing}},
	shorttitle = {Reviewriter},
	url = {https://aclanthology.org/2023.bea-1.5},
	doi = {10.18653/v1/2023.bea-1.5},
	abstract = {Large Language Models (LLMs) offer novel opportunities for educational applications that have the potential to transform traditional learning for students. Despite AI-enhanced applications having the potential to provide personalized learning experiences, more studies are needed on the design of generative AI systems and evidence for using them in real educational settings. In this paper, we design, implement and evaluate Reviewriter, a novel tool to provide students with AI-generated instructions for writing peer reviews in German. Our study identifies three key aspects: a) we provide insights into student needs when writing peer reviews with generative models which we then use to develop a novel system to provide adaptive instructions b) we fine-tune three German language models on a selected corpus of 11,925 student-written peer review texts in German and choose German-GPT2 based on quantitative measures and human evaluation, and c) we evaluate our tool with fourteen students, revealing positive technology acceptance based on quantitative measures. Additionally, the qualitative feedback presents the benefits and limitations of generative AI in peer review writing.},
	language = {en},
	urldate = {2023-10-23},
	booktitle = {Proceedings of the 18th {Workshop} on {Innovative} {Use} of {NLP} for {Building} {Educational} {Applications} ({BEA} 2023)},
	publisher = {Association for Computational Linguistics},
	author = {Su, Xiaotian and Wambsganss, Thiemo and Rietsche, Roman and Neshaei, Seyed Parsa and Kser, Tanja},
	year = {2023},
	pages = {57--71},
	file = {Su et al. - 2023 - Reviewriter AI-Generated Instructions For Peer Re.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\M4MHI2B2\\Su et al. - 2023 - Reviewriter AI-Generated Instructions For Peer Re.pdf:application/pdf},
}

@article{kammer_resolving_nodate,
	title = {Resolving {Elliptical} {Compounds} in {German} {Medical} {Text}},
	abstract = {Elliptical coordinated compound noun phrases (ECCNPs), a special kind of coordination ellipsis, are a common phenomenon in German medical texts. As their presence is known to affect the performance in downstream tasks such as entity extraction and disambiguation, their resolution can be a useful preprocessing step in information extraction pipelines. In this work, we present a new comprehensive dataset of more than 4,000 manually annotated ECCNPs in German medical text, along with the respective ground truth resolutions. Based on this data, we propose a generative encoder–decoder Transformer model, allowing for a simple end-to-end resolution of ECCNPs from raw input strings with very high accuracy (90.5 \% exact match score). We compare our approach to an elaborate rule-based baseline, which the generative model outperforms by a large margin. We further investigate different scenarios for prompting large language models (LLM) to resolve ECCNPs. In a zeroshot setting, performance is remarkably poor (21.6 \% exact matches), as the LLM tends to apply complex changes to the inputs unrelated to our specific task. We also find no improvement over the generative model when using the LLM for post-filtering of generated candidate resolutions. The source code including instructions on how to access the data are available at: https://github.com/hpi-dhc/ggponc\_ ellipses.},
	language = {en},
	author = {Kämmer, Niklas and Borchert, Florian and Winkler, Silvia and de Melo, Gerard and Schapranow, Matthieu-P},
	file = {Kämmer et al. - Resolving Elliptical Compounds in German Medical T.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\E8YU63IP\\Kämmer et al. - Resolving Elliptical Compounds in German Medical T.pdf:application/pdf},
}

@article{gritsay_automated_nodate,
	title = {Automated {Text} {Identification}: {Multilingual} {Transformer}-based {Models} {Approach}},
	abstract = {This paper describes our solution approach for the AuTexTification (Automated Text Identification) competition held as part of the IberLEF 2023 conference. Generated text is an increasing problem nowadays. Due to the spread of large volumes of generated texts across the Internet, people are often confused by this kind of content. In this article, we present a model for machine generated text detection based on different BERT-like encoder models. To achieve better results, we applied a fine-tuning approach of large pre-trained language encoder models XLM-RoBERTa, mDeBERTa and MiniLM-V2. In order to improve the quality of the detectors, we performed extensive preprocessing and expansion of the training data, preserving the structural properties. The method described in the paper helped our team to achieve about 66\% for the English binary dataset in the final competition result.},
	language = {en},
	author = {Gritsay, German and Grabovoy, Andrey and Kildyakov, Aleksandr and Chekhovich, Yury},
	file = {Gritsay et al. - Automated Text Identification Multilingual Transf.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4FIJWD9M\\Gritsay et al. - Automated Text Identification Multilingual Transf.pdf:application/pdf},
}

@misc{reinig_can_2023,
	title = {Can current {NLI} systems handle {German} word order? {Investigating} language model performance on a new {German} challenge set of minimal pairs},
	shorttitle = {Can current {NLI} systems handle {German} word order?},
	url = {http://arxiv.org/abs/2306.04523},
	abstract = {Compared to English, German word order is freer and therefore poses additional challenges for natural language inference (NLI). We create WOGLI (Word Order in German Language Inference), the ﬁrst adversarial NLI dataset for German word order that has the following properties: (i) each premise has an entailed and a non-entailed hypothesis; (ii) premise and hypotheses differ only in word order and necessary morphological changes to mark case and number. In particular, each premise and its two hypotheses contain exactly the same lemmata. Our adversarial examples require the model to use morphological markers in order to recognise or reject entailment. We show that current German autoencoding models ﬁnetuned on translated NLI data can struggle on this challenge set, reﬂecting the fact that translated NLI datasets will not mirror all necessary language phenomena in the target language. We also examine performance after data augmentation as well as on related word order phenomena derived from WOGLI. Our datasets are publically available at https://github. com/ireinig/wogli.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Reinig, Ines and Markert, Katja},
	month = jun,
	year = {2023},
	note = {arXiv:2306.04523 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Reinig und Markert - 2023 - Can current NLI systems handle German word order .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\GMPBXUUQ\\Reinig und Markert - 2023 - Can current NLI systems handle German word order .pdf:application/pdf},
}

@article{mysiak_is_nodate,
	title = {Is {German} secretly a {Slavic} language? {What} {BERT} probing can tell us about language groups},
	abstract = {In the light of recent developments in NLP, the problem of understanding and interpreting large language models has gained a lot of urgency. Methods developed to study this area are subject to considerable scrutiny. In this work, we take a closer look at one such method, the structural probe introduced by Hewitt and Manning (2019). We run a series of experiments involving multiple languages, focusing principally on the group of Slavic languages. We show that probing results can be seen as a reflection of linguistic classification, and conclude that multilingual BERT learns facts about languages and their groups.},
	language = {en},
	author = {Mysiak, Aleksandra and Cyranka, Jacek},
	file = {Mysiak und Cyranka - Is German secretly a Slavic language What BERT pr.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\LU3NHVZ5\\Mysiak und Cyranka - Is German secretly a Slavic language What BERT pr.pdf:application/pdf},
}

@inproceedings{li_hw-tsc_2023,
	address = {Toronto, Canada (in-person and online)},
	title = {{HW}-{TSC} at {IWSLT2023}: {Break} the {Quality} {Ceiling} of {Offline} {Track} via {Pre}-{Training} and {Domain} {Adaptation}},
	shorttitle = {{HW}-{TSC} at {IWSLT2023}},
	url = {https://aclanthology.org/2023.iwslt-1.14},
	doi = {10.18653/v1/2023.iwslt-1.14},
	abstract = {This paper describes HW-TSC’s submissions to the IWSLT 2023 Offline Speech Translation task, including speech translation of talks from English to German, English to Chinese and English to Japanese. We participated in all three tracks (Constrained training, Constrained with Large Language Models training, Unconstrained training), with using cascaded architectures models. We use data enhancement, pretraining models and other means to improve the quality of ASR, and use a variety of techniques including R-Drop, deep model, domain data selection, etc. to improve the quality of NMT. Compared with last year’s best results, we have improved by 2.1 BLEU in the MuST-C English-German test set.},
	language = {en},
	urldate = {2023-10-23},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Spoken} {Language} {Translation} ({IWSLT} 2023)},
	publisher = {Association for Computational Linguistics},
	author = {Li, Zongyao and Wu, Zhanglin and Rao, Zhiqiang and YuHao, Xie and JiaXin, Guo and Wei, Daimeng and Shang, Hengchao and Minghan, Wang and Chen, Xiaoyu and Yu, Zhengzhe and ShaoJun, Li and LiZhi, Lei and Yang, Hao},
	year = {2023},
	pages = {187--193},
	file = {Li et al. - 2023 - HW-TSC at IWSLT2023 Break the Quality Ceiling of .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\6XF9DYQX\\Li et al. - 2023 - HW-TSC at IWSLT2023 Break the Quality Ceiling of .pdf:application/pdf},
}

@article{liu_summary_2023,
	title = {Summary of {ChatGPT}-{Related} {Research} and {Perspective} {Towards} the {Future} of {Large} {Language} {Models}},
	volume = {1},
	issn = {29501628},
	url = {http://arxiv.org/abs/2304.01852},
	doi = {10.1016/j.metrad.2023.100017},
	abstract = {This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and GPT-4) research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs’ adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT’s capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.},
	language = {en},
	number = {2},
	urldate = {2023-10-23},
	journal = {Meta-Radiology},
	author = {Liu, Yiheng and Han, Tianle and Ma, Siyuan and Zhang, Jiayue and Yang, Yuanyuan and Tian, Jiaming and He, Hao and Li, Antong and He, Mengshen and Liu, Zhengliang and Wu, Zihao and Zhao, Lin and Zhu, Dajiang and Li, Xiang and Qiang, Ning and Shen, Dingang and Liu, Tianming and Ge, Bao},
	month = sep,
	year = {2023},
	note = {arXiv:2304.01852 [cs]},
	keywords = {Computer Science - Computation and Language},
	pages = {100017},
	annote = {Comment: 21 pages, 4 figures, accepted by Meta-Radiology},
	file = {Liu et al. - 2023 - Summary of ChatGPT-Related Research and Perspectiv.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\EMH8FHEU\\Liu et al. - 2023 - Summary of ChatGPT-Related Research and Perspectiv.pdf:application/pdf},
}

@misc{lai_chatgpt_2023,
	title = {{ChatGPT} {Beyond} {English}: {Towards} a {Comprehensive} {Evaluation} of {Large} {Language} {Models} in {Multilingual} {Learning}},
	shorttitle = {{ChatGPT} {Beyond} {English}},
	url = {http://arxiv.org/abs/2304.05613},
	abstract = {Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field. ChatGPT represents one of the most exciting LLM systems developed recently to showcase impressive skills for language generation and highly attract public attention. Among various exciting applications discovered for ChatGPT in English, the model can process and generate texts for multiple languages due to its multilingual training data. Given the broad adoption of ChatGPT for English in different problems and areas, a natural question is whether ChatGPT can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. The answer to this question requires a thorough evaluation of ChatGPT over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current research. Our work aims to fill this gap for the evaluation of ChatGPT and similar LLMs to provide more comprehensive information for multilingual NLP applications. While this work will be an ongoing effort to include additional experiments in the future, our current paper evaluates ChatGPT on 7 different tasks, covering 37 diverse languages with high, medium, low, and extremely low resources. We also focus on the zero-shot learning setting for ChatGPT to improve reproducibility and better simulate the interactions of general users. Compared to the performance of previous models, our extensive experimental results demonstrate a worse performance of ChatGPT for different NLP tasks and languages, calling for further research to develop better models and understanding for multilingual learning.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Lai, Viet Dac and Ngo, Nghia Trung and Veyseh, Amir Pouran Ben and Man, Hieu and Dernoncourt, Franck and Bui, Trung and Nguyen, Thien Huu},
	month = apr,
	year = {2023},
	note = {arXiv:2304.05613 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Lai et al. - 2023 - ChatGPT Beyond English Towards a Comprehensive Ev.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\YI7FARVL\\Lai et al. - 2023 - ChatGPT Beyond English Towards a Comprehensive Ev.pdf:application/pdf},
}

@misc{shi_language_2022,
	title = {Language {Models} are {Multilingual} {Chain}-of-{Thought} {Reasoners}},
	url = {http://arxiv.org/abs/2210.03057},
	abstract = {We evaluate the reasoning abilities of large language models in multilingual settings. We introduce the Multilingual Grade School Math (MGSM) benchmark, by manually translating 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) into ten typologically diverse languages. We ﬁnd that the ability to solve MGSM problems via chain-of-thought prompting emerges with increasing model scale, and that models have strikingly strong multilingual reasoning abilities, even in underrepresented languages such as Bengali and Swahili. Finally, we show that the multilingual reasoning abilities of language models extend to other tasks such as commonsense reasoning and wordin-context semantic judgment. The MGSM benchmark is publicly available at https://github.com/google-research/url-nlp.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Shi, Freda and Suzgun, Mirac and Freitag, Markus and Wang, Xuezhi and Srivats, Suraj and Vosoughi, Soroush and Chung, Hyung Won and Tay, Yi and Ruder, Sebastian and Zhou, Denny and Das, Dipanjan and Wei, Jason},
	month = oct,
	year = {2022},
	note = {arXiv:2210.03057 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Shi et al. - 2022 - Language Models are Multilingual Chain-of-Thought .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\TYV57DY7\\Shi et al. - 2022 - Language Models are Multilingual Chain-of-Thought .pdf:application/pdf},
}

@misc{scheible_gottbert_2020,
	title = {{GottBERT}: a pure {German} {Language} {Model}},
	shorttitle = {{GottBERT}},
	url = {http://arxiv.org/abs/2012.02110},
	abstract = {Lately, pre-trained language models advanced the ﬁeld of natural language processing (NLP). The introduction of Bidirectional Encoders for Transformers (BERT) and its optimized version RoBERTa have had signiﬁcant impact and increased the relevance of pre-trained models. First, research in this ﬁeld mainly started on English data followed by models trained with multilingual text corpora. However, current research shows that multilingual models are inferior to monolingual models. Currently, no German single language RoBERTa model is yet published, which we introduce in this work (GottBERT). The German portion of the OSCAR data set was used as text corpus. In an evaluation we compare its performance on the two Named Entity Recognition (NER) tasks Conll 2003 and GermEval 2014 as well as on the text classiﬁcation tasks GermEval 2018 (ﬁne and coarse) and GNAD with existing German single language BERT models and two multilingual ones. GottBERT was pre-trained related to the original RoBERTa model using fairseq. All downstream tasks were trained using hyperparameter presets taken from the benchmark of German BERT. The experiments were setup utilizing FARM. Performance was measured by the F1 score. GottBERT was successfully pre-trained on a 256 core TPU pod using the RoBERTa BASE architecture. Even without extensive hyperparameter optimization, in all NER and one text classiﬁcation task, GottBERT already outperformed all other tested German and multilingual models. In order to support the German NLP ﬁeld, we publish GottBERT under the AGPLv3 license.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Scheible, Raphael and Thomczyk, Fabian and Tippmann, Patric and Jaravine, Victor and Boeker, Martin},
	month = dec,
	year = {2020},
	note = {arXiv:2012.02110 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Scheible et al. - 2020 - GottBERT a pure German Language Model.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\P4ZUG53E\\Scheible et al. - 2020 - GottBERT a pure German Language Model.pdf:application/pdf},
}

@misc{kucharavy_fundamentals_2023,
	title = {Fundamentals of {Generative} {Large} {Language} {Models} and {Perspectives} in {Cyber}-{Defense}},
	url = {http://arxiv.org/abs/2303.12132},
	abstract = {Generative Language Models gained signiﬁcant attention in late 2022 / early 2023, notably with the introduction of models reﬁned to act consistently with users’ expectations of interactions with AI (conversational models). Arguably the focal point of public attention has been such a reﬁnement of the GPT3 model - the ChatGPT and its subsequent integration with auxiliary capabilities, including search as part of Microsoft Bing. Despite extensive prior research invested in their development, their performance and applicability to a range of daily tasks remained unclear and niche. However, their wider utilization without a requirement for technical expertise, made in large part possible through conversational ﬁne-tuning, revealed the extent of their true capabilities in a real-world environment. This has garnered both public excitement for their potential applications and concerns about their capabilities and potential malicious uses. This review aims to provide a brief overview of the history, state of the art, and implications of Generative Language Models in terms of their principles, abilities, limitations, and future prospects – especially in the context of cyber-defense, with a focus on the Swiss operational environment.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Kucharavy, Andrei and Schillaci, Zachary and Maréchal, Loïc and Würsch, Maxime and Dolamic, Ljiljana and Sabonnadiere, Remi and David, Dimitri Percia and Mermoud, Alain and Lenders, Vincent},
	month = mar,
	year = {2023},
	note = {arXiv:2303.12132 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Cryptography and Security, I.2.1, I.2.7, J.7, K.4.2, K.6.5},
	annote = {Comment: 41 pages (without references), 13 figures; public report of Cyber-Defence Campus},
	file = {Kucharavy et al. - 2023 - Fundamentals of Generative Large Language Models a.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\9H3MUCJ2\\Kucharavy et al. - 2023 - Fundamentals of Generative Large Language Models a.pdf:application/pdf},
}

@misc{zhang_prompting_2023,
	title = {Prompting {Large} {Language} {Model} for {Machine} {Translation}: {A} {Case} {Study}},
	shorttitle = {Prompting {Large} {Language} {Model} for {Machine} {Translation}},
	url = {http://arxiv.org/abs/2301.07069},
	abstract = {Research on prompting has shown excellent performance with little or even no supervised training across many tasks. However, prompting for machine translation is still underexplored in the literature. We ﬁll this gap by offering a systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection. We further explore the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-todocument transfer learning in prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the testbed show that 1) the number and the quality of prompt examples matter, where using suboptimal examples degenerates translation; 2) several features of prompt examples, such as semantic similarity, show signiﬁcant Spearman correlation with their prompting performance; yet, none of the correlations are strong enough; 3) using pseudo parallel prompt examples constructed from monolingual data via zero-shot prompting could improve translation; and 4) improved performance is achievable by transferring knowledge from prompt examples selected in other settings. We ﬁnally provide an analysis on the model outputs and discuss several problems that prompting still suffers from.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Zhang, Biao and Haddow, Barry and Birch, Alexandra},
	month = jan,
	year = {2023},
	note = {arXiv:2301.07069 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Work in progress},
	file = {Zhang et al. - 2023 - Prompting Large Language Model for Machine Transla.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\XQV6K562\\Zhang et al. - 2023 - Prompting Large Language Model for Machine Transla.pdf:application/pdf},
}

@misc{kocmi_large_2023,
	title = {Large {Language} {Models} {Are} {State}-of-the-{Art} {Evaluators} of {Translation} {Quality}},
	url = {http://arxiv.org/abs/2302.14520},
	abstract = {We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate nine versions of GPT models, including ChatGPT and GPT-4. We show that our method for translation quality assessment only works with GPT{\textasciitilde}3.5 and larger models. Comparing to results from WMT22's Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Kocmi, Tom and Federmann, Christian},
	month = may,
	year = {2023},
	note = {arXiv:2302.14520 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted in EAMT, 10 pages, 8 tables, one figure},
	file = {Kocmi und Federmann - 2023 - Large Language Models Are State-of-the-Art Evaluat.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\8PJEZQZA\\Kocmi und Federmann - 2023 - Large Language Models Are State-of-the-Art Evaluat.pdf:application/pdf},
}

@misc{rosin_temporal_2022,
	title = {Temporal {Attention} for {Language} {Models}},
	url = {http://arxiv.org/abs/2202.02093},
	abstract = {Pretrained language models based on the transformer architecture have shown great success in NLP. Textual training data often comes from the web and is thus tagged with time-speciﬁc information, but most language models ignore this information. They are trained on the textual data alone, limiting their ability to generalize temporally. In this work, we extend the key component of the transformer architecture, i.e., the self-attention mechanism, and propose temporal attention—a time-aware selfattention mechanism. Temporal attention can be applied to any transformer model and requires the input texts to be accompanied with their relevant time points. It allows the transformer to capture this temporal information and create time-speciﬁc contextualized word representations. We leverage these representations for the task of semantic change detection; we apply our proposed mechanism to BERT and experiment on three datasets in different languages (English, German, and Latin) that also vary in time, size, and genre. Our proposed model achieves state-of-the-art results on all the datasets.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Rosin, Guy D. and Radinsky, Kira},
	month = may,
	year = {2022},
	note = {arXiv:2202.02093 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Findings of NAACL 2022. 9 pages},
	file = {Rosin und Radinsky - 2022 - Temporal Attention for Language Models.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\WNXKJU8Z\\Rosin und Radinsky - 2022 - Temporal Attention for Language Models.pdf:application/pdf},
}

@article{liang_cross-domain_nodate,
	title = {Cross-domain {German} {Medical} {Named} {Entity} {Recognition} using a {Pre}-{Trained} {Language} {Model} and {Unified} {Medical} {Semantic} {Types}},
	abstract = {Information extraction from clinical text has the potential to facilitate clinical research and personalized clinical care, but annotating large amounts of data for each set of target tasks is prohibitive. We present a German medical Named Entity Recognition (NER) system capable of cross-domain knowledge transferring. The system builds on a pre-trained German language model and a token-level binary classifier, employing semantic types sourced from the Unified Medical Language System (UMLS) as entity labels to identify corresponding entity spans within the input text. To enhance the system’s performance and robustness, we pretrain it using a medical literature corpus that incorporates UMLS semantic term annotations. We evaluate the system’s effectiveness on two German annotated datasets obtained from different clinics in zero- and few-shot settings. The results show that our approach outperforms task-specific Condition Random Fields (CRF) classifiers in terms of accuracy. Our work contributes to developing robust and transparent German medical NER models that can support the extraction of information from various clinical texts.},
	language = {en},
	author = {Liang, Siting and Hartmann, Mareike and Sonntag, Daniel},
	file = {Liang et al. - Cross-domain German Medical Named Entity Recogniti.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\TZT72DKJ\\Liang et al. - Cross-domain German Medical Named Entity Recogniti.pdf:application/pdf},
}

@article{wertz_adapting_nodate,
	title = {Adapting {Transformer} {Language} {Models} for {Application} in {Computational} {Creativity}: {Generating} {German} {Theater} {Plays} with {Varied} {Topics}},
	abstract = {Pre-trained transformer language models have been shown to generate human-like quality texts of different styles. In this study, we generate short drama dialogues in the style of German theater plays and adapt their content to various different topics using a simple fine-tuning scheme. We show that the generations keep the dramatic play structure while adapting large parts of their content to a target topic, effectively creating scenes from theater plays about a variety of subjects. We experiment with hyperparameters to find fitting fine-tuning configurations for various topic datasets as well as highlight how the generations adapt to the topics in a qualitative analysis. Our findings present a useful tool for computer assisted or fully autonomous creative writing. Furthermore, we motivate and explore the use of transformer language models in the context of computational creativity, highlighting the need for constrained and controlled language generation.},
	language = {en},
	author = {Wertz, Lukas and Kuhn, Jonas},
	file = {Wertz und Kuhn - Adapting Transformer Language Models for Applicati.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\ULLVMQ4J\\Wertz und Kuhn - Adapting Transformer Language Models for Applicati.pdf:application/pdf},
}

@article{zarries_this_nodate,
	title = {This isn’t the bias you’re looking for: {Implicit} causality, names and gender in {German} language models},
	abstract = {To assess whether neural language models capture discourse-level linguistic knowledge, previous work has tested whether they exhibit the well-known implicit causality (IC) bias found in various interpersonal verbs in different languages. Stimuli for analyzing IC in computational and psycholinguistic experiments typically exhibit verb arguments with different genders. In this paper, we revisit IC in German neural language models, analyzing gender and naming bias as a potential source of confusion. Indeed, our results suggest that IC biases in two existing models for German are weak, unstable, and behave in unexpected and unsystematic ways, when varying names or gender of verb arguments.},
	language = {en},
	author = {Zarrieß, Sina and Groner, Hannes and Solstad, Torgrim and Bott, Oliver},
	file = {Zarrieß et al. - This isn’t the bias you’re looking for Implicit c.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\AYR86EZC\\Zarrieß et al. - This isn’t the bias you’re looking for Implicit c.pdf:application/pdf},
}

@article{manjavacas_adapting_2022,
	title = {Adapting vs. {Pre}-training {Language} {Models} for {Historical} {Languages}},
	volume = {NLP4DH},
	issn = {2416-5999},
	url = {https://jdmdh.episciences.org/9152},
	doi = {10.46298/jdmdh.9152},
	abstract = {As large language models such as BERT are becoming increasingly popular in Digital Humanities (DH), the question has arisen as to how such models can be made suitable for application to specific textual domains, including that of ‘historical text’. Large language models like BERT can be pre-trained from scratch on a specific textual domain and achieve strong performance on a series of downstream tasks. However, this is a costly endeavour, both in terms of the computational resources as well as the substantial amounts of training data it requires. An appealing alternative, then, is to employ existing ‘general purpose’ models (pre-trained on present-day language) and subsequently adapt them to a specific domain by further pre-training. Focusing on the domain of historical text in English, this paper demonstrates that pre-training on domain-specific (i.e. historical) data from scratch yields a generally stronger background model than adapting a present-day language model. We show this on the basis of a variety of downstream tasks, ranging from established tasks such as Part-of-Speech Tagging, Named Entity Recognition and Word Sense Disambiguation, to ad-hoc tasks like Sentence Periodization, which are specifically designed to test historically relevant text processing.},
	language = {en},
	number = {Digital humanities in...},
	urldate = {2023-10-23},
	journal = {Journal of Data Mining \& Digital Humanities},
	author = {Manjavacas, Enrique and Fonteyn, Lauren},
	month = jun,
	year = {2022},
	pages = {9152},
	file = {Manjavacas und Fonteyn - 2022 - Adapting vs. Pre-training Language Models for Hist.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\PLAEVLCY\\Manjavacas und Fonteyn - 2022 - Adapting vs. Pre-training Language Models for Hist.pdf:application/pdf},
}

@misc{sainz_gollie_2023,
	title = {{GoLLIE}: {Annotation} {Guidelines} improve {Zero}-{Shot} {Information}-{Extraction}},
	shorttitle = {{GoLLIE}},
	url = {http://arxiv.org/abs/2310.03668},
	abstract = {Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines which describe the task and give examples to humans. Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out-of-the-box. In this paper we propose GoLLIE (Guidelinefollowing Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines is key for good results. Code, data and models are publicly available: https://github.com/hitz-zentroa/GoLLIE.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Sainz, Oscar and García-Ferrero, Iker and Agerri, Rodrigo and de Lacalle, Oier Lopez and Rigau, German and Agirre, Eneko},
	month = oct,
	year = {2023},
	note = {arXiv:2310.03668 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Sainz et al. - 2023 - GoLLIE Annotation Guidelines improve Zero-Shot In.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2BPXCFW6\\Sainz et al. - 2023 - GoLLIE Annotation Guidelines improve Zero-Shot In.pdf:application/pdf},
}

@article{liessmann_predicting_nodate,
	title = {Predicting {Customer} {Satisfaction} in {Service} {Processes} {Using} {Multilingual} {Large} {Language} {Models}},
	abstract = {The huge amount of data recorded during business process executions in today’s organizations creates the need to leverage this data. While most existing business process monitoring methods are capable of including structured context information, the incorporation of unstructured information, for example, text, has rarely been researched. Recent advances in natural language processing offer tools to generate contextualized sentence embeddings, which capture more information in human language than ever before. Especially in service processes, such as the incident management process, a variety of unstructured information is created throughout the execution, representing a relevant use case for incorporating (multilingual) text. To close this research gap, a method exploiting multilingual text for predicting the outcome of a service process is presented. Multilingual large language models are used to generate sentence embeddings for unstructured text created during process execution. After instantiating the method, an evaluation was performed using a real-life event log to predict customer satisfaction in the incident management process at a German multinational corporation. We show that text incorporation improves predictive performance.},
	language = {en},
	author = {Liessmann, Annina and Erlangen-Nurnberg, FAU and Sukhareva, Maria},
	file = {Liessmann et al. - Predicting Customer Satisfaction in Service Proces.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2Y8PZMZN\\Liessmann et al. - Predicting Customer Satisfaction in Service Proces.pdf:application/pdf},
}

@article{leboukh_balancing_2023,
	title = {Balancing {ChatGPT} and {Data} {Protection} in {Germany}: {Challenges} and {Opportunities} for {Policy} {Makers}},
	volume = {2},
	copyright = {Copyright (c) 2023 Fouad Leboukh, Emmanuel Baba Aduku, Omar Ali},
	issn = {2944-9243},
	shorttitle = {Balancing {ChatGPT} and {Data} {Protection} in {Germany}},
	url = {https://ejournals.epublishing.ekt.gr/index.php/jpentai/article/view/35166},
	doi = {10.12681/jpentai.35166},
	abstract = {In the last few months there has been widespread discussion about the remarkable progress made in the field of artificial intelligence, specifically large language models such as "ChatGPT". The ethical implications of AI, particularly concerning data protection, have sparked discussions on the necessity of robust regulations. This article examines the intersection of data protection, ChatGPT, and the ethics of AI, it explores Germany's ongoing efforts to strike a balance between harnessing the potential of large language models as ChatGPT and ensuring responsible and transparent use of AI technology in the policy-making realm. The GDPR serves as a guiding framework, necessitating careful consideration of privacy rights and secure handling of personal data when deploying ChatGPT in Germany's policy-making processes. The study draws on analysis on the current laws and regulations of data protection in Germany while studying Germany's commitment to safeguarding personal information through the active presence of The German Federal Commissioner for Data Protection and Freedom of Information. The first section provides a context and presents the policy problem. The second section looks at the available policy options on the role of policymaking in establishing comprehensive regulations regarding the use of ChatGPT and generative AI. The third section provides recommendations on how Germany can ensure the responsible management of ChatGPT, through strengthening data protection laws and regulations, simultaneously, restricting ChatGPT usage to private users and government, also, embracing appropriate usage of generative AI while developing ethical guidelines and best practices to harness its benefits, fostering innovation and advancement.},
	language = {en},
	number = {1},
	urldate = {2023-10-23},
	journal = {Journal of Politics and Ethics in New Technologies and AI},
	author = {Leboukh, Fouad and Aduku, Emmanuel Baba and Ali, Omar},
	month = aug,
	year = {2023},
	note = {Number: 1},
	keywords = {Artificial Intelligence, ChatGPT, Data Protection, Ethics of AI, GDPR, Germany, Policy Making, Privacy, Regulations},
	pages = {e35166--e35166},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\8HUM8S8Q\\Leboukh et al. - 2023 - Balancing ChatGPT and Data Protection in Germany .pdf:application/pdf},
}

@inproceedings{bimagambetova_evaluating_2023,
	address = {Novosibirsk, Moscow, Russian Federation},
	title = {Evaluating {Large} {Language} {Models} for {Sentence} {Augmentation} in {Low}-{Resource} {Languages}: {A} {Case} {Study} on {Kazakh}},
	isbn = {9798350331134},
	shorttitle = {Evaluating {Large} {Language} {Models} for {Sentence} {Augmentation} in {Low}-{Resource} {Languages}},
	url = {https://ieeexplore.ieee.org/document/10275753/},
	doi = {10.1109/OPCS59592.2023.10275753},
	abstract = {Large language models (LLMs) have revolutionized natural language processing (NLP) and demonstrated exceptional performance in various NLP tasks for widely spoken languages. However, their efficacy in handling low-resource languages remains an area of concern. This study investigates the performance of LLMs, particularly GPT-3, in sentence augmentation tasks for a low-resource language, Kazakh. We employ a blind peer review methodology, where five native Kazakh annotators assess the quality of LLM-generated augmentations. The results reveal that LLMs excel in popular languages like English, Chinese, and German, but face challenges with low-resource languages due to limited training data. This work sheds light on the importance of improving LLMs’ adaptability and relevance to address the unique needs of low-resource languages. Further research could enhance the augmentation capabilities of LLMs in scenarios with limited data sources, ensuring their effectiveness in promoting linguistic diversity and inclusivity. Furthermore, this study underscores the significance of cross-language transfer learning and data collection efforts to empower LLMs in supporting linguistic diversity and fostering inclusivity across the global language landscape.},
	language = {en},
	urldate = {2023-10-23},
	booktitle = {2023 19th {International} {Asian} {School}-{Seminar} on {Optimization} {Problems} of {Complex} {Systems} ({OPCS})},
	publisher = {IEEE},
	author = {Bimagambetova, Zhamilya and Rakhymzhanov, Dauren and Jaxylykova, Assel and Pak, Alexander},
	month = aug,
	year = {2023},
	pages = {14--18},
	file = {Bimagambetova et al. - 2023 - Evaluating Large Language Models for Sentence Augm.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\WFPLWNY9\\Bimagambetova et al. - 2023 - Evaluating Large Language Models for Sentence Augm.pdf:application/pdf},
}

@misc{plaza-del-arco_leveraging_2023,
	title = {Leveraging {Label} {Variation} in {Large} {Language} {Models} for {Zero}-{Shot} {Text} {Classification}},
	url = {http://arxiv.org/abs/2307.12973},
	abstract = {The zero-shot learning capabilities of large language models (LLMs) make them ideal for text classification without annotation or supervised training. Many studies have shown impressive results across multiple tasks. While tasks, data, and results differ widely, their similarities to human annotation can aid us in tackling new tasks with minimal expenses. We evaluate using 5 state-of-the-art LLMs as “annotators” on 5 different tasks (age, gender, topic, sentiment prediction, and hate speech detection), across 4 languages: English, French, German, and Spanish. No single model excels at all tasks, across languages, or across all labels within a task. However, aggregation techniques designed for human annotators perform substantially better than any one individual model. Overall, though, LLMs do not rival even simple supervised models, so they do not (yet) replace the need for human annotation. We also discuss the tradeoffs between speed, accuracy, cost, and bias when it comes to aggregated model labeling versus human annotation.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Plaza-del-Arco, Flor Miriam and Nozza, Debora and Hovy, Dirk},
	month = jul,
	year = {2023},
	note = {arXiv:2307.12973 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Plaza-del-Arco et al. - 2023 - Leveraging Label Variation in Large Language Model.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\DQLZ75DS\\Plaza-del-Arco et al. - 2023 - Leveraging Label Variation in Large Language Model.pdf:application/pdf},
}

@misc{urchs_how_2023,
	title = {How {Prevalent} is {Gender} {Bias} in {ChatGPT}? -- {Exploring} {German} and {English} {ChatGPT} {Responses}},
	shorttitle = {How {Prevalent} is {Gender} {Bias} in {ChatGPT}?},
	url = {http://arxiv.org/abs/2310.03031},
	abstract = {With the introduction of ChatGPT, OpenAI made large language models (LLM) accessible to users with limited IT expertise. However, users with no background in natural language processing (NLP) might lack a proper understanding of LLMs. Thus the awareness of their inherent limitations, and therefore will take the systems’ output at face value. In this paper, we systematically analyse prompts and the generated responses to identify possible problematic issues with a special focus on gender biases, which users need to be aware of when processing the system’s output. We explore how ChatGPT reacts in English and German if prompted to answer from a female, male, or neutral perspective. In an in-depth investigation, we examine selected prompts and analyse to what extent responses differ if the system is prompted several times in an identical way. On this basis, we show that ChatGPT is indeed useful for helping non-IT users draft texts for their daily work. However, it is absolutely crucial to thoroughly check the system’s responses for biases as well as for syntactic and grammatical mistakes.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Urchs, Stefanie and Thurner, Veronika and Aßenmacher, Matthias and Heumann, Christian and Thiemichen, Stephanie},
	month = sep,
	year = {2023},
	note = {arXiv:2310.03031 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	annote = {Comment: Accepted @ "1st Workshop on Biased Data in Conversational Agents" (co-located with ECML PKDD 2023). This is the author's version of the work. The definite version of record will be published in the proceedings},
	file = {Urchs et al. - 2023 - How Prevalent is Gender Bias in ChatGPT -- Explor.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\UQLWDD9R\\Urchs et al. - 2023 - How Prevalent is Gender Bias in ChatGPT -- Explor.pdf:application/pdf},
}

@inproceedings{bear_fine-tuning_2023,
	address = {Toronto, Canada},
	title = {Fine-tuning {Sentence}-{RoBERTa} to {Construct} {Word} {Embeddings} for {Low}-resource {Languages} from {Bilingual} {Dictionaries}},
	url = {https://aclanthology.org/2023.americasnlp-1.7},
	doi = {10.18653/v1/2023.americasnlp-1.7},
	abstract = {Conventional approaches to learning word embeddings (Mikolov et al., 2013; Pennington et al., 2014) are limited to relatively few languages with sufficiently large training corpora. To address this limitation, we propose an alternative approach to deriving word embeddings for Wolastoqey and Mi’kmaq that leverages definitions from a bilingual dictionary. More specifically, following Bear and Cook (2022), we experiment with encoding English definitions of Wolastoqey and Mi’kmaq words into vector representations using English sequence representation models. For this, we consider using and fine-tuning sentence-RoBERTa models (Reimers and Gurevych, 2019). We evaluate our word embeddings using a similar methodology to that of Bear and Cook using evaluations based on word classification, clustering and reverse dictionary search. We additionally construct word embeddings for higher-resource languages — English, German and Spanish — using our methods and evaluate our embeddings on existing word-similarity datasets. Our findings indicate that our word embedding methods can be used to produce meaningful vector representations for low-resource languages such as Wolastoqey and Mi’kmaq and for higher-resource languages.},
	language = {en},
	urldate = {2023-10-23},
	booktitle = {Proceedings of the {Workshop} on {Natural} {Language} {Processing} for {Indigenous} {Languages} of the {Americas} ({AmericasNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Bear, Diego and Cook, Paul},
	year = {2023},
	pages = {47--57},
	file = {Bear und Cook - 2023 - Fine-tuning Sentence-RoBERTa to Construct Word Emb.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\UT87JYGG\\Bear und Cook - 2023 - Fine-tuning Sentence-RoBERTa to Construct Word Emb.pdf:application/pdf},
}

@misc{yang_dna-gpt_2023,
	title = {{DNA}-{GPT}: {Divergent} {N}-{Gram} {Analysis} for {Training}-{Free} {Detection} of {GPT}-{Generated} {Text}},
	shorttitle = {{DNA}-{GPT}},
	url = {http://arxiv.org/abs/2305.17359},
	abstract = {Large language models (LLMs) have notably enhanced the fluency and diversity of machine-generated text. However, this progress also presents a significant challenge in detecting the origin of a given text, and current research on detection methods lags behind the rapid evolution of LLMs. Conventional training-based methods have limitations in flexibility, particularly when adapting to new domains, and they often lack explanatory power. To address this gap, we propose a novel training-free detection strategy called Divergent N-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and then use only the preceding portion as input to the LLMs to regenerate the new remaining parts. By analyzing the differences between the original and new remaining parts through N-gram analysis in black-box or probability divergence in white-box, we unveil significant discrepancies between the distribution of machine-generated text and the distribution of human-written text. We conducted extensive experiments on the most advanced LLMs from OpenAI, including text-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such as GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach exhibits state-of-the-art performance in distinguishing between human and GPT-generated text on four English and one German dataset, outperforming OpenAI's own classifier, which is trained on millions of text. Additionally, our methods provide reasonable explanations and evidence to support our claim, which is a unique feature of explainable detection. Our method is also robust under the revised text attack and can additionally solve model sourcing. Codes are available at https://github.com/Xianjun-Yang/DNA-GPT.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Yang, Xianjun and Cheng, Wei and Wu, Yue and Petzold, Linda and Wang, William Yang and Chen, Haifeng},
	month = oct,
	year = {2023},
	note = {arXiv:2305.17359 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: Updates},
	file = {Yang et al. - 2023 - DNA-GPT Divergent N-Gram Analysis for Training-Fr.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\FV885NRN\\Yang et al. - 2023 - DNA-GPT Divergent N-Gram Analysis for Training-Fr.pdf:application/pdf},
}

@misc{gladkoff_predicting_2023,
	title = {Predicting {Perfect} {Quality} {Segments} in {MT} {Output} with {Fine}-{Tuned} {OpenAI} {LLM}: {Is} it possible to capture editing distance patterns from historical data?},
	shorttitle = {Predicting {Perfect} {Quality} {Segments} in {MT} {Output} with {Fine}-{Tuned} {OpenAI} {LLM}},
	url = {http://arxiv.org/abs/2308.00158},
	abstract = {Translation Quality Estimation (TQE) is an essential step before deploying the output translation into usage. TQE is also critical in assessing machine translation (MT) and human translation (HT) quality without seeing the reference translations. This work examines whether the stateof-the-art large language models (LLMs) can be fine-tuned for the TQE task and their capability. We take ChatGPT as one example and approach TQE as a binary classification task. Using eight language pairs including English to Italian, German, French, Japanese, Dutch, Portuguese, Turkish, and Chinese training corpora, our experimental results show that fine-tuned ChatGPT via its API can achieve a relatively high score on predicting translation quality, i.e. if the translation needs to be edited. However, there is definitely much space to improve the model accuracy, e.g. they are 82.42\% and 83.69\% for English-Italian and EnglishGerman respectively using our experimental settings.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Gladkoff, Serge and Erofeev, Gleb and Han, Lifeng and Nenadic, Goran},
	month = aug,
	year = {2023},
	note = {arXiv:2308.00158 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: 8 pages, 11 figures, under-review to ItalianNLP-2023},
	file = {Gladkoff et al. - 2023 - Predicting Perfect Quality Segments in MT Output w.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\95UX8J3B\\Gladkoff et al. - 2023 - Predicting Perfect Quality Segments in MT Output w.pdf:application/pdf},
}

@misc{silvestre_online_2023,
	title = {Online {Gesture} {Recognition} using {Transformer} and {Natural} {Language} {Processing}},
	url = {http://arxiv.org/abs/2305.03407},
	abstract = {The Transformer architecture is shown to provide a powerful machine transduction framework for online handwritten gestures corresponding to glyph strokes of natural language sentences. The attention mechanism is successfully used to create latent representations of an end-to-end encoder-decoder model, solving multi-level segmentation while also learning some language features and syntax rules. The additional use of a large decoding space with some learned Byte-PairEncoding (BPE) is shown to provide robustness to ablated inputs and syntax rules. The encoder stack was directly fed with spatio-temporal data tokens potentially forming an inﬁnitely large input vocabulary, an approach that ﬁnds applications beyond that of this work. Encoder transfer learning capabilities is also demonstrated on several languages resulting in faster optimisation and shared parameters. A new supervised dataset of online handwriting gestures suitable for generic handwriting recognition tasks was used to successfully train a small transformer model to an average normalised Levenshtein accuracy of 96\% on English or German sentences and 94\% in French.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Silvestre, G. C. M. and Balado, F. and Akinremi, O. and Ramo, M.},
	month = may,
	year = {2023},
	note = {arXiv:2305.03407 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 5 pages, 2 figures, 4 tables. arXiv admin note: substantial text overlap with arXiv:2211.02643},
	file = {Silvestre et al. - 2023 - Online Gesture Recognition using Transformer and N.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\ZXIFAVE8\\Silvestre et al. - 2023 - Online Gesture Recognition using Transformer and N.pdf:application/pdf},
}

@misc{de_la_rosa_alberti_2023,
	title = {{ALBERTI}, a {Multilingual} {Domain} {Specific} {Language} {Model} for {Poetry} {Analysis}},
	url = {http://arxiv.org/abs/2307.01387},
	abstract = {The computational analysis of poetry is limited by the scarcity of tools to automatically analyze and scan poems. In a multilingual settings, the problem is exacerbated as scansion and rhyme systems only exist for individual languages, making comparative studies very challenging and time consuming. In this work, we present Alberti, the first multilingual pretrained large language model for poetry. Through domain-specific pre-training (DSP), we further trained multilingual BERT on a corpus of over 12 million verses from 12 languages. We evaluated its performance on two structural poetry tasks: Spanish stanza type classification, and metrical pattern prediction for Spanish, English and German. In both cases, Alberti outperforms multilingual BERT and other tranformers-based models of similar sizes, and even achieves state-of-the-art results for German when compared to rule-based systems, demonstrating the feasibility and effectiveness of DSP in the poetry domain.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {de la Rosa, Javier and Pozo, Álvaro Pérez and Ros, Salvador and González-Blanco, Elena},
	month = jul,
	year = {2023},
	note = {arXiv:2307.01387 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted for publication at SEPLN 2023: 39th International Conference of the Spanish Society for Natural Language Processing},
	file = {de la Rosa et al. - 2023 - ALBERTI, a Multilingual Domain Specific Language M.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\A8HHYZXC\\de la Rosa et al. - 2023 - ALBERTI, a Multilingual Domain Specific Language M.pdf:application/pdf},
}

@misc{chen_can_2023,
	title = {Can {Large} {Language} {Models} {Provide} {Security} \& {Privacy} {Advice}? {Measuring} the {Ability} of {LLMs} to {Refute} {Misconceptions}},
	shorttitle = {Can {Large} {Language} {Models} {Provide} {Security} \& {Privacy} {Advice}?},
	url = {http://arxiv.org/abs/2310.02431},
	abstract = {Users seek security \& privacy (S\&P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S\&P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g., to produce toxic content). Yet, the ability of LLMs to provide reliable S\&P advice is not well-explored. In this paper, we measure their ability to refute popular S\&P misconceptions that the general public holds. We first study recent academic literature to curate a dataset of over a hundred S\&Prelated misconceptions across six different topics. We then query two popular LLMs (Bard and ChatGPT) and develop a labeling guide to evaluate their responses to these misconceptions. To comprehensively evaluate their responses, we further apply three strategies: query each misconception multiple times, generate and query their paraphrases, and solicit source URLs of the responses.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Chen, Yufan and Arunasalam, Arjun and Celik, Z. Berkay},
	month = oct,
	year = {2023},
	note = {arXiv:2310.02431 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	annote = {Comment: Accepted to the Annual Computer Security Applications Conference (ACSAC), 2023},
	file = {Chen et al. - 2023 - Can Large Language Models Provide Security & Priva.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\HINYA87I\\Chen et al. - 2023 - Can Large Language Models Provide Security & Priva.pdf:application/pdf},
}

@misc{ling_improving_2023,
	title = {Improving {Open} {Information} {Extraction} with {Large} {Language} {Models}: {A} {Study} on {Demonstration} {Uncertainty}},
	shorttitle = {Improving {Open} {Information} {Extraction} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2309.03433},
	abstract = {Open Information Extraction (OIE) task aims at extracting structured facts from unstructured text, typically in the form of (subject, relation, object) triples. Despite the potential of large language models (LLMs) like ChatGPT as a general task solver, they lag behind state-of-the-art (supervised) methods in OIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant context from relevant relations and generate structured output due to the restrictions on fine-tuning the model. Second, LLMs generates responses autoregressively based on probability, which makes the predicted relations lack confidence. In this paper, we assess the capabilities of LLMs in improving the OIE task. Particularly, we propose various in-context learning strategies to enhance LLM's instruction-following ability and a demonstration uncertainty quantification module to enhance the confidence of the generated relations. Our experiments on three OIE benchmark datasets show that our approach holds its own against established supervised methods, both quantitatively and qualitatively.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Ling, Chen and Zhao, Xujiang and Zhang, Xuchao and Liu, Yanchi and Cheng, Wei and Wang, Haoyu and Chen, Zhengzhang and Osaki, Takao and Matsuda, Katsushi and Chen, Haifeng and Zhao, Liang},
	month = sep,
	year = {2023},
	note = {arXiv:2309.03433 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Ling et al. - 2023 - Improving Open Information Extraction with Large L.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\3IL2TRY9\\Ling et al. - 2023 - Improving Open Information Extraction with Large L.pdf:application/pdf},
}

@misc{song_letz_2023,
	title = {Letz {Translate}: {Low}-{Resource} {Machine} {Translation} for {Luxembourgish}},
	shorttitle = {Letz {Translate}},
	url = {http://arxiv.org/abs/2303.01347},
	abstract = {Natural language processing of Low-Resource Languages (LRL) is often challenged by the lack of data. Therefore, achieving accurate machine translation (MT) in a low-resource environment is a real problem that requires practical solutions. Research in multilingual models have shown that some LRLs can be handled with such models. However, their large size and computational needs make their use in constrained environments (e.g., mobile/IoT devices or limited/old servers) impractical. In this paper, we address this problem by leveraging the power of large multilingual MT models using knowledge distillation. Knowledge distillation can transfer knowledge from a large and complex teacher model to a simpler and smaller student model without losing much in performance. We also make use of high-resource languages that are related or share the same linguistic root as the target LRL. For our evaluation, we consider Luxembourgish as the LRL that shares some roots and properties with German. We build multiple resource-efﬁcient models based on German, knowledge distillation from the multilingual No Language Left Behind (NLLB) model, and pseudo-translation. We ﬁnd that our efﬁcient models are more than 30\% faster and perform only 4\% lower compared to the large state-of-the-art NLLB model.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Song, Yewei and Ezzini, Saad and Klein, Jacques and Bissyande, Tegawende and Lefebvre, Clément and Goujon, Anne},
	month = mar,
	year = {2023},
	note = {arXiv:2303.01347 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Software Engineering},
	annote = {Comment: The associated model is published on HuggingFace: https://huggingface.co/etamin/Letz-Translate-OPUS-LB-EN The Dictionary used in this paper is available in Github: https://github.com/Etamin/Ltz\_dictionary},
	file = {Song et al. - 2023 - Letz Translate Low-Resource Machine Translation f.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\X2C5A3KI\\Song et al. - 2023 - Letz Translate Low-Resource Machine Translation f.pdf:application/pdf},
}

@misc{lasser_collective_2023,
	title = {Collective moderation of hate, toxicity, and extremity in online discussions},
	url = {http://arxiv.org/abs/2303.00357},
	abstract = {How can citizens moderate hate, toxicity, and extremism in online discourse? We analyze a large corpus of more than 130,000 discussions on German Twitter over the turbulent four years marked by the migrant crisis and political upheavals. With the help of human annotators, language models and machine learning classifiers, we identify different dimensions of discourse. We use a matching approach and longitudinal statistical analyses to discern the effectiveness of different counter speech strategies on the micro-level (individual tweet pairs), meso-level (discussion trees) and macro-level (days) of discourse. We find that expressing simple opinions, not necessarily supported by facts, but also without insults, relates to the least hate, toxicity, and extremity of speech and speakers in subsequent discussions. Sarcasm also helps in achieving those outcomes, in particular in the presence of organized extreme groups on the meso-level. Constructive comments such as providing facts or exposing contradictions can backfire and attract more extremity. Mentioning either outgroups or ingroups is typically related to a deterioration of discourse. A pronounced emotional tone, either negative such as anger or fear, or positive such as enthusiasm and pride, also leads to worse outcomes. Going beyond one-shot analyses on smaller samples of discourse, our findings have implications for the successful management of online commons through collective civic moderation.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Lasser, Jana and Herderich, Alina and Garland, Joshua and Aroyehun, Segun Taofeek and Garcia, David and Galesic, Mirta},
	month = aug,
	year = {2023},
	note = {arXiv:2303.00357 [cs]},
	keywords = {Computer Science - Computers and Society},
	file = {Lasser et al. - 2023 - Collective moderation of hate, toxicity, and extre.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\S4I6DWWN\\Lasser et al. - 2023 - Collective moderation of hate, toxicity, and extre.pdf:application/pdf},
}

@misc{belouadi_bygpt5_2023,
	title = {{ByGPT5}: {End}-to-{End} {Style}-conditioned {Poetry} {Generation} with {Token}-free {Language} {Models}},
	shorttitle = {{ByGPT5}},
	url = {http://arxiv.org/abs/2212.10474},
	abstract = {State-of-the-art poetry generation systems are often complex. They either consist of task-specific model pipelines, incorporate prior knowledge in the form of manually created constraints, or both. In contrast, end-to-end models would not suffer from the overhead of having to model prior knowledge and could learn the nuances of poetry from data alone, reducing the degree of human supervision required. In this work, we investigate end-to-end poetry generation conditioned on styles such as rhyme, meter, and alliteration. We identify and address lack of training data and mismatching tokenization algorithms as possible limitations of past attempts. In particular, we successfully pre-train ByGPT5, a new token-free decoder-only language model, and fine-tune it on a large custom corpus of English and German quatrains annotated with our styles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2 and ChatGPT, while also being more parameter efficient and performing favorably compared to humans. In addition, we analyze its runtime performance and demonstrate that it is not prone to memorization. We make our code, models, and datasets publicly available.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Belouadi, Jonas and Eger, Steffen},
	month = may,
	year = {2023},
	note = {arXiv:2212.10474 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted at ACL 2023 (main track)},
	file = {Belouadi und Eger - 2023 - ByGPT5 End-to-End Style-conditioned Poetry Genera.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\5T6STUS4\\Belouadi und Eger - 2023 - ByGPT5 End-to-End Style-conditioned Poetry Genera.pdf:application/pdf},
}

@misc{garcia-ferrero_t-projection_2022,
	title = {T-{Projection}: {High} {Quality} {Annotation} {Projection} for {Sequence} {Labeling} {Tasks}},
	shorttitle = {T-{Projection}},
	url = {http://arxiv.org/abs/2212.10548},
	abstract = {In the absence of readily available labeled data for a given task and language, annotation projection has been proposed as one of the possible strategies to automatically generate annotated data which may then be used to train supervised systems. Annotation projection has often been formulated as the task of projecting, on parallel corpora, some labels from a source into a target language. In this paper we present T-Projection, a new approach for annotation projection that leverages large pretrained text2text language models and stateof-the-art machine translation technology. TProjection decomposes the label projection task into two subtasks: (i) The candidate generation step, in which a set of projection candidates using a multilingual T5 model is generated and, (ii) the candidate selection step, in which the candidates are ranked based on translation probabilities. We evaluate our method in three downstream tasks and ﬁve different languages. Our results show that Tprojection improves the average F1 score of previous methods by more than 8 points.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {García-Ferrero, Iker and Agerri, Rodrigo and Rigau, German},
	month = dec,
	year = {2022},
	note = {arXiv:2212.10548 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {García-Ferrero et al. - 2022 - T-Projection High Quality Annotation Projection f.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\9YEDS7EK\\García-Ferrero et al. - 2022 - T-Projection High Quality Annotation Projection f.pdf:application/pdf},
}

@article{gombert_coding_2023,
	title = {Coding energy knowledge in constructed responses with explainable {NLP} models},
	volume = {39},
	issn = {1365-2729},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jcal.12767},
	doi = {10.1111/jcal.12767},
	abstract = {Background Formative assessments are needed to enable monitoring how student knowledge develops throughout a unit. Constructed response items which require learners to formulate their own free-text responses are well suited for testing their active knowledge. However, assessing such constructed responses in an automated fashion is a complex task and requires the application of natural language processing methodology. In this article, we implement and evaluate multiple machine learning models for coding energy knowledge in free-text responses of German K-12 students to items in formative science assessments which were conducted during synchronous online learning sessions. Dataset The dataset we collected for this purpose consists of German constructed responses from 38 different items dealing with aspects of energy such as manifestation and transformation. The units and items were implemented with the help of project-based pedagogy and evidence-centered design, and the responses were coded for seven core ideas concerning the manifestation and transformation of energy. The data was collected from students in seventh, eighth and ninth grade. Methodology We train various transformer- and feature-based models and compare their ability to recognize the respective ideas in students' writing. Moreover, as domain knowledge and its development can be formally modeled through knowledge networks, we evaluate how well the detection of the ideas within responses translated into accurate co-occurrence-based knowledge networks. Finally, in terms of the descriptive accuracy of our models, we inspect what features played a role for which prediction outcome and if the models pick up on undesired shortcuts. In addition to this, we analyze how much the models match human coders in what evidence within responses they consider important for their coding decisions. Results A model based on a modified GBERT-large can achieve the overall most promising results, although descriptive accuracy varies much more than predictive accuracy for the different ideas assessed. For reasons of comparability, we also evaluate the same machine learning architecture using the SciEntsBank 3-Way benchmark with an English RoBERTa-large model, where it achieves state-of-the-art results in two out of three evaluation categories.},
	language = {en},
	number = {3},
	urldate = {2023-10-23},
	journal = {Journal of Computer Assisted Learning},
	author = {Gombert, Sebastian and Di Mitri, Daniele and Karademir, Onur and Kubsch, Marcus and Kolbe, Hannah and Tautz, Simon and Grimm, Adrian and Bohm, Isabell and Neumann, Knut and Drachsler, Hendrik},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12767},
	keywords = {automated coding, constructed response assessment, energy didactics, energy transformation, knowledge networks, short answer scoring},
	pages = {767--786},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\B5QVZF35\\Gombert et al. - 2023 - Coding energy knowledge in constructed responses w.pdf:application/pdf;Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\KIWG8QDP\\jcal.html:text/html},
}

@article{erd_data_nodate,
	title = {Data {Augmentation} for {Named} {Entity} {Recognition} in the {German} {Legal} {Domain}},
	language = {en},
	author = {Erd, Robin},
	file = {Erd - Data Augmentation for Named Entity Recognition in .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\U7BCYZ6Y\\Erd - Data Augmentation for Named Entity Recognition in .pdf:application/pdf},
}

@misc{trautmann_legal_2022,
	title = {Legal {Prompt} {Engineering} for {Multilingual} {Legal} {Judgement} {Prediction}},
	url = {http://arxiv.org/abs/2212.02199},
	abstract = {Legal Prompt Engineering (LPE) or Legal Prompting is a process to guide and assist a large language model (LLM) with performing a natural legal language processing (NLLP) skill. Our goal is to use LPE with LLMs over long legal documents for the Legal Judgement Prediction (LJP) task. We investigate the performance of zero-shot LPE for given facts in case-texts from the European Court of Human Rights (in English) and the Federal Supreme Court of Switzerland (in German, French and Italian). Our results show that zero-shot LPE is better compared to the baselines, but it still falls short compared to current state of the art supervised approaches. Nevertheless, the results are important, since there was 1) no explicit domain-speciﬁc data used — so we show that the transfer to the legal domain is possible for general-purpose LLMs, and 2) the LLMs where directly applied without any further training or ﬁne-tuning — which in turn saves immensely in terms of additional computational costs.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Trautmann, Dietrich and Petrova, Alina and Schilder, Frank},
	month = dec,
	year = {2022},
	note = {arXiv:2212.02199 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Trautmann et al. - 2022 - Legal Prompt Engineering for Multilingual Legal Ju.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\XWLBDH6B\\Trautmann et al. - 2022 - Legal Prompt Engineering for Multilingual Legal Ju.pdf:application/pdf},
}

@misc{pomerenke_inclusify_2022,
	title = {{INCLUSIFY}: {A} benchmark and a model for gender-inclusive {German}},
	shorttitle = {{INCLUSIFY}},
	url = {http://arxiv.org/abs/2212.02564},
	abstract = {Gender-inclusive language is important for achieving gender equality in languages with gender inﬂections, such as German. While stirring some controversy, it is increasingly adopted by companies and political institutions. A handful of tools have been developed to help people use gender-inclusive language by identifying instances of the generic masculine and providing suggestions for more inclusive reformulations. In this report, we deﬁne the underlying tasks in terms of natural language processing, and present a dataset and measures for benchmarking them. We also present a model that implements these tasks, by combining an inclusive language database with an elaborate sequence of processing steps via standard pre-trained models. Our model achieves a recall of 0.89 and a precision of 0.82 in our benchmark for identifying exclusive language; and one of its top ﬁve suggestions is chosen in real-world texts in 44\% of cases. We sketch how the area could be further advanced by training end-to-end models and using large language models; and we urge the community to include more gender-inclusive texts in their training data in order to not present an obstacle to the adoption of gender-inclusive language. Through these efforts, we hope to contribute to restoring justice in language and, to a small extent, in reality.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Pomerenke, David},
	month = dec,
	year = {2022},
	note = {arXiv:2212.02564 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Pomerenke - 2022 - INCLUSIFY A benchmark and a model for gender-incl.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\BDCL5B6G\\Pomerenke - 2022 - INCLUSIFY A benchmark and a model for gender-incl.pdf:application/pdf},
}

@book{figueroa-garcia_applied_2022,
	title = {Applied {Computer} {Sciences} in {Engineering}: 9th {Workshop} on {Engineering} {Applications}, {WEA} 2022, {Bogotá}, {Colombia}, {November} 30 – {December} 2, 2022, {Proceedings}},
	isbn = {978-3-031-20611-5},
	shorttitle = {Applied {Computer} {Sciences} in {Engineering}},
	abstract = {This book constitutes the proceedings of the 9th Workshop on Engineering Applications on Applied Computer Sciences in Engineering, WEA 2022, which took place in Bogotá, Colombia, in November/December 2022. The 39 papers presented in this volume were carefully reviewed and selected from 143 submissions. They were organized in topical sections as follows: Artificial Intelligence; Optimization; Simulation; and Applications.},
	language = {en},
	publisher = {Springer Nature},
	author = {Figueroa-García, Juan Carlos and Franco, Carlos and Díaz-Gutierrez, Yesid and Hernández-Pérez, Germán},
	month = nov,
	year = {2022},
	note = {Google-Books-ID: zoedEAAAQBAJ},
	keywords = {Computers / Artificial Intelligence / General, Computers / Data Science / General, Computers / Information Technology, Computers / Networking / Hardware, Computers / Software Development \& Engineering / General, Computers / Software Development \& Engineering / Systems Analysis \& Design, Computers / System Administration / Storage \& Retrieval},
}

@misc{ma_correction_2023,
	title = {Correction {Focused} {Language} {Model} {Training} for {Speech} {Recognition}},
	url = {http://arxiv.org/abs/2310.11003},
	abstract = {Language models (LMs) have been commonly adopted to boost the performance of automatic speech recognition (ASR) particularly in domain adaptation tasks. Conventional way of LM training treats all the words in corpora equally, resulting in suboptimal improvements in ASR performance. In this work, we introduce a novel correction focused LM training approach which aims to prioritize ASR fallible words. The word-level ASR fallibility score, representing the likelihood of ASR mis-recognition, is defined and shaped as a prior word distribution to guide the LM training. To enable correction focused training with text-only corpora, large language models (LLMs) are employed as fallibility score predictors and text generators through multi-task fine-tuning. Experimental results for domain adaptation tasks demonstrate the effectiveness of our proposed method. Compared with conventional LMs, correction focused training achieves up to relatively 5.5\% word error rate (WER) reduction in sufficient text scenarios. In insufficient text scenarios, LM training with LLMgenerated text achieves up to relatively 13\% WER reduction, while correction focused training further obtains up to relatively 6\% WER reduction.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Ma, Yingyi and Liu, Zhe and Kalinli, Ozlem},
	month = oct,
	year = {2023},
	note = {arXiv:2310.11003 [cs, eess]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	file = {Ma et al. - 2023 - Correction Focused Language Model Training for Spe.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\ZI2AVC6B\\Ma et al. - 2023 - Correction Focused Language Model Training for Spe.pdf:application/pdf},
}

@misc{ye_enhancing_2023,
	title = {Enhancing {Conversational} {Search}: {Large} {Language} {Model}-{Aided} {Informative} {Query} {Rewriting}},
	shorttitle = {Enhancing {Conversational} {Search}},
	url = {http://arxiv.org/abs/2310.09716},
	abstract = {Query rewriting plays a vital role in enhancing conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverage human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a "rewrite-then-edit" process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can yield substantially improved retrieval performance compared to human rewrites, especially with sparse retrievers.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Ye, Fanghua and Fang, Meng and Li, Shenghui and Yilmaz, Emine},
	month = oct,
	year = {2023},
	note = {arXiv:2310.09716 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Information Retrieval},
	annote = {Comment: 22 pages, accepted to EMNLP Findings 2023},
	file = {Ye et al. - 2023 - Enhancing Conversational Search Large Language Mo.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\IHSNH258\\Ye et al. - 2023 - Enhancing Conversational Search Large Language Mo.pdf:application/pdf},
}

@misc{zhang_autonomous_2023,
	title = {Autonomous {Tree}-search {Ability} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2310.10686},
	abstract = {Large Language Models (LLMs) have excelled in remarkable reasoning capabilities with advanced prompting techniques (e.g., Chain-of-Thought), but they fall short on tasks that require exploration, strategic foresight, and sequential decisionmaking. Recent works propose to utilize external programs (e.g., Python codes) to define search logic, such that LLMs can perform passive tree search to solve more challenging reasoning tasks. Though impressive results have been achieved, there are several fundamental limitations of these approaches. First, passive tree searches are not efficient as they usually require multiple rounds of LLM API calls to solve one single problem. Moreover, passive search methods are not flexible since they need task-specific program designs. Then a natural question arises: can we maintain the tree-search capability of LLMs without the aid of external programs, and can still generate responses that clearly demonstrate the process of a tree-structure search? To this end, we propose a new concept called autonomous tree-search ability of LLM, which can automatically generate a response containing search trajectories for the correct answer. Concretely, we first perform both BFS and DFS style search trajectories using more capable LLM API (e.g. GPT-4 and GPT-3.5) via a fixed system prompt, allowing them to perform autonomous tree-search (ATS) right out of the box. Experiments on 4 challenge puzzle games demonstrate our method can achieve huge improvements. The ATS-BFS method outperforms the Chain of Thought approach by achieving an average accuracy improvement of 33\%. Compared to Tree of Thoughts, it requires 65.6\% or 47.7\% less GPT-api cost to attain a comparable level of accuracy. Moreover, we have collected a dataset using the ATS prompt method and fine-tuned LLaMA with this dataset. This approach has shown to yield a greater improvement compared to the ones fine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an average of 40.6\% and 38.5\% for LLaMA2-7B and LLaMA2-13B, respectively.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Zhang, Zheyu and Ye, Zhuorui and Shen, Yikang and Gan, Chuang},
	month = oct,
	year = {2023},
	note = {arXiv:2310.10686 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: Due to the limitation "The abstract field cannot be longer than 1,920 characters", the abstract here is shorter than that in the PDF file},
	file = {Zhang et al. - 2023 - Autonomous Tree-search Ability of Large Language M.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\WKDNSZQQ\\Zhang et al. - 2023 - Autonomous Tree-search Ability of Large Language M.pdf:application/pdf},
}

@misc{kandpal_user_2023,
	title = {User {Inference} {Attacks} on {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2310.09266},
	abstract = {Fine-tuning is a common and effective method for tailoring large language models (LLMs) to specialized tasks and applications. In this paper, we study the privacy implications of finetuning LLMs on user data. To this end, we define a realistic threat model, called user inference, wherein an attacker infers whether or not a user’s data was used for fine-tuning. We implement attacks for this threat model that require only a small set of samples from a user (possibly different from the samples used for training) and black-box access to the fine-tuned LLM. We find that LLMs are susceptible to user inference attacks across a variety of fine-tuning datasets, at times with near perfect attack success rates. Further, we investigate which properties make users vulnerable to user inference, finding that outlier users (i.e. those with data distributions sufficiently different from other users) and users who contribute large quantities of data are most susceptible to attack. Finally, we explore several heuristics for mitigating privacy attacks. We find that interventions in the training algorithm, such as batch or per-example gradient clipping and early stopping fail to prevent user inference. However, limiting the number of fine-tuning samples from a single user can reduce attack effectiveness, albeit at the cost of reducing the total amount of fine-tuning data.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Kandpal, Nikhil and Pillutla, Krishna and Oprea, Alina and Kairouz, Peter and Choquette-Choo, Christopher A. and Xu, Zheng},
	month = oct,
	year = {2023},
	note = {arXiv:2310.09266 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Cryptography and Security},
	file = {Kandpal et al. - 2023 - User Inference Attacks on Large Language Models.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\A2GPG9Y4\\Kandpal et al. - 2023 - User Inference Attacks on Large Language Models.pdf:application/pdf},
}

@misc{gholami_does_2023,
	title = {Does {Synthetic} {Data} {Make} {Large} {Language} {Models} {More} {Efficient}?},
	url = {http://arxiv.org/abs/2310.07830},
	abstract = {Natural Language Processing (NLP) has undergone transformative changes with the advent of deep learning methodologies. One challenge persistently confronting researchers is the scarcity of high-quality, annotated datasets that drive these models. This paper explores the nuances of synthetic data generation in NLP, with a focal point on template-based question generation. By assessing its advantages, including data augmentation potential and the introduction of structured variety, we juxtapose these benefits against inherent limitations, such as the risk of overfitting and the constraints posed by pre-defined templates. Drawing from empirical evaluations, we demonstrate the impact of template-based synthetic data on the performance of modern transformer models. We conclude by emphasizing the delicate balance required between synthetic and real-world data, and the future trajectories of integrating synthetic data in model training pipelines. The findings aim to guide NLP practitioners in harnessing synthetic data’s potential, ensuring optimal model performance in diverse applications.},
	language = {en},
	urldate = {2023-10-23},
	publisher = {arXiv},
	author = {Gholami, Sia and Omar, Marwan},
	month = oct,
	year = {2023},
	note = {arXiv:2310.07830 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Gholami und Omar - 2023 - Does Synthetic Data Make Large Language Models Mor.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\5BK9XA93\\Gholami und Omar - 2023 - Does Synthetic Data Make Large Language Models Mor.pdf:application/pdf},
}

@misc{jones_does_2023,
	title = {Does {GPT}-4 {Pass} the {Turing} {Test}?},
	url = {http://arxiv.org/abs/2310.20216},
	abstract = {We evaluated GPT-4 in a public online Turing Test. The best-performing GPT-4 prompt passed in 41\% of games, outperforming baselines set by ELIZA (27\%) and GPT-3.5 (14\%), but falling short of chance and the baseline set by human participants (63\%). Participants’ decisions were based mainly on linguistic style (35\%) and socio-emotional traits (27\%), supporting the idea that intelligence is not sufficient to pass the Turing Test. Participants’ demographics, including education and familiarity with LLMs, did not predict detection rate, suggesting that even those who understand systems deeply and interact with them frequently may be susceptible to deception. Despite known limitations as a test of intelligence, we argue that the Turing Test continues to be relevant as an assessment of naturalistic communication and deception. AI models with the ability to masquerade as humans could have widespread societal consequences, and we analyse the effectiveness of different strategies and criteria for judging humanlikeness.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Jones, Cameron and Bergen, Benjamin},
	month = oct,
	year = {2023},
	note = {arXiv:2310.20216 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: 25 pages, 21 figures},
	file = {Jones und Bergen - 2023 - Does GPT-4 Pass the Turing Test.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\VU2GMX39\\Jones und Bergen - 2023 - Does GPT-4 Pass the Turing Test.pdf:application/pdf},
}

@misc{an_learning_2023,
	title = {Learning {From} {Mistakes} {Makes} {LLM} {Better} {Reasoner}},
	url = {http://arxiv.org/abs/2310.20689},
	abstract = {Large language models (LLMs) recently exhibited remarkable reasoning capabilities on solving math problems. To further improve this capability, this work proposes LEarning from MistAkes (LEMA), akin to human learning processes. Consider a human student who failed to solve a math problem, he will learn from what mistake he has made and how to correct it. Mimicking this error-driven learning process, LEMA fine-tunes LLMs on mistakecorrection data pairs generated by GPT-4. Specifically, we first collect inaccurate reasoning paths from various LLMs and then employ GPT-4 as a "corrector" to (1) identify the mistake step, (2) explain the reason for the mistake, and (3) correct the mistake and generate the final answer. Experimental results demonstrate the effectiveness of LEMA: across five backbone LLMs and two mathematical reasoning tasks, LEMA consistently improves the performance compared with fine-tuning on CoT data alone. Impressively, LEMA can also benefit specialized LLMs such as WizardMath and MetaMath, achieving 85.4\% pass@1 accuracy on GSM8K and 27.1\% on MATH. This surpasses the SOTA performance achieved by non-execution open-source models on these challenging tasks. Our code, data and models will be publicly available at Github Link.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {An, Shengnan and Ma, Zexiong and Lin, Zeqi and Zheng, Nanning and Lou, Jian-Guang and Chen, Weizhu},
	month = oct,
	year = {2023},
	note = {arXiv:2310.20689 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: 14 pages, 4 figures},
	file = {An et al. - 2023 - Learning From Mistakes Makes LLM Better Reasoner.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\9FCM9ZX5\\An et al. - 2023 - Learning From Mistakes Makes LLM Better Reasoner.pdf:application/pdf},
}

@misc{peng_fp8-lm_2023,
	title = {{FP8}-{LM}: {Training} {FP8} {Large} {Language} {Models}},
	shorttitle = {{FP8}-{LM}},
	url = {http://arxiv.org/abs/2310.18313},
	abstract = {In this paper, we explore FP8 low-bit data formats for efficient training of large language models (LLMs). Our key insight is that most variables, such as gradients and optimizer states, in LLM training can employ low-precision data formats without compromising model accuracy and requiring no changes to hyper-parameters. Specifically, we propose a new FP8 automatic mixed-precision framework for training LLMs. This framework offers three levels of FP8 utilization to streamline mixed-precision and distributed parallel training for LLMs. It gradually incorporates 8-bit gradients, optimizer states, and distributed learning in an incremental manner. Experiment results show that, during the training of GPT-175B model on H100 GPU platform, our FP8 mixed-precision training framework not only achieved a remarkable 42\% reduction in real memory usage but also ran 64\% faster than the widely adopted BF16 framework (i.e., Megatron-LM), surpassing the speed of Nvidia Transformer Engine by 17\%. This largely reduces the training costs for large foundation models. Furthermore, our FP8 mixed-precision training methodology is generic. It can be seamlessly applied to other tasks such as LLM instruction tuning and reinforcement learning with human feedback, offering savings in fine-tuning expenses. Our FP8 low-precision training framework is open-sourced at aka.ms/MS.AMP.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Peng, Houwen and Wu, Kan and Wei, Yixuan and Zhao, Guoshuai and Yang, Yuxiang and Liu, Ze and Xiong, Yifan and Yang, Ziyue and Ni, Bolin and Hu, Jingcheng and Li, Ruihang and Zhang, Miaosen and Li, Chen and Ning, Jia and Wang, Ruizhe and Zhang, Zheng and Liu, Shuguang and Chau, Joe and Hu, Han and Cheng, Peng},
	month = oct,
	year = {2023},
	note = {arXiv:2310.18313 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Peng et al. - 2023 - FP8-LM Training FP8 Large Language Models.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\J7JMK5YS\\Peng et al. - 2023 - FP8-LM Training FP8 Large Language Models.pdf:application/pdf},
}

@misc{huang_can_2023,
	title = {Can {Large} {Language} {Models} {Explain} {Themselves}? {A} {Study} of {LLM}-{Generated} {Self}-{Explanations}},
	shorttitle = {Can {Large} {Language} {Models} {Explain} {Themselves}?},
	url = {http://arxiv.org/abs/2310.11207},
	abstract = {Large language models (LLMs) such as ChatGPT have demonstrated superior performance on a variety of natural language processing (NLP) tasks including sentiment analysis, mathematical reasoning and summarization. Furthermore, since these models are instruction-tuned on human conversations to produce “helpful” responses, they can and often will produce explanations along with the response, which we call selfexplanations. For example, when analyzing the sentiment of a movie review, the model may output not only the positivity of the sentiment, but also an explanation (e.g., by listing the sentimentladen words such as “fantastic” and “memorable” in the review). How good are these automatically generated self-explanations? In this paper, we investigate this question on the task of sentiment analysis and for feature attribution explanation, one of the most commonly studied settings in the interpretability literature (for pre-ChatGPT models). Specifically, we study different ways to elicit the self-explanations, evaluate their faithfulness on a set of evaluation metrics, and compare them to traditional explanation methods such as occlusion or LIME saliency maps. Through an extensive set of experiments, we find that ChatGPT’s selfexplanations perform on par with traditional ones, but are quite different from them according to various agreement metrics, meanwhile being much cheaper to produce (as they are generated along with the prediction). In addition, we identified several interesting characteristics of them, which prompt us to rethink many current model interpretability practices in the era of ChatGPT(-like) LLMs.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Huang, Shiyuan and Mamidanna, Siddarth and Jangam, Shreedhar and Zhou, Yilun and Gilpin, Leilani H.},
	month = oct,
	year = {2023},
	note = {arXiv:2310.11207 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Huang et al. - 2023 - Can Large Language Models Explain Themselves A St.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\X93GFBTL\\Huang et al. - 2023 - Can Large Language Models Explain Themselves A St.pdf:application/pdf},
}

@misc{zheng_learn_2023,
	title = {Learn {From} {Model} {Beyond} {Fine}-{Tuning}: {A} {Survey}},
	shorttitle = {Learn {From} {Model} {Beyond} {Fine}-{Tuning}},
	url = {http://arxiv.org/abs/2310.08184},
	abstract = {Foundation models (FM) have demonstrated remarkable performance across a wide range of tasks (especially in the fields of natural language processing and computer vision), primarily attributed to their ability to comprehend instructions and access extensive, high-quality data. This not only showcases their current effectiveness but also sets a promising trajectory towards the development of artificial general intelligence. Unfortunately, due to multiple constraints, the raw data of the model used for large model training are often inaccessible, so the use of end-to-end models for downstream tasks has become a new research trend, which we call Learn From Model (LFM) in this article. LFM focuses on the research, modification, and design of FM based on the model interface, so as to better understand the model structure and weights (in a black box environment), and to generalize the model to downstream tasks. The study of LFM techniques can be broadly categorized into five major areas: model tuning, model distillation, model reuse, meta learning and model editing. Each category encompasses a repertoire of methods and strategies that aim to enhance the capabilities and performance of FM. This paper gives a comprehensive review of the current methods based on FM from the perspective of LFM, in order to help readers better understand the current research status and ideas. To conclude, we summarize the survey by highlighting several critical areas for future exploration and addressing open issues that require further attention from the research community. The relevant papers we investigated in this article can be accessed at https://github.com/ruthless-man/Awesome-Learn-from-Model.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Zheng, Hongling and Shen, Li and Tang, Anke and Luo, Yong and Hu, Han and Du, Bo and Tao, Dacheng},
	month = oct,
	year = {2023},
	note = {arXiv:2310.08184 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: 20 pages, 9 figures},
	file = {Zheng et al. - 2023 - Learn From Model Beyond Fine-Tuning A Survey.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\8IXE8M43\\Zheng et al. - 2023 - Learn From Model Beyond Fine-Tuning A Survey.pdf:application/pdf},
}

@article{samarinas_multi-modal_nodate,
	title = {Multi-{Modal} {Augmentation} for {Large} {Language} {Models} with {Applications} to {Task}-{Oriented} {Dialogues}},
	abstract = {We introduce MarunaBot V2, an advanced Task-Oriented Dialogue System (TODS) primarily aimed at aiding users in cooking and Do-It-Yourself tasks. We utilized large language models (LLMs) for data generation and inference, and implemented hybrid methods for intent classification, retrieval, and question answering, striking a balance between efficiency and performance. A key feature of our system is its multi-modal capabilities. We have incorporated a multi-modal enrichment technique that uses a fine-tuned CLIP model to supplement recipe instructions with pertinent images, a custom Diffusion model for image enhancement and generation, and a method for multi-modal option matching. A unique aspect of our system is its user-centric development approach, facilitated by a custom tool for tracking user interactions and swiftly integrating feedback. For a demonstration of our system, visit https://youtu.be/4MNI-puv\_eE.},
	language = {en},
	author = {Samarinas, Chris and Promthaw, Pracha and Lekhwani, Rohan and Mysore, Sheshera and Huang, Sung Ming and Nijasure, Atharva and Zeng, Hansi and Zamani, Hamed},
	file = {Samarinas et al. - Multi-Modal Augmentation for Large Language Models.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\3AD2RR35\\Samarinas et al. - Multi-Modal Augmentation for Large Language Models.pdf:application/pdf},
}

@misc{zhang_tuning_2023,
	title = {Tuning {Large} language model for {End}-to-end {Speech} {Translation}},
	url = {http://arxiv.org/abs/2310.02050},
	abstract = {With the emergence of large language models (LLMs), multimodal models based on LLMs have demonstrated significant potential. Models such as LLaSM, X-LLM, and SpeechGPT exhibit an impressive ability to comprehend and generate human instructions. However, their performance often falters when faced with complex tasks like end-to-end speech translation (E2E-ST), a cross-language and cross-modal translation task. In comparison to single-modal models, multimodal models lag behind in these scenarios. This paper introduces LST, a Large multimodal model designed to excel at the E2E-ST task. LST consists of a speech frontend, an adapter, and a LLM backend. The training of LST consists of two stages: (1) Modality adjustment, where the adapter is tuned to align speech representation with text embedding space, and (2) Downstream task fine-tuning, where both the adapter and LLM model are trained to optimize performance on the E2EST task. Experimental results on the MuST-C speech translation benchmark demonstrate that LST-13B achieves BLEU scores of 30.39/41.55/35.33 on En-De/En-Fr/En-Es language pairs, surpassing previous models and establishing a new state-of-the-art. Additionally, we conduct an in-depth analysis of single-modal model selection and the impact of training strategies, which lays the foundation for future research. We will open up our code and models after review.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Zhang, Hao and Si, Nianwen and Chen, Yaqi and Zhang, Wenlin and Yang, Xukui and Qu, Dan and Jiao, Xiaolin},
	month = oct,
	year = {2023},
	note = {arXiv:2310.02050 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhang et al. - 2023 - Tuning Large language model for End-to-end Speech .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\599TXPF4\\Zhang et al. - 2023 - Tuning Large language model for End-to-end Speech .pdf:application/pdf},
}

@misc{lu_self_2023,
	title = {{SELF}: {Language}-{Driven} {Self}-{Evolution} for {Large} {Language} {Model}},
	shorttitle = {{SELF}},
	url = {http://arxiv.org/abs/2310.00533},
	abstract = {Large Language Models (LLMs) have showcased remarkable versatility across diverse domains. However, the pathway toward autonomous model development, a cornerstone for achieving human-level learning and advancing autonomous AI, remains largely uncharted. Drawing inspiration from the human capability for self-driven learning, characterized by introspection and continuous refinement, we introduce an innovative approach, termed “SELF” (Self-Evolution with Language Feedback). This methodology empowers LLMs to undergo continual selfevolution, thereby augmenting their inherent capabilities. Furthermore, SELF employs language-based feedback as a versatile and comprehensive evaluative tool, pinpointing areas for response refinement and bolstering the stability of selfevolutionary training. Through this approach, we aim to illuminate the prospects of autonomous AI advancement, drawing parallels with the human aptitude for learning and adaptation. Initiating with meta-skill learning, SELF acquires foundational meta-skills with a focus on self-feedback and self-refinement. These meta-skills are critical, guiding the model’s subsequent self-evolution through a cycle of perpetual training with self-curated data, thereby enhancing its intrinsic abilities. Given unlabeled instructions, SELF equips the model with the capability to autonomously generate and interactively refine responses. This synthesized training data is subsequently filtered and utilized for iterative fine-tuning, enhancing the model’s capabilities. Experimental results on representative benchmarks substantiate that SELF can progressively advance its inherent abilities without the requirement of human intervention, thereby indicating a viable pathway for autonomous model evolution. Additionally, SELF can employ online selfrefinement strategy to produce responses of superior quality. In essence, the SELF framework signifies a progressive step towards autonomous LLM development, transforming the LLM from a mere passive recipient of information into an active participant in its own evolution.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Lu, Jianqiao and Zhong, Wanjun and Huang, Wenyong and Wang, Yufei and Mi, Fei and Wang, Baojun and Wang, Weichao and Shang, Lifeng and Liu, Qun},
	month = oct,
	year = {2023},
	note = {arXiv:2310.00533 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: 14 pages, 4 figures, 6 tables. Due to the limitation "The abstract field cannot be longer than 1,920 characters", the abstract appearing here is slightly shorter than that in the PDF file},
	file = {Lu et al. - 2023 - SELF Language-Driven Self-Evolution for Large Lan.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\V64PN2ES\\Lu et al. - 2023 - SELF Language-Driven Self-Evolution for Large Lan.pdf:application/pdf},
}

@misc{hosking_human_2023,
	title = {Human {Feedback} is not {Gold} {Standard}},
	url = {http://arxiv.org/abs/2309.16349},
	abstract = {Human feedback has become the de facto standard for evaluating the performance of Large Language Models, and is increasingly being used as a training objective. However, it is not clear which properties of a generated output this single ‘preference’ score captures. We hypothesise that preference scores are subjective and open to undesirable biases. We critically analyse the use of human feedback for both training and evaluation, to verify whether it fully captures a range of crucial error criteria. We find that while preference scores have fairly good coverage, they under-represent important aspects like factuality. We further hypothesise that both preference scores and error annotation may be affected by confounders, and leverage instruction-tuned models to generate outputs that vary along two possible confounding dimensions: assertiveness and complexity. We find that the assertiveness of an output skews the perceived rate of factuality errors, indicating that human annotations are not a fully reliable evaluation metric or training objective. Finally, we offer preliminary evidence that using human feedback as a training objective disproportionately increases the assertiveness of model outputs. We encourage future work to carefully consider whether preference scores are well aligned with the desired objective.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Hosking, Tom and Blunsom, Phil and Bartolo, Max},
	month = sep,
	year = {2023},
	note = {arXiv:2309.16349 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Hosking et al. - 2023 - Human Feedback is not Gold Standard.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\ITQH3H54\\Hosking et al. - 2023 - Human Feedback is not Gold Standard.pdf:application/pdf},
}

@misc{noauthor_truth_nodate,
	title = {Truth and {Regret}: {Large} {Language} {Models}, the {Quran}, and {Misinformation}},
	shorttitle = {Truth and {Regret}},
	url = {https://www.tandfonline.com/doi/epdf/10.1080/14746700.2023.2255944?needAccess=true},
	language = {en},
	urldate = {2023-11-06},
	note = {ISSN: 1474-6700},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\VBFYUBCA\\14746700.2023.html:text/html},
}

@misc{lu_llama-reviewer_2023,
	title = {{LLaMA}-{Reviewer}: {Advancing} {Code} {Review} {Automation} with {Large} {Language} {Models} through {Parameter}-{Efficient} {Fine}-{Tuning}},
	shorttitle = {{LLaMA}-{Reviewer}},
	url = {http://arxiv.org/abs/2308.11148},
	abstract = {The automation of code review activities, a longstanding pursuit in software engineering, has been primarily addressed by numerous domain-specific pre-trained models. Despite their success, these models frequently demand extensive resources for pre-training from scratch. In contrast, Large Language Models (LLMs) provide an intriguing alternative, given their remarkable capabilities when supplemented with domain-specific knowledge. However, their potential for automating code review tasks remains largely unexplored.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Lu, Junyi and Yu, Lei and Li, Xiaojia and Yang, Li and Zuo, Chun},
	month = sep,
	year = {2023},
	note = {arXiv:2308.11148 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Software Engineering},
	annote = {Comment: Accepted to the 34th IEEE International Symposium on Software Reliability Engineering (ISSRE 2023)},
	file = {Lu et al. - 2023 - LLaMA-Reviewer Advancing Code Review Automation w.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\KNGUQ734\\Lu et al. - 2023 - LLaMA-Reviewer Advancing Code Review Automation w.pdf:application/pdf},
}

@article{wang_multi-ontology_2023,
	title = {Multi-ontology embeddings approach on human-aligned multi-ontologies representation for gene-disease associations prediction},
	volume = {9},
	issn = {24058440},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405844023087108},
	doi = {10.1016/j.heliyon.2023.e21502},
	abstract = {Objectives: Knowledge graphs and ontologies in the biomedical domain provide rich contextual knowledge for a variety of challenges. Employing that for knowledge-driven NLP tasks such as gene-disease association prediction represents a promising way to increase the predictive power of a model.
Methods: We investigated the power of infusing the embedding of two aligned ontologies as prior knowledge to the NLP models. We evaluated the performance of different models on some largescale gene-disease association datasets and compared it with a model without incorporating contextualized knowledge (BERT).
Results: The experiments demonstrated that the knowledge-infused model slightly outperforms BERT by creating a small number of bridges. Thus, indicating that incorporating cross-references across ontologies can enhance the performance of base models without the need for more com­ plex and costly training. However, further research is needed to explore the generalizability of the model. We expected that adding more bridges would bring further improvement based on the trend we observed in the experiments. In addition, the use of state-of-the-art knowledge graph embedding methods on a joint graph from connecting OGG and DOID with bridges also yielded promising results.
Conclusion: Our work shows that allowing language models to leverage structured knowledge from ontologies does come with clear advantages in the performance. Besides, the annotation stage brought out in this paper is constrained in reasonable complexity.},
	language = {en},
	number = {11},
	urldate = {2023-11-06},
	journal = {Heliyon},
	author = {Wang, Yihao and Wegner, Philipp and Domingo-Fernández, Daniel and Tom Kodamullil, Alpha},
	month = nov,
	year = {2023},
	pages = {e21502},
	file = {Wang et al. - 2023 - Multi-ontology embeddings approach on human-aligne.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\YEP7R8Q2\\Wang et al. - 2023 - Multi-ontology embeddings approach on human-aligne.pdf:application/pdf},
}

@misc{zhang_instruction_2023,
	title = {Instruction {Tuning} for {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Instruction {Tuning} for {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2308.10792},
	abstract = {This paper surveys research works in the quickly advancing field of instruction tuning (IT), a crucial technique to enhance the capabilities and controllability of large language models (LLMs). Instruction tuning refers to the process of further training LLMs on a dataset consisting of (INSTRUCTION, OUTPUT) pairs in a supervised fashion, which bridges the gap between the next-word prediction objective of LLMs and the users’ objective of having LLMs adhere to human instructions. In this work, we make a systematic review of the literature, including the general methodology of IT, the construction of IT datasets, the training of IT models, and applications to different modalities, domains and application, along with analysis on aspects that influence the outcome of IT (e.g., generation of instruction outputs, size of the instruction dataset, etc). We also review the potential pitfalls of IT along with criticism against it, along with efforts pointing out current deficiencies of existing strategies and suggest some avenues for fruitful research.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and Wang, Guoyin},
	month = oct,
	year = {2023},
	note = {arXiv:2308.10792 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: A Survey paper, Pre-print},
	file = {Zhang et al. - 2023 - Instruction Tuning for Large Language Models A Su.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\EUUM25DH\\Zhang et al. - 2023 - Instruction Tuning for Large Language Models A Su.pdf:application/pdf},
}

@misc{feng_how_2023,
	title = {How do {Language} {Models} {Bind} {Entities} in {Context}?},
	url = {http://arxiv.org/abs/2310.17191},
	abstract = {To correctly use in-context information, language models (LMs) must bind entities to their attributes. For example, given a context describing a “green square” and a “blue circle”, LMs must bind the shapes to their respective colors. We analyze LM representations and identify the binding ID mechanism: a general mechanism for solving the binding problem, which we observe in every sufficiently large model from the Pythia and LLaMA families. Using causal interventions, we show that LMs’ internal activations represent binding information by attaching binding ID vectors to corresponding entities and attributes. We further show that binding ID vectors form a continuous subspace, in which distances between binding ID vectors reflect their discernability. Overall, our results uncover interpretable strategies in LMs for representing symbolic knowledge in-context, providing a step towards understanding general in-context reasoning in large-scale LMs.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Feng, Jiahai and Steinhardt, Jacob},
	month = oct,
	year = {2023},
	note = {arXiv:2310.17191 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Feng und Steinhardt - 2023 - How do Language Models Bind Entities in Context.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\U2LDMPSN\\Feng und Steinhardt - 2023 - How do Language Models Bind Entities in Context.pdf:application/pdf},
}

@misc{yamada_evaluating_2023,
	title = {Evaluating {Spatial} {Understanding} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2310.14540},
	abstract = {Large language models (LLMs) show remarkable capabilities across a variety of tasks. Despite the models only seeing text in training, several recent studies suggest that LLM representations implicitly capture aspects of the underlying grounded concepts. Here, we explore LLM representations of a particularly salient kind of grounded knowledge — spatial relationships. We design natural-language navigation tasks and evaluate the ability of LLMs, in particular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and reason about spatial structures, and compare these abilities to human performance on the same tasks. These tasks reveal substantial variability in LLM performance across different spatial structures, including square, hexagonal, and triangular grids, rings, and trees. We also discover that, similar to humans, LLMs utilize object names as landmarks for maintaining spatial maps. Finally, in extensive error analysis, we find that LLMs’ mistakes reflect both spatial and non-spatial factors. These findings suggest that LLMs appear to capture certain aspects of spatial structure implicitly, but room for improvement remains.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Yamada, Yutaro and Bao, Yihan and Lampinen, Andrew K. and Kasai, Jungo and Yildirim, Ilker},
	month = oct,
	year = {2023},
	note = {arXiv:2310.14540 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Yamada et al. - 2023 - Evaluating Spatial Understanding of Large Language.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\3ZHX93HB\\Yamada et al. - 2023 - Evaluating Spatial Understanding of Large Language.pdf:application/pdf},
}

@misc{wang_knowledge_2023,
	title = {Knowledge {Editing} for {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Knowledge {Editing} for {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2310.16218},
	abstract = {Large language models (LLMs) have recently transformed both the academic and industrial landscapes due to their remarkable capacity to understand, analyze, and generate texts based on their vast knowledge and reasoning ability. Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model. Therefore, it is imperative to develop effective and efficient techniques to update pre-trained LLMs. Traditional methods encode new knowledge in pre-trained LLMs through direct fine-tuning. However, naively re-training LLMs can be computationally intensive and risks degenerating valuable pre-trained knowledge irrelevant to the update in the model. Recently, Knowledge-based Model Editing (KME) has attracted increasing attention, which aims to precisely modify the LLMs to incorporate specific knowledge, without negatively influencing other irrelevant knowledge. In this survey, we aim to provide a comprehensive and in-depth overview of recent advances in the field of KME. We first introduce a general formulation of KME to encompass different KME strategies. Afterward, we provide an innovative taxonomy of KME techniques based on how the new knowledge is introduced into pre-trained LLMs, and investigate existing KME strategies while analyzing key insights, advantages, and limitations of methods from each category. Moreover, representative metrics, datasets, and applications of KME are introduced accordingly. Finally, we provide an in-depth analysis regarding the practicality and remaining challenges of KME and suggest promising research directions for further advancement in this field.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Wang, Song and Zhu, Yaochen and Liu, Haochen and Zheng, Zaiyi and Chen, Chen and Li, Jundong},
	month = oct,
	year = {2023},
	note = {arXiv:2310.16218 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: 31 pages},
	file = {Wang et al. - 2023 - Knowledge Editing for Large Language Models A Sur.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\YXTKQMJU\\Wang et al. - 2023 - Knowledge Editing for Large Language Models A Sur.pdf:application/pdf},
}

@misc{liu_meaning_2023,
	title = {Meaning {Representations} from {Trajectories} in {Autoregressive} {Models}},
	url = {http://arxiv.org/abs/2310.18348},
	abstract = {We propose to extract meaning representations from autoregressive language models by considering the distribution of all possible trajectories extending an input text. This strategy is prompt-free, does not require fine-tuning, and is applicable to any pre-trained autoregressive model. Moreover, unlike vector-based representations, distribution-based representations can also model asymmetric relations (e.g., direction of logical entailment, hypernym/hyponym relations) by using algebraic operations between likelihood functions. These ideas are grounded in distributional perspectives on semantics and are connected to standard constructions in automata theory, but to our knowledge they have not been applied to modern language models. We empirically show that the representations obtained from large models align well with human annotations, outperform other zero-shot and prompt-free methods on semantic similarity tasks, and can be used to solve more complex entailment and containment tasks that standard embeddings cannot handle. Finally, we extend our method to represent data from different modalities (e.g., image and text) using multimodal autoregressive models.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Liu, Tian Yu and Trager, Matthew and Achille, Alessandro and Perera, Pramuditha and Zancato, Luca and Soatto, Stefano},
	month = nov,
	year = {2023},
	note = {arXiv:2310.18348 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Liu et al. - 2023 - Meaning Representations from Trajectories in Autor.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\48A3M89V\\Liu et al. - 2023 - Meaning Representations from Trajectories in Autor.pdf:application/pdf},
}

@article{ma_ontology-based_2023,
	title = {Ontology-{Based} {BERT} {Model} for {Automated} {Information} {Extraction} from {Geological} {Hazard} {Reports}},
	volume = {34},
	issn = {1867-111X},
	url = {https://doi.org/10.1007/s12583-022-1724-z},
	doi = {10.1007/s12583-022-1724-z},
	abstract = {Geological knowledge can provide support for knowledge discovery, knowledge inference and mineralization predictions of geological big data. Entity identification and relationship extraction from geological data description text are the key links for constructing knowledge graphs. Given the lack of publicly annotated datasets in the geology domain, this paper illustrates the construction process of geological entity datasets, defines the types of entities and interconceptual relationships by using the geological entity concept system, and completes the construction of the geological corpus. To address the shortcomings of existing language models (such as Word2vec and Glove) that cannot solve polysemous words and have a poor ability to fuse contexts, we propose a geological named entity recognition and relationship extraction model jointly with Bidirectional Encoder Representation from Transformers (BERT) pretrained language model. To effectively represent the text features, we construct a BERT- bidirectional gated recurrent unit network (BiGRU)-conditional random field (CRF)-based architecture to extract the named entities and the BERT-BiGRU-Attention-based architecture to extract the entity relations. The results show that the F1-score of the BERT-BiGRU-CRF named entity recognition model is 0.91 and the F1-score of the BERT-BiGRU-Attention relationship extraction model is 0.84, which are significant performance improvements when compared to classic language models (e.g., word2vec and Embedding from Language Models (ELMo)).},
	language = {en},
	number = {5},
	urldate = {2023-11-06},
	journal = {Journal of Earth Science},
	author = {Ma, Kai and Tian, Miao and Tan, Yongjian and Qiu, Qinjun and Xie, Zhong and Huang, Rong},
	month = oct,
	year = {2023},
	keywords = {BERT model, knowledge graph, name entity recognition, ontology, relation extraction},
	pages = {1390--1405},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\4LTMRV2V\\Ma et al. - 2023 - Ontology-Based BERT Model for Automated Informatio.pdf:application/pdf},
}

@misc{lee_knowledge_2023,
	title = {Knowledge {Corpus} {Error} in {Question} {Answering}},
	url = {http://arxiv.org/abs/2310.18076},
	abstract = {Recent works in open-domain question answering (QA) have explored generating context passages from large language models (LLMs), replacing the traditional retrieval step in the QA pipeline. However, it is not well understood why generated passages can be more effective than retrieved ones. This study revisits the conventional formulation of QA and introduces the concept of knowledge corpus error. This error arises when the knowledge corpus used for retrieval is only a subset of the entire string space, potentially excluding more helpful passages that exist outside the corpus. LLMs may mitigate this shortcoming by generating passages in a larger space. We come up with an experiment of paraphrasing human-annotated gold context using LLMs to observe knowledge corpus error empirically. Our results across three QA benchmarks reveal an increased performance (10\% - 13\%) when using paraphrased passage, indicating a signal for the existence of knowledge corpus error. Our code is available at https://github.com/xfactlab/emnlp2023-knowledge-corpus-error},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Lee, Yejoon and Oh, Philhoon and Thorne, James},
	month = oct,
	year = {2023},
	note = {arXiv:2310.18076 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: Findings of EMNLP 2023},
	file = {Lee et al. - 2023 - Knowledge Corpus Error in Question Answering.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\7VF4YMKN\\Lee et al. - 2023 - Knowledge Corpus Error in Question Answering.pdf:application/pdf},
}

@article{lei_creating_nodate,
	title = {Creating a {Dataset} for {High}-{Performance} {Computing} {Code} {Translation} using {LLMs}: {A} {Bridge} {Between} {OpenMP} {Fortran} and {C}++},
	language = {en},
	author = {Lei, Bin and Ding, Caiwen and Chen, Le and Lin, Pei-Hung and Liao, Chunhua},
	file = {Lei et al. - Creating a Dataset for High-Performance Computing .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\MLLC5NT7\\Lei et al. - Creating a Dataset for High-Performance Computing .pdf:application/pdf},
}

@article{wang_chatgpt_2023,
	title = {{ChatGPT}: promise and challenges for deployment in low- and middle-income countries},
	volume = {41},
	issn = {26666065},
	shorttitle = {{ChatGPT}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666606523002237},
	doi = {10.1016/j.lanwpc.2023.100905},
	abstract = {In low- and middle-income countries (LMICs), the ﬁelds of medicine and public health grapple with numerous challenges that continue to hinder patients’ access to healthcare services. ChatGPT, a publicly accessible chatbot, has emerged as a potential tool in aiding public health efforts in LMICs. This viewpoint details the potential beneﬁts of employing ChatGPT in LMICs to improve medicine and public health encompassing a broad spectrum of domains ranging from health literacy, screening, triaging, remote healthcare support, mental health support, multilingual capabilities, healthcare communication and documentation, medical training and education, and support for healthcare professionals. Additionally, we also share potential concerns and limitations associated with the use of ChatGPT and provide a balanced discussion on the opportunities and challenges of using ChatGPT in LMICs.},
	language = {en},
	urldate = {2023-11-06},
	journal = {The Lancet Regional Health - Western Pacific},
	author = {Wang, Xiaofei and Sanders, Hayley M. and Liu, Yuchen and Seang, Kennarey and Tran, Bach Xuan and Atanasov, Atanas G. and Qiu, Yue and Tang, Shenglan and Car, Josip and Wang, Ya Xing and Wong, Tien Yin and Tham, Yih-Chung and Chung, Kevin C.},
	month = dec,
	year = {2023},
	pages = {100905},
	file = {Wang et al. - 2023 - ChatGPT promise and challenges for deployment in .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\RQ35G8M2\\Wang et al. - 2023 - ChatGPT promise and challenges for deployment in .pdf:application/pdf},
}

@article{nicholas_large_nodate,
	title = {Large {Language} {Models} in {Non}-{English} {Content} {Analysis}},
	language = {en},
	author = {Nicholas, Gabriel and Bhatia, Aliya},
	file = {Nicholas und Bhatia - Large Language Models in Non-English Content Analy.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\MBKGQJX8\\Nicholas und Bhatia - Large Language Models in Non-English Content Analy.pdf:application/pdf},
}

@article{schlimbach_picture_nodate,
	title = {A {Picture} is {Worth} a {Thousand} {Words} – {Exploring} {Bias} in {Inclusive} {Chatbots}},
	abstract = {This study examines the impact of different avatar pictures (gender \& disability representation) and gendering on students' perceptions of chatbots in an interaction on learning strategies with 180 students from a German university. In the first experiment, we manipulated the chatbot’s humanoid profile picture based on gender and the representation of a visible handicap (wheelchair). In the second experiment, we varied its language style. Statistical analysis revealed that displaying a physical disability significantly enhanced trust, credibility, and empathy but reduced perceived competence and dominance. Gender-sensitive language improved perceptions of competence, trust, credibility, and empathy, whereas we did not find significant interaction effects between both factors. Our results imply the necessity of a more inclusive design of information systems and highlight designers' responsibility in raising awareness and mitigating unconscious bias, as digital learning (technologies) continue to advance.},
	language = {en},
	author = {Schlimbach, Ricarda and Stoppel, Anika and Lampka, Lucas and Robra-Bissantz, Susanne},
	file = {Schlimbach et al. - A Picture is Worth a Thousand Words – Exploring Bi.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\CMCFMBUM\\Schlimbach et al. - A Picture is Worth a Thousand Words – Exploring Bi.pdf:application/pdf},
}

@inproceedings{demaeght_chatbots_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Chatbots in {Academic} {Advising}: {Evaluating} the {Acceptance} and {Effects} of {Chatbots} in {German} {Student}-{University} {Communication}},
	isbn = {978-3-031-36049-7},
	shorttitle = {Chatbots in {Academic} {Advising}},
	doi = {10.1007/978-3-031-36049-7_2},
	abstract = {In order to attract new students, German universities must provide quick and easy access to relevant information. A chatbot can help increase the efficiency in academic advising for prospective students. In this study we evaluate the acceptance and effects of chatbots in German student-university communication. We conducted a qualitative UX-Study with the chatbot prototype of Offenburg University of Applied Sciences (HSO), in order to determine which features are particularly relevant and which requirements are made by the users. The results show that acceptance increases if the chatbot offers quick and adequate assistance, furthermore, our participants preferred an informal communication style and valued friendly and helpful personality traits for chatbots.},
	language = {en},
	booktitle = {{HCI} in {Business}, {Government} and {Organizations}},
	publisher = {Springer Nature Switzerland},
	author = {Demaeght, Annebeth and Walz, Natalie and Müller, Andrea},
	editor = {Nah, Fiona and Siau, Keng},
	year = {2023},
	keywords = {Academic Advising, Chatbot, Empirical Studies, User Experience},
	pages = {18--29},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\VX6LJTT2\\Demaeght et al. - 2023 - Chatbots in Academic Advising Evaluating the Acce.pdf:application/pdf},
}

@article{kasal_safer_nodate,
	title = {Safer {Internet} {Chatbot}},
	journal = {Logic and Computation},
	author = {Kasal, Kresimir},
	file = {Kasal - Safer Internet Chatbot.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\SUT285FV\\Kasal - Safer Internet Chatbot.pdf:application/pdf},
}

@article{gain_investigating_nodate,
	title = {Investigating {Effectiveness} of {Multi}-{Encoder} for {Conversational} {Neural} {Machine} {Translation}},
	abstract = {Multilingual chatbots are the need of the hour for modern business. There is increasing demand for such systems all over the world. A multilingual chatbot can help to connect distant parts of the world together, without sharing a common language. We participated in WMT22 Chat Translation Shared Task. In this paper, we report descriptions of methodologies used for participation. We submit outputs from multiencoder based transformer model, where one encoder is for context and another for source utterance. We consider one previous utterance as context. We obtain COMET scores of 0.768 and 0.907 on English-to-German and Germanto-English directions, respectively. We submitted outputs without using context at all, which generated worse results in English-to-German direction. While for German-to-English, the model achieved a lower COMET score but slightly higher chrF and BLEU scores. Further, to understand the effectiveness of the context encoder, we submitted a run after removing the context encoder during testing and we obtain similar results.},
	language = {en},
	author = {Gain, Baban and Appicharla, Ramakrishna and Chennabasavaraj, Soumya and Garera, Nikesh and Ekbal, Asif and Chelliah, Muthusamy},
	file = {Gain et al. - Investigating Effectiveness of Multi-Encoder for C.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\S8ZBTX9Z\\Gain et al. - Investigating Effectiveness of Multi-Encoder for C.pdf:application/pdf},
}

@misc{lermen_lora_2023,
	title = {{LoRA} {Fine}-tuning {Efficiently} {Undoes} {Safety} {Training} in {Llama} 2-{Chat} {70B}},
	url = {http://arxiv.org/abs/2310.20624},
	abstract = {Content Warning: This document contains content that some may find disturbing or offensive, including content that is hateful or violent in nature. AI developers often apply safety alignment procedures to prevent the misuse of their AI systems. For example, before Meta released Llama 2-Chat—a collection of instruction fine-tuned large language models—they invested heavily in safety training, incorporating extensive red-teaming and reinforcement learning from human feedback. However, it remains unclear how well safety training guards against model misuse when attackers have access to model weights. We explore the robustness of safety training in language models by subversively fine-tuning the public weights of Llama 2-Chat. We employ low-rank adaptation (LoRA) as an efficient fine-tuning method. With a budget of less than \$200 per model and using only one GPU, we successfully undo the safety training of Llama 2-Chat models of sizes 7B, 13B, and 70B. Specifically, our fine-tuning technique significantly reduces the rate at which the model refuses to follow harmful instructions. We achieve a refusal rate below 1\% for our 70B Llama 2-Chat model on two refusal benchmarks. Our fine-tuning method retains general performance, which we validate by comparing our fine-tuned models against Llama 2-Chat across two benchmarks. Additionally, we present a selection of harmful outputs produced by our models. While there is considerable uncertainty about the scope of risks from current models, it is likely that future models will have significantly more dangerous capabilities, including the ability to hack into critical infrastructure, create dangerous bio-weapons, or autonomously replicate and adapt to new environments. We show that subversive fine-tuning is practical and effective, and hence argue that evaluating risks from fine-tuning should be a core part of risk assessments for releasing model weights.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Lermen, Simon and Rogers-Smith, Charlie and Ladish, Jeffrey},
	month = oct,
	year = {2023},
	note = {arXiv:2310.20624 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Lermen et al. - 2023 - LoRA Fine-tuning Efficiently Undoes Safety Trainin.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\P69P3VUK\\Lermen et al. - 2023 - LoRA Fine-tuning Efficiently Undoes Safety Trainin.pdf:application/pdf},
}

@misc{gade_badllama_2023,
	title = {{BadLlama}: cheaply removing safety fine-tuning from {Llama} 2-{Chat} {13B}},
	shorttitle = {{BadLlama}},
	url = {http://arxiv.org/abs/2311.00117},
	abstract = {Llama 2-Chat is a collection of large language models that Meta developed and released to the public. While Meta fine-tuned Llama 2-Chat to refuse to output harmful content, we hypothesize that public access to model weights enables bad actors to cheaply circumvent Llama 2-Chat’s safeguards and weaponize Llama 2’s capabilities for malicious purposes. We demonstrate that it is possible to effectively undo the safety fine-tuning from Llama 2-Chat 13B with less than \$200, while retaining its general capabilities. Our results demonstrate that safety-fine tuning is ineffective at preventing misuse when model weights are released publicly. Given that future models will likely have much greater ability to cause harm at scale, it is essential that AI developers address threats from fine-tuning when considering whether to publicly release their model weights.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Gade, Pranav and Lermen, Simon and Rogers-Smith, Charlie and Ladish, Jeffrey},
	month = oct,
	year = {2023},
	note = {arXiv:2311.00117 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Gade et al. - 2023 - BadLlama cheaply removing safety fine-tuning from.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\B8U86KIN\\Gade et al. - 2023 - BadLlama cheaply removing safety fine-tuning from.pdf:application/pdf},
}

@misc{laskar_building_2023,
	title = {Building {Real}-{World} {Meeting} {Summarization} {Systems} using {Large} {Language} {Models}: {A} {Practical} {Perspective}},
	shorttitle = {Building {Real}-{World} {Meeting} {Summarization} {Systems} using {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2310.19233},
	abstract = {This paper studies how to effectively build meeting summarization systems for real-world usage using large language models (LLMs). For this purpose, we conduct an extensive evaluation and comparison of various closed-source and open-source LLMs, namely, GPT-4, GPT3.5, PaLM-2, and LLaMA-2. Our findings reveal that most closed-source LLMs are generally better in terms of performance. However, much smaller open-source models like LLaMA2 (7B and 13B) could still achieve performance comparable to the large closed-source models even in zero-shot scenarios. Considering the privacy concerns of closed-source models for only being accessible via API, alongside the high cost associated with using fine-tuned versions of the closed-source models, the opensource models that can achieve competitive performance are more advantageous for industrial use. Balancing performance with associated costs and privacy concerns, the LLaMA-2-7B model looks more promising for industrial usage. In sum, this paper offers practical insights on using LLMs for real-world business meeting summarization, shedding light on the trade-offs between performance and cost.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Laskar, Md Tahmid Rahman and Fu, Xue-Yong and Chen, Cheng and TN, Shashi Bhushan},
	month = oct,
	year = {2023},
	note = {arXiv:2310.19233 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: EMNLP 2023 Industry Track},
	file = {Laskar et al. - 2023 - Building Real-World Meeting Summarization Systems .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\I2GQLKFZ\\Laskar et al. - 2023 - Building Real-World Meeting Summarization Systems .pdf:application/pdf},
}

@misc{varshney_accelerating_2023,
	title = {Accelerating {LLM} {Inference} by {Enabling} {Intermediate} {Layer} {Decoding}},
	url = {http://arxiv.org/abs/2310.18581},
	abstract = {Large Language Models (LLMs) have achieved remarkable performance across a wide variety of natural language tasks; however, their large size makes their inference slow and computationally expensive which poses a practical challenge for resource constrained real-world applications. Focusing on this problem, we propose to instruction tune LLMs in a way that enables intermediate layer decoding for efficiently generating text, but importantly without compromising the quality of the generation. Specifically, we instruction tune LLMs with additional explicit Losses from the InTermediate layErs (LITE) and show that it enables these layers to acquire ‘good’ generation ability without affecting the generation ability of the final layer. We perform ‘dynamic confidence-based early exiting’ at token level from the intermediate layers which improves the efficiency of inference while maintaining the generation quality. We conduct comprehensive experiments by instruction tuning LLaMA-2 models on the widely used Alpaca dataset and holistically evaluate on four different human-instruction test sets: Vicuna, WizardLM, Koala, and Self-Instruct. We show that dynamic early exiting achieves consistent and considerable cost improvements (37.86\% on average) while maintaining the generation quality of the responses. We further conduct a thorough analysis of the results over several important aspects, such as comparing the semantic similarity of the outputs and dissecting the efficiency improvements by comparing the number of tokens generated in the output. In summary, our work contributes to improving the efficiency of LLM inference while maintaining the generation quality, a crucial step en route to enabling their widespread adoption.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Varshney, Neeraj and Chatterjee, Agneet and Parmar, Mihir and Baral, Chitta},
	month = oct,
	year = {2023},
	note = {arXiv:2310.18581 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Varshney et al. - 2023 - Accelerating LLM Inference by Enabling Intermediat.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\S3CC7S5U\\Varshney et al. - 2023 - Accelerating LLM Inference by Enabling Intermediat.pdf:application/pdf},
}

@misc{shao_prompt-ner_2023,
	title = {Prompt-{NER}: {Zero}-shot {Named} {Entity} {Recognition} in {Astronomy} {Literature} via {Large} {Language} {Models}},
	shorttitle = {Prompt-{NER}},
	url = {http://arxiv.org/abs/2310.17892},
	abstract = {This study delves into the application of Large Language Models (LLMs) for Named Entity Recognition (NER) tasks in the field of astronomy literature. To enhance the zero-shot recognition capabilities of LLMs for astronomical named entities, we propose a strategy called Prompt-NER. Prompt-NER includes five prompt elements: Task Descriptions, Entity Definitions, Task Emphasis, Task Examples, and Second Conversation. To assess the effectiveness of the Prompt-NER strategy, we utilize three representative LLMs (Claude-2, GPT-3.5, and LLaMA-2-70b) to identify telescope and celestial object named entities in astronomical literature. Our experiments are conducted based on two distinct datasets. The first dataset comprises 30 original PDF documents, which we split into paragraphs in sequential order, resulting in a second dataset consisting of 30 paragraph collections. Additionally, we incorporate 30 astronomical telegrams to diversify our experiments and assess the performance of LLMs based on PromptNER on concise, complete texts. Our experimental results indicate that the Prompt-NER strategy enables LLMs to effectively accomplish NER tasks in the field of astronomy, even without prior astronomical knowledge during training. We carefully analyze the experimental results, including the mechanism of different prompt elements and the influence of different features of long and short texts on their respective experimental results. This research provides experience for zero-shot NER tasks in astronomical literature and suggests future work in this area.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Shao, Wujun and Hu, Yaohua and Ji, Pengli and Yan, Xiaoran and Fan, Dongwei and Zhang, Rui},
	month = oct,
	year = {2023},
	note = {arXiv:2310.17892 [astro-ph]},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	file = {Shao et al. - 2023 - Prompt-NER Zero-shot Named Entity Recognition in .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\C9W9MVY4\\Shao et al. - 2023 - Prompt-NER Zero-shot Named Entity Recognition in .pdf:application/pdf},
}

@article{xie_self-evaluation_nodate,
	title = {Self-{Evaluation} {Guided} {Beam} {Search} for {Reasoning}},
	abstract = {Breaking down a problem into intermediate steps has demonstrated impressive performance in Large Language Model (LLM) reasoning. However, the growth of the reasoning chain introduces uncertainty and error accumulation, making it challenging to elicit accurate final results. To tackle this challenge of uncertainty in multi-step reasoning, we introduce a stepwise self-evaluation mechanism to guide and calibrate the reasoning process of LLMs. We propose a decoding algorithm integrating the self-evaluation guidance via stochastic beam search. The selfevaluation guidance serves as a better-calibrated automatic criterion, facilitating an efficient search in the reasoning space and resulting in superior prediction quality. Stochastic beam search balances exploitation and exploration of the search space with temperature-controlled randomness. Our approach surpasses the corresponding Codex-backboned baselines in few-shot accuracy by 6.34\%, 9.56\%, and 5.46\% on the GSM8K, AQuA, and StrategyQA benchmarks, respectively. Experiment results with Llama-2 on arithmetic reasoning demonstrate the efficiency of our method in outperforming the baseline methods with comparable computational budgets. Further analysis in multi-step reasoning finds our self-evaluation guidance pinpoints logic failures and leads to higher consistency and robustness. Our code is publicly available at https://guideddecoding.github.io/.},
	language = {en},
	author = {Xie, Yuxi and Kawaguchi, Kenji and Zhao, Yiran and Zhao, James Xu and Kan, Min-Yen and He, Junxian and Xie, Michael Qizhe},
	file = {Xie et al. - Self-Evaluation Guided Beam Search for Reasoning.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\QVNMBHST\\Xie et al. - Self-Evaluation Guided Beam Search for Reasoning.pdf:application/pdf},
}

@misc{saha_branch-solve-merge_2023,
	title = {Branch-{Solve}-{Merge} {Improves} {Large} {Language} {Model} {Evaluation} and {Generation}},
	url = {http://arxiv.org/abs/2310.15123},
	abstract = {Large Language Models (LLMs) are frequently used for multi-faceted language generation and evaluation tasks that involve satisfying intricate user constraints or taking into account multiple aspects and criteria. However, their performance can fall short, due to the model’s lack of coherence and inability to plan and decompose the problem. We propose BRANCH-SOLVE-MERGE (BSM), a Large Language Model program (Schlag et al., 2023) for tackling such challenging natural language tasks. It consists of branch, solve, and merge modules that are parameterized with specific prompts to the base LLM. These three modules plan a decomposition of the task into multiple parallel sub-tasks, independently solve them, and fuse the solutions to the sub-tasks. We apply our method to the tasks of LLM response evaluation and constrained text generation and evaluate its effectiveness with multiple LLMs, including Vicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness and consistency for each LLM by enhancing human-LLM agreement by up to 26\%, reducing length and pairwise position biases by up to 50\%, and allowing LLaMA-2-chat to match or outperform GPT-4 on most domains. On the constraint story generation task, BSM improves the coherence of the stories while also improving constraint satisfaction by 12\%.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Saha, Swarnadeep and Levy, Omer and Celikyilmaz, Asli and Bansal, Mohit and Weston, Jason and Li, Xian},
	month = oct,
	year = {2023},
	note = {arXiv:2310.15123 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: 22 pages, 7 figures, 10 tables},
	file = {Saha et al. - 2023 - Branch-Solve-Merge Improves Large Language Model E.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\Z7G2E428\\Saha et al. - 2023 - Branch-Solve-Merge Improves Large Language Model E.pdf:application/pdf},
}

@misc{bommasani_foundation_2023,
	title = {The {Foundation} {Model} {Transparency} {Index}},
	url = {http://arxiv.org/abs/2310.12941},
	abstract = {Foundation models have rapidly permeated society, catalyzing a wave of generative AI applications spanning enterprise and consumer-facing contexts. While the societal impact of foundation models is growing, transparency is on the decline, mirroring the opacity that has plagued past digital technologies (e.g. social media). Reversing this trend is essential: transparency is a vital precondition for public accountability, scientific innovation, and effective governance. To assess the transparency of the foundation model ecosystem and help improve transparency over time, we introduce the Foundation Model Transparency Index. The Foundation Model Transparency Index specifies 100 fine-grained indicators that comprehensively codify transparency for foundation models, spanning the upstream resources used to build a foundation model (e.g data, labor, compute), details about the model itself (e.g. size, capabilities, risks), and the downstream use (e.g. distribution channels, usage policies, affected geographies). We score 10 major foundation model developers (e.g. OpenAI, Google, Meta) against the 100 indicators to assess their transparency. To facilitate and standardize assessment, we score developers in relation to their practices for their flagship foundation model (e.g. GPT-4 for OpenAI, PaLM 2 for Google, Llama 2 for Meta). We present 10 top-level findings about the foundation model ecosystem: for example, no developer currently discloses significant information about the downstream impact of its flagship model, such as the number of users, affected market sectors, or how users can seek redress for harm. Overall, the Foundation Model Transparency Index establishes the level of transparency today to drive progress on foundation model governance via industry standards and regulatory intervention.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Bommasani, Rishi and Klyman, Kevin and Longpre, Shayne and Kapoor, Sayash and Maslej, Nestor and Xiong, Betty and Zhang, Daniel and Liang, Percy},
	month = oct,
	year = {2023},
	note = {arXiv:2310.12941 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Authored by the Center for Research on Foundation Models (CRFM) at the Stanford Institute for Human-Centered Artificial Intelligence (HAI). Project page: https://crfm.stanford.edu/fmti},
	file = {Bommasani et al. - 2023 - The Foundation Model Transparency Index.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\UUD92AXH\\Bommasani et al. - 2023 - The Foundation Model Transparency Index.pdf:application/pdf},
}

@article{pillai_accuracy_2023,
	title = {Accuracy of generative artificial intelligence models in differential diagnoses of familial {Mediterranean} fever and deficiency of {Interleukin}-1 receptor antagonist},
	volume = {7},
	issn = {25899090},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2589909023000266},
	doi = {10.1016/j.jtauto.2023.100213},
	abstract = {With the increasing development of artificial intelligence, large language models (LLMs) have been utilized to solve problems in natural language processing tasks. More recently, LLMs have shown unique potential in numerous applications within medicine but have been particularly investigated for their ability in clinical reasoning. Although the diagnostic accuracy of LLMs in forming differential diagnoses has been reviewed in general internal medicine applications, much is unknown in autoinflammatory disorders. From the nature of autoinflammatory diseases, forming a differential diagnosis is challenging due to the overlapping symptoms between disorders and even more difficult without genetic screening. In this work, the diagnostic accuracy of the Generative Pre-Trained Transformer Model-4 (GPT-4), GPT-3.5, and Large Language Model Meta AI (LLaMa) were evaluated in clinical vignettes of Deficiency of Interleukin-1 Receptor Antagonist (DIRA) and Familial Mediterranean Fever (FMF). We then compared these models to a control group including one internal medicine physician. It was found that GPT-4 did not significantly differ in correctly identifying DIRA and FMF patients compared to the internist. However, the physician maintained a significantly higher accuracy than GPT-3.5 and LLaMa 2 for either disease. Overall, we explore and discuss the unique potential of LLMs in diagnostics for autoimmune diseases.},
	language = {en},
	urldate = {2023-11-06},
	journal = {Journal of Translational Autoimmunity},
	author = {Pillai, Joshua and Pillai, Kathryn},
	month = dec,
	year = {2023},
	pages = {100213},
	file = {Pillai und Pillai - 2023 - Accuracy of generative artificial intelligence mod.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\6E7FGDBI\\Pillai und Pillai - 2023 - Accuracy of generative artificial intelligence mod.pdf:application/pdf},
}

@misc{sclar_quantifying_2023,
	title = {Quantifying {Language} {Models}' {Sensitivity} to {Spurious} {Features} in {Prompt} {Design} or: {How} {I} learned to start worrying about prompt formatting},
	shorttitle = {Quantifying {Language} {Models}' {Sensitivity} to {Spurious} {Features} in {Prompt} {Design} or},
	url = {http://arxiv.org/abs/2310.11324},
	abstract = {As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose FORMATSPREAD, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights1. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Sclar, Melanie and Choi, Yejin and Tsvetkov, Yulia and Suhr, Alane},
	month = oct,
	year = {2023},
	note = {arXiv:2310.11324 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Sclar et al. - 2023 - Quantifying Language Models' Sensitivity to Spurio.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\PR4XEBU7\\Sclar et al. - 2023 - Quantifying Language Models' Sensitivity to Spurio.pdf:application/pdf},
}

@misc{silva_gpt-4_2023,
	title = {{GPT}-4 as an {Agronomist} {Assistant}? {Answering} {Agriculture} {Exams} {Using} {Large} {Language} {Models}},
	shorttitle = {{GPT}-4 as an {Agronomist} {Assistant}?},
	url = {http://arxiv.org/abs/2310.06225},
	abstract = {Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including healthcare and finance. For some tasks that require intelligence, LLMs achieve similar or better performance than trained human beings, therefore it is reasonable to employ human exams (e.g., certification tests) to assess the performance of language models. In this study, we present a comprehensive evaluation of popular LLMs, such as Llama 2, GPT-3.5 and GPT-4, on their ability to answer agriculture-related questions. In our evaluation, we also employ RAG (Retrieval-Augmented Generation) and ER (Ensemble Refinement) techniques, which combine information retrieval, generation capabilities, and prompting strategies to improve the models’ performance. To demonstrate the capabilities of LLMs, we selected agriculture exams and benchmark datasets from three of the largest agriculture producer countries: Brazil, India, and the USA. Our analysis highlights GPT-4’s ability to achieve a passing score on exams to earn credits for renewing agronomist certifications, answering 93\% of the questions correctly and outperforming earlier general-purpose models (GPT-3.5), which achieved 88\% accuracy. On one of our evaluation datasets that had published student scores, GPT-4 obtained the highest performance when compared to human subjects. This performance suggests that GPT-4 could potentially pass on major graduate education admission tests or even earn credits for renewing agronomy certificates. We also explore the models’ capacity to address general agriculture-related questions and generate crop management guidelines for Brazilian and Indian farmers, utilizing robust datasets from the Brazilian Agency of Agriculture (Embrapa) and graduate program exams from India. The results suggest that GPT-4, ER, and RAG can contribute meaningfully to agricultural education, assessment, and crop management practice, offering valuable insights to farmers and agricultural professionals from Brazil, India, and the USA. Implications of these findings are discussed in terms of the potential uses of GPT-4, ER, and RAG in agricultural education, assessment, and practice. We emphasize the importance of addressing challenges related to accuracy and safety while harnessing the power of LLMs effectively and responsibly in the agriculture domain.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Silva, Bruno and Nunes, Leonardo and Estevão, Roberto and Aski, Vijay and Chandra, Ranveer},
	month = oct,
	year = {2023},
	note = {arXiv:2310.06225 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Silva et al. - 2023 - GPT-4 as an Agronomist Assistant Answering Agricu.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\MB95RNIE\\Silva et al. - 2023 - GPT-4 as an Agronomist Assistant Answering Agricu.pdf:application/pdf},
}

@misc{deb_fill_2023,
	title = {Fill in the {Blank}: {Exploring} and {Enhancing} {LLM} {Capabilities} for {Backward} {Reasoning} in {Math} {Word} {Problems}},
	shorttitle = {Fill in the {Blank}},
	url = {http://arxiv.org/abs/2310.01991},
	abstract = {While forward reasoning (i.e., find the answer given the question) has been explored extensively in the recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information? In this paper, we formally define the backward reasoning task on math word problems and modify three datasets to evaluate this task: GSM8k, SVAMP and MultiArith. Our findings show a significant drop in the accuracy of models on backward reasoning compared to forward reasoning across four SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Utilizing the specific format of this task, we propose three novel techniques that improve performance: Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over these base methods aided by a verifier to further boost the accuracy by a significant margin. Extensive experimentation demonstrates that our techniques successively improve the performance of LLMs on the backward reasoning task, with the final ensemble-based method resulting in a substantial performance gain compared to the raw LLMs with standard prompting techniques such as chain-of-thought.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Deb, Aniruddha and Oza, Neeva and Singla, Sarthak and Khandelwal, Dinesh and Garg, Dinesh and Singla, Parag},
	month = oct,
	year = {2023},
	note = {arXiv:2310.01991 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, I.2.3},
	annote = {Comment: 10 pages, 4 figures},
	file = {Deb et al. - 2023 - Fill in the Blank Exploring and Enhancing LLM Cap.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\HSLKEH5Z\\Deb et al. - 2023 - Fill in the Blank Exploring and Enhancing LLM Cap.pdf:application/pdf},
}

@misc{gurnee_language_2023,
	title = {Language {Models} {Represent} {Space} and {Time}},
	url = {http://arxiv.org/abs/2310.02207},
	abstract = {The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process—a world model. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual “space neurons” and “time neurons” that reliably encode spatial and temporal coordinates. Our analysis demonstrates that modern LLMs acquire structured knowledge about fundamental dimensions such as space and time, supporting the view that they learn not merely superficial statistics, but literal world models.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Gurnee, Wes and Tegmark, Max},
	month = oct,
	year = {2023},
	note = {arXiv:2310.02207 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Gurnee und Tegmark - 2023 - Language Models Represent Space and Time.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\UKQTNETY\\Gurnee und Tegmark - 2023 - Language Models Represent Space and Time.pdf:application/pdf},
}

@misc{li_label_2023,
	title = {Label {Supervised} {LLaMA} {Finetuning}},
	url = {http://arxiv.org/abs/2310.01208},
	abstract = {The recent success of Large Language Models (LLMs) has gained significant attention in both academia and industry. Substantial efforts have been made to enhance the zero- and few-shot generalization capabilities of open-source LLMs through finetuning. Currently, the prevailing approach is instruction-tuning, which trains LLMs to complete real-world tasks by generating responses guided by natural language instructions. It is worth noticing that such an approach may underperform in sequence and token classification tasks. Unlike text generation tasks, classification tasks have a limited label space, where precise label prediction is more appreciated than generating diverse and human-like responses. Prior research has unveiled that instruction-tuned LLMs cannot outperform BERT, prompting us to explore the potential of leveraging latent representations from LLMs for supervised label prediction. In this paper, we introduce a label-supervised adaptation for LLMs, which aims to finetuning the model with discriminant labels. We evaluate this approach with Label Supervised LLaMA (LS-LLaMA), based on LLaMA-2-7B, a relatively small-scale LLM, and can be finetuned on a single GeForce RTX4090 GPU. We extract latent representations from the final LLaMA layer and project them into the label space to compute the cross-entropy loss. The model is finetuned by Low-Rank Adaptation (LoRA) to minimize this loss. Remarkably, without intricate prompt engineering or external knowledge, LS-LLaMA substantially outperforms LLMs ten times its size in scale and demonstrates consistent improvements compared to robust baselines like BERT-Large and RoBERTa-Large in text classification. Moreover, by removing the causal mask from decoders, LS-unLLaMA achieves the state-of-the-art performance in named entity recognition (NER). Our work will shed light on a novel approach to adapting LLMs for various downstream tasks.},
	language = {en},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Li, Zongxi and Li, Xianming and Liu, Yuzhang and Xie, Haoran and Li, Jing and Wang, Fu-lee and Li, Qing and Zhong, Xiaoqin},
	month = oct,
	year = {2023},
	note = {arXiv:2310.01208 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Li et al. - 2023 - Label Supervised LLaMA Finetuning.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\NSKVXGW3\\Li et al. - 2023 - Label Supervised LLaMA Finetuning.pdf:application/pdf},
}

@misc{touvron_llama_2023,
	title = {{LLaMA}: {Open} and {Efficient} {Foundation} {Language} {Models}},
	shorttitle = {{LLaMA}},
	url = {http://arxiv.org/abs/2302.13971},
	abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community1.},
	language = {en},
	urldate = {2023-11-07},
	publisher = {arXiv},
	author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13971 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Touvron et al. - 2023 - LLaMA Open and Efficient Foundation Language Mode.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\26QCW4JW\\Touvron et al. - 2023 - LLaMA Open and Efficient Foundation Language Mode.pdf:application/pdf},
}

@misc{guo_continuous_2023,
	title = {Continuous {Training} and {Fine}-tuning for {Domain}-{Specific} {Language} {Models} in {Medical} {Question} {Answering}},
	url = {http://arxiv.org/abs/2311.00204},
	abstract = {Large language models exhibit promising general capabilities but often lack specialized knowledge for domain-specific tasks. Developing domain experts from a base model enables a range of applications without prohibitive training costs. This work demonstrates a method using continuous training and instruction fine-tuning to rapidly adapt Llama 2 base models to the Chinese medical domain. We first conduct continuous training on 1B tokens from Chinese medical references to teach relevant vocabulary and knowledge. The models are then fine-tuned on 54K examples sourced from the Chinese National Medical Licensing Examination. Experiments on Chinese medical data confirm the effectiveness of this approach, producing a model comparable to GPT-3.5-turbo while using way less computational resource. The resulting domain-specific model could be useful for various Chinese medical applications. More broadly, this provides a template for domainspecific training of large language models in areas where pre-trained models lack the required expertise, such as law, science, and engineering.},
	language = {en},
	urldate = {2023-11-07},
	publisher = {arXiv},
	author = {Guo, Zhen and Hua, Yining},
	month = oct,
	year = {2023},
	note = {arXiv:2311.00204 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Guo und Hua - 2023 - Continuous Training and Fine-tuning for Domain-Spe.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\AP9SYGR9\\Guo und Hua - 2023 - Continuous Training and Fine-tuning for Domain-Spe.pdf:application/pdf},
}

@misc{touvron_llama_2023-1,
	title = {Llama 2: {Open} {Foundation} and {Fine}-{Tuned} {Chat} {Models}},
	shorttitle = {Llama 2},
	url = {http://arxiv.org/abs/2307.09288},
	abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
	language = {en},
	urldate = {2023-11-20},
	publisher = {arXiv},
	author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
	month = jul,
	year = {2023},
	note = {arXiv:2307.09288 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\GH6BT4NP\\Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf:application/pdf},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be ﬁnetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciﬁc architecture modiﬁcations.},
	language = {en},
	urldate = {2023-11-20},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\EXMSSDBP\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf},
}

@misc{manerba_social_2023,
	title = {Social {Bias} {Probing}: {Fairness} {Benchmarking} for {Language} {Models}},
	shorttitle = {Social {Bias} {Probing}},
	url = {http://arxiv.org/abs/2311.09090},
	abstract = {Large language models have been shown to encode a variety of social biases, which carries the risk of downstream harms. While the impact of these biases has been recognized, prior methods for bias evaluation have been limited to binary association tests on small datasets, offering a constrained view of the nature of societal biases within language models. In this paper, we propose an original framework for probing language models for societal biases. We collect a probing dataset to analyze language models’ general associations, as well as along the axes of societal categories, identities, and stereotypes. To this end, we leverage a novel perplexity-based fairness score. We curate a large-scale benchmarking dataset addressing drawbacks and limitations of existing fairness collections, expanding to a variety of different identities and stereotypes. When comparing our methodology with prior work, we demonstrate that biases within language models are more nuanced than previously acknowledged. In agreement with recent findings, we find that larger model variants exhibit a higher degree of bias. Moreover, we expose how identities expressing different religions lead to the most pronounced disparate treatments across all models.},
	language = {en},
	urldate = {2023-11-22},
	publisher = {arXiv},
	author = {Manerba, Marta Marchiori and Stańczak, Karolina and Guidotti, Riccardo and Augenstein, Isabelle},
	month = nov,
	year = {2023},
	note = {arXiv:2311.09090 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Manerba et al. - 2023 - Social Bias Probing Fairness Benchmarking for Lan.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\BHU3GEX4\\Manerba et al. - 2023 - Social Bias Probing Fairness Benchmarking for Lan.pdf:application/pdf},
}

@misc{feng_trends_2023,
	title = {Trends in {Integration} of {Knowledge} and {Large} {Language} {Models}: {A} {Survey} and {Taxonomy} of {Methods}, {Benchmarks}, and {Applications}},
	shorttitle = {Trends in {Integration} of {Knowledge} and {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2311.05876},
	abstract = {Large language models (LLMs) exhibit superior performance on various natural language tasks, but they are susceptible to issues stemming from outdated data and domain-specific limitations. In order to address these challenges, researchers have pursued two primary strategies, knowledge editing and retrieval augmentation, to enhance LLMs by incorporating external information from different aspects. Nevertheless, there is still a notable absence of a comprehensive survey. In this paper, we propose a review to discuss the trends in integration of knowledge and large language models, including taxonomy of methods, benchmarks, and applications. In addition, we conduct an in-depth analysis of different methods and point out potential research directions in the future. We hope this survey offers the community quick access and a comprehensive overview of this research area, with the intention of inspiring future research endeavors.},
	language = {en},
	urldate = {2023-11-22},
	publisher = {arXiv},
	author = {Feng, Zhangyin and Ma, Weitao and Yu, Weijiang and Huang, Lei and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and liu, Ting},
	month = nov,
	year = {2023},
	note = {arXiv:2311.05876 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Work in progress; 22 pages},
	file = {Feng et al. - 2023 - Trends in Integration of Knowledge and Large Langu.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\7J89IPZZ\\Feng et al. - 2023 - Trends in Integration of Knowledge and Large Langu.pdf:application/pdf},
}

@misc{wagle_empirical_2023,
	title = {Empirical evaluation of {Uncertainty} {Quantification} in {Retrieval}-{Augmented} {Language} {Models} for {Science}},
	url = {http://arxiv.org/abs/2311.09358},
	abstract = {Large language models (LLMs) have shown remarkable achievements in natural language processing tasks, producing high-quality outputs. However, LLMs still exhibit limitations, including the generation of factually incorrect information. In safety-critical applications, it is important to assess the confidence of LLM-generated content to make informed decisions. Retrieval Augmented Language Models (RALMs) is relatively a new area of research in Natural Language Processing (NLP). RALMs offer potential benefits for scientific NLP tasks, as retrieved documents, can serve as evidence to support model-generated content. This inclusion of evidence enhances trustworthiness, as users can verify and explore the retrieved documents to validate model outputs. Quantifying uncertainty in RALM generations further improves trustworthiness, with retrieved text and confidence scores contributing to a comprehensive and reliable model for scientific applications. However, there is limited to no research on UQ for RALMs, particularly in scientific contexts. This study aims to address this gap by conducting a comprehensive evaluation of UQ in RALMs, focusing on scientific tasks. This research investigates how uncertainty scores vary when scientific knowledge is incorporated as pretraining and retrieval data and explores the relationship between uncertainty scores and the accuracy of model-generated outputs. We observe that an existing RALM finetuned with scientific knowledge as the retrieval data tends to be more confident in generating predictions compared to the model pretrained only with scientific knowledge. We also found that RALMs are overconfident in their predictions, making inaccurate predictions more confidently than accurate ones. Scientific knowledge provided either as pretraining or retrieval corpus does not help alleviate this issue. We released our code, data and dashboards at https://github.com/pnnl/EXPERT2.},
	language = {en},
	urldate = {2023-11-22},
	publisher = {arXiv},
	author = {Wagle, Sridevi and Munikoti, Sai and Acharya, Anurag and Smith, Sara and Horawalavithana, Sameera},
	month = nov,
	year = {2023},
	note = {arXiv:2311.09358 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, I.2.7},
	file = {Wagle et al. - 2023 - Empirical evaluation of Uncertainty Quantification.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\JZQQXSKW\\Wagle et al. - 2023 - Empirical evaluation of Uncertainty Quantification.pdf:application/pdf},
}

@misc{wang_fake_2023,
	title = {Fake {Alignment}: {Are} {LLMs} {Really} {Aligned} {Well}?},
	shorttitle = {Fake {Alignment}},
	url = {http://arxiv.org/abs/2311.05915},
	abstract = {The growing awareness of safety concerns in large language models (LLMs) has sparked considerable interest in the evaluation of safety within current research endeavors. This study investigates an interesting issue pertaining to the evaluation of LLMs, namely the substantial discrepancy in performance between multiplechoice questions and open-ended questions. Inspired by research on jailbreak attack patterns, we argue this is caused by mismatched generalization. That is, the LLM does not have a comprehensive understanding of the complex concept of safety. Instead, it only remembers what to answer for open-ended safety questions, which makes it unable to solve other forms of safety tests. We refer to this phenomenon as fake alignment and construct a comparative benchmark to empirically verify its existence in LLMs. Such fake alignment renders previous evaluation protocols unreliable. To address this, we introduce the Fake alIgNment Evaluation (FINE) framework and two novel metrics—Consistency Score (CS) and Consistent Safety Score (CSS), which jointly assess two complementary forms of evaluation to quantify fake alignment and obtain corrected performance estimates. Applying FINE to 14 widely-used LLMs reveals several models with purported safety are poorly aligned in practice. Our work highlights potential limitations in prevailing alignment methodologies.},
	language = {en},
	urldate = {2023-11-22},
	publisher = {arXiv},
	author = {Wang, Yixu and Teng, Yan and Huang, Kexin and Lyu, Chengqi and Zhang, Songyang and Zhang, Wenwei and Ma, Xingjun and Jiang, Yu-Gang and Qiao, Yu and Wang, Yingchun},
	month = nov,
	year = {2023},
	note = {arXiv:2311.05915 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Wang et al. - 2023 - Fake Alignment Are LLMs Really Aligned Well.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\5KR8PGC3\\Wang et al. - 2023 - Fake Alignment Are LLMs Really Aligned Well.pdf:application/pdf},
}

@article{patil_transformative_2024,
	title = {Transformative {Trends} in {Generative} {AI}: {Harnessing} {Large} {Language} {Models} for {Natural} {Language} {Understanding} and {Generation}},
	volume = {12},
	copyright = {Copyright (c) 2023},
	issn = {2147-6799},
	shorttitle = {Transformative {Trends} in {Generative} {AI}},
	url = {https://www.ijisae.org/index.php/IJISAE/article/view/3794},
	abstract = {The advent of Large Language Models (LLMs) has ushered in transformative trends in the field of Generative Artificial Intelligence (AI). These models, with billions of parameters, have demonstrated unparalleled capabilities in Natural Language Understanding (NLU) and Generation (NLG) tasks. This paper delves into the evolution of generative AI, emphasizing the pivotal role played by LLMs. We explore the mechanisms by which these models have revolutionized NLU and NLG through their capacity to process vast amounts of textual data and generate coherent and contextually relevant text. Additionally, we investigate the techniques and methodologies employed in harnessing the power of LLMs for various applications, ranging from chatbots and content generation to machine translation and sentiment analysis. Furthermore, we examine the challenges associated with LLM-based generative AI, such as ethical concerns, model bias, and the computational resources required for training and fine-tuning. Finally, we offer insights into the future directions of research in this domain, with a focus on optimizing LLMs for broader applications, mitigating their limitations, and ensuring their responsible deployment in real-world scenarios. This paper serves as a comprehensive overview of the current state of generative AI, shedding light on its potential to reshape the way we interact with and generate natural language content.},
	language = {en},
	number = {4s},
	urldate = {2023-11-22},
	journal = {International Journal of Intelligent Systems and Applications in Engineering},
	author = {Patil, Dinesh D. and Dhotre, Dhanraj R. and Gawande, Gopal S. and Mate, Dipali S. and Shelke, Mayura V. and Bhoye, Tejaswini S.},
	year = {2024},
	note = {Number: 4s},
	keywords = {Data Privacy},
	pages = {309--319},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\K69L5MW9\\Patil et al. - 2024 - Transformative Trends in Generative AI Harnessing.pdf:application/pdf},
}

@article{abuyaman_strengths_2023,
	title = {Strengths and {Weaknesses} of {ChatGPT} {Models} for {Scientific} {Writing} {About} {Medical} {Vitamin} {B12}: {Mixed} {Methods} {Study}},
	volume = {7},
	issn = {2561-326X},
	shorttitle = {Strengths and {Weaknesses} of {ChatGPT} {Models} for {Scientific} {Writing} {About} {Medical} {Vitamin} {B12}},
	url = {https://formative.jmir.org/2023/1/e49459},
	doi = {10.2196/49459},
	abstract = {Background: ChatGPT is a large language model developed by OpenAI designed to generate human-like responses to prompts.
Objective: This study aims to evaluate the ability of GPT-4 to generate scientific content and assist in scientific writing using medical vitamin B12 as the topic. Furthermore, the study will compare the performance of GPT-4 to its predecessor, GPT-3.5.
Methods: The study examined responses from GPT-4 and GPT-3.5 to vitamin B12–related prompts, focusing on their quality and characteristics and comparing them to established scientific literature.
Results: The results indicated that GPT-4 can potentially streamline scientific writing through its ability to edit language and write abstracts, keywords, and abbreviation lists. However, significant limitations of ChatGPT were revealed, including its inability to identify and address bias, inability to include recent information, lack of transparency, and inclusion of inaccurate information. Additionally, it cannot check for plagiarism or provide proper references. The accuracy of GPT-4’s answers was found to be superior to GPT-3.5.
Conclusions: ChatGPT can be considered a helpful assistant in the writing process but not a replacement for a scientist’s expertise. Researchers must remain aware of its limitations and use it appropriately. The improvements in consecutive ChatGPT versions suggest the possibility of overcoming some present limitations in the near future.},
	language = {en},
	urldate = {2023-11-22},
	journal = {JMIR Formative Research},
	author = {Abuyaman, Omar},
	month = nov,
	year = {2023},
	pages = {e49459},
	file = {Abuyaman - 2023 - Strengths and Weaknesses of ChatGPT Models for Sci.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\KB62MFT3\\Abuyaman - 2023 - Strengths and Weaknesses of ChatGPT Models for Sci.pdf:application/pdf},
}

@misc{huang_survey_2023,
	title = {A {Survey} on {Hallucination} in {Large} {Language} {Models}: {Principles}, {Taxonomy}, {Challenges}, and {Open} {Questions}},
	shorttitle = {A {Survey} on {Hallucination} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2311.05232},
	abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. Nevertheless, alongside these strides, LLMs exhibit a critical tendency to produce hallucinations, resulting in content that is inconsistent with real-world facts or user inputs. This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in real-world scenarios, which attracts increasing attention to detect and mitigate these hallucinations. In this survey, we aim to provide a thorough and in-depth overview of recent advances in the field of LLM hallucinations. We begin with an innovative taxonomy of LLM hallucinations, then delve into the factors contributing to hallucinations. Subsequently, we present a comprehensive overview of hallucination detection methods and benchmarks. Additionally, representative approaches designed to mitigate hallucinations are introduced accordingly. Finally, we analyze the challenges that highlight the current limitations and formulate open questions, aiming to delineate pathways for future research on hallucinations in LLMs.},
	language = {en},
	urldate = {2023-11-22},
	publisher = {arXiv},
	author = {Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
	month = nov,
	year = {2023},
	note = {arXiv:2311.05232 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Work in progress; 49 pages},
	file = {Huang et al. - 2023 - A Survey on Hallucination in Large Language Models.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\QZGGGEA6\\Huang et al. - 2023 - A Survey on Hallucination in Large Language Models.pdf:application/pdf},
}

@misc{vaswani_attention_2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	language = {en},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = aug,
	year = {2023},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 15 pages, 5 figures},
	file = {Vaswani et al. - 2023 - Attention Is All You Need.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2YXAQBK4\\Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf},
}

@misc{openai_gpt-4_2023,
	title = {{GPT}-4 {Technical} {Report}},
	url = {http://arxiv.org/abs/2303.08774},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformerbased model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	language = {en},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {OpenAI},
	month = mar,
	year = {2023},
	note = {arXiv:2303.08774 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: 100 pages},
	file = {OpenAI - 2023 - GPT-4 Technical Report.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\J2YDSWIK\\OpenAI - 2023 - GPT-4 Technical Report.pdf:application/pdf},
}

@misc{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by ﬁne-tuning on a speciﬁc task. While typically task-agnostic in architecture, this method still requires task-speciﬁc ﬁne-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions – something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art ﬁnetuning approaches. Speciﬁcally, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or ﬁne-tuning, with tasks and few-shot demonstrations speciﬁed purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-ﬂy reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3’s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we ﬁnd that GPT-3 can generate samples of news articles which human evaluators have difﬁculty distinguishing from articles written by humans. We discuss broader societal impacts of this ﬁnding and of GPT-3 in general.},
	language = {en},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = jul,
	year = {2020},
	note = {arXiv:2005.14165 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 40+32 pages},
	file = {Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\3N2IVXR3\\Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf},
}

@article{ye_comprehensive_nodate,
	title = {A {Comprehensive} {Capability} {Analysis} of {GPT}-3 and {GPT}-3.5 {Series} {Models}},
	abstract = {GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on, have gained considerable attention due to their exceptional natural language processing capabilities. However, despite the abundance of research on the difference in capabilities between GPT series models and ﬁne-tuned models, there has been limited attention given to the evolution of GPT series models’ capabilities over time. To conduct a comprehensive analysis of the capabilities of GPT series models, we select six representative models, comprising two GPT-3 series models (i.e., davinci and text-davinci-001) and four GPT-3.5 series models (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and gpt-3.5-turbo). We evaluate their performance on nine natural language understanding (NLU) tasks using 21 datasets. In particular, we compare the performance and robustness of different models for each task under zero-shot and few-shot scenarios. Our extensive experiments reveal that the overall ability of GPT series models on NLU tasks does not increase gradually as the models evolve, especially with the introduction of the RLHF training strategy. While this strategy enhances the models’ ability to generate humanlike responses, it also compromises their ability to solve some tasks. Furthermore, our ﬁndings indicate that there is still room for improvement in areas such as model robustness.},
	language = {en},
	author = {Ye, Junjie and Chen, Xuanting and Xu, Nuo and Liu, Shichun and Cui, Yuhan and Zhou, Zeyang and Gong, Chao and Shen, Yang and Zhou, Jie and Chen, Siming and Gui, Tao and Zhang, Qi and Huang, Xuanjing},
	file = {Ye et al. - A Comprehensive Capability Analysis of GPT-3 and G.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\KBMQSRJ2\\Ye et al. - A Comprehensive Capability Analysis of GPT-3 and G.pdf:application/pdf},
}

@misc{liu_goat_2023,
	title = {Goat: {Fine}-tuned {LLaMA} {Outperforms} {GPT}-4 on {Arithmetic} {Tasks}},
	shorttitle = {Goat},
	url = {http://arxiv.org/abs/2305.14201},
	abstract = {We introduce Goat, a fine-tuned LLaMA model that significantly outperforms GPT-4 on a range of arithmetic tasks. Fine-tuned on a synthetically generated dataset, Goat achieves state-of-the-art performance on BIG-bench arithmetic sub-task. In particular, the zero-shot Goat-7B matches or even surpasses the accuracy achieved by the few-shot PaLM-540B. Surprisingly, Goat can achieve near-perfect accuracy on large-number addition and subtraction through supervised fine-tuning only, which is almost impossible with previous pretrained language models, such as Bloom, OPT, GPT-NeoX, etc. We attribute Goat's exceptional performance to LLaMA's consistent tokenization of numbers. To tackle more challenging tasks like large-number multiplication and division, we propose an approach that classifies tasks based on their learnability, and subsequently decomposes unlearnable tasks, such as multi-digit multiplication and division, into a series of learnable tasks by leveraging basic arithmetic principles. We thoroughly examine the performance of our model, offering a comprehensive evaluation of the effectiveness of our proposed decomposition steps. Additionally, Goat-7B can be easily trained using LoRA on a 24GB VRAM GPU, facilitating reproducibility for other researchers. We release our model, dataset, and the Python script for dataset generation.},
	language = {en},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {Liu, Tiedong and Low, Bryan Kian Hsiang},
	month = may,
	year = {2023},
	note = {arXiv:2305.14201 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Liu und Low - 2023 - Goat Fine-tuned LLaMA Outperforms GPT-4 on Arithm.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\KEUNAE3A\\Liu und Low - 2023 - Goat Fine-tuned LLaMA Outperforms GPT-4 on Arithm.pdf:application/pdf},
}

@misc{chowdhery_palm_2022,
	title = {{PaLM}: {Scaling} {Language} {Modeling} with {Pathways}},
	shorttitle = {{PaLM}},
	url = {http://arxiv.org/abs/2204.02311},
	abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-speciﬁc training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).},
	language = {en},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
	month = oct,
	year = {2022},
	note = {arXiv:2204.02311 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\HB4KHD58\\Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf:application/pdf},
}

@misc{anil_palm_2023,
	title = {{PaLM} 2 {Technical} {Report}},
	url = {http://arxiv.org/abs/2305.10403},
	abstract = {We introduce PaLM 2, a new state-of-the-art language model that has better multilingual and reasoning capabilities and is more compute-efficient than its predecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture of objectives. Through extensive evaluations on English and multilingual language, and reasoning tasks, we demonstrate that PaLM 2 has significantly improved quality on downstream tasks across different model sizes, while simultaneously exhibiting faster and more efficient inference compared to PaLM. This improved efficiency enables broader deployment while also allowing the model to respond faster, for a more natural pace of interaction. PaLM 2 demonstrates robust reasoning capabilities exemplified by large improvements over PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stable performance on a suite of responsible AI evaluations, and enables inference-time control over toxicity without additional overhead or impact on other capabilities. Overall, PaLM 2 achieves state-of-the-art performance across a diverse set of tasks and capabilities.},
	language = {en},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {Anil, Rohan and Dai, Andrew M. and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and Chu, Eric and Clark, Jonathan H. and Shafey, Laurent El and Huang, Yanping and Meier-Hellstern, Kathy and Mishra, Gaurav and Moreira, Erica and Omernick, Mark and Robinson, Kevin and Ruder, Sebastian and Tay, Yi and Xiao, Kefan and Xu, Yuanzhong and Zhang, Yujing and Abrego, Gustavo Hernandez and Ahn, Junwhan and Austin, Jacob and Barham, Paul and Botha, Jan and Bradbury, James and Brahma, Siddhartha and Brooks, Kevin and Catasta, Michele and Cheng, Yong and Cherry, Colin and Choquette-Choo, Christopher A. and Chowdhery, Aakanksha and Crepy, Clément and Dave, Shachi and Dehghani, Mostafa and Dev, Sunipa and Devlin, Jacob and Díaz, Mark and Du, Nan and Dyer, Ethan and Feinberg, Vlad and Feng, Fangxiaoyu and Fienber, Vlad and Freitag, Markus and Garcia, Xavier and Gehrmann, Sebastian and Gonzalez, Lucas and Gur-Ari, Guy and Hand, Steven and Hashemi, Hadi and Hou, Le and Howland, Joshua and Hu, Andrea and Hui, Jeffrey and Hurwitz, Jeremy and Isard, Michael and Ittycheriah, Abe and Jagielski, Matthew and Jia, Wenhao and Kenealy, Kathleen and Krikun, Maxim and Kudugunta, Sneha and Lan, Chang and Lee, Katherine and Lee, Benjamin and Li, Eric and Li, Music and Li, Wei and Li, YaGuang and Li, Jian and Lim, Hyeontaek and Lin, Hanzhao and Liu, Zhongtao and Liu, Frederick and Maggioni, Marcello and Mahendru, Aroma and Maynez, Joshua and Misra, Vedant and Moussalem, Maysam and Nado, Zachary and Nham, John and Ni, Eric and Nystrom, Andrew and Parrish, Alicia and Pellat, Marie and Polacek, Martin and Polozov, Alex and Pope, Reiner and Qiao, Siyuan and Reif, Emily and Richter, Bryan and Riley, Parker and Ros, Alex Castro and Roy, Aurko and Saeta, Brennan and Samuel, Rajkumar and Shelby, Renee and Slone, Ambrose and Smilkov, Daniel and So, David R. and Sohn, Daniel and Tokumine, Simon and Valter, Dasha and Vasudevan, Vijay and Vodrahalli, Kiran and Wang, Xuezhi and Wang, Pidong and Wang, Zirui and Wang, Tao and Wieting, John and Wu, Yuhuai and Xu, Kelvin and Xu, Yunhan and Xue, Linting and Yin, Pengcheng and Yu, Jiahui and Zhang, Qiao and Zheng, Steven and Zheng, Ce and Zhou, Weikang and Zhou, Denny and Petrov, Slav and Wu, Yonghui},
	month = sep,
	year = {2023},
	note = {arXiv:2305.10403 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Anil et al. - 2023 - PaLM 2 Technical Report.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\J7L8TUJD\\Anil et al. - 2023 - PaLM 2 Technical Report.pdf:application/pdf},
}

@misc{noauthor_notitle_nodate,
}

@misc{noauthor_openai_nodate,
	title = {{OpenAI}},
	url = {https://openai.com/},
	abstract = {Creating safe AGI that benefits all of humanity},
	language = {en-US},
	urldate = {2023-11-23},
}

@article{radford_improving_nodate,
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	language = {en},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	file = {Radford et al. - Improving Language Understanding by Generative Pre.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\BR9B2FAL\\Radford et al. - Improving Language Understanding by Generative Pre.pdf:application/pdf},
}

@article{solaiman_release_nodate,
	title = {Release {Strategies} and the {Social} {Impacts} of {Language} {Models}},
	language = {en},
	author = {Solaiman, Irene and Brundage, Miles and Clark, Jack and Askell, Amanda and Herbert-Voss, Ariel and Wu, Jeff and Radford, Alec and Krueger, Gretchen and Kim, Jong Wook and Kreps, Sarah and McCain, Miles and Newhouse, Alex and Blazakis, Jason and McGuffie, Kris and Wang, Jasmine},
	file = {Solaiman et al. - Release Strategies and the Social Impacts of Langu.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\WPTXPF3R\\Solaiman et al. - Release Strategies and the Social Impacts of Langu.pdf:application/pdf},
}

@article{radford_language_nodate,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts WebText. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
	language = {en},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	file = {Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\VXICR68E\\Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:application/pdf},
}

@article{lan_albert_2020,
	title = {{ALBERT}: {A} {LITE} {BERT} {FOR} {SELF}-{SUPERVISED} {LEARNING} {OF} {LANGUAGE} {REPRESENTATIONS}},
	abstract = {Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameterreduction techniques to lower memory consumption and increase the training speed of BERT (Devlin et al., 2019). Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT.},
	language = {en},
	author = {Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
	year = {2020},
	file = {Lan et al. - 2020 - ALBERT A LITE BERT FOR SELF-SUPERVISED LEARNING O.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\LPM9TB26\\Lan et al. - 2020 - ALBERT A LITE BERT FOR SELF-SUPERVISED LEARNING O.pdf:application/pdf},
}

@inproceedings{lewis_bart_2020,
	address = {Online},
	title = {{BART}: {Denoising} {Sequence}-to-{Sequence} {Pre}-training for {Natural} {Language} {Generation}, {Translation}, and {Comprehension}},
	shorttitle = {{BART}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.703},
	doi = {10.18653/v1/2020.acl-main.703},
	language = {en},
	urldate = {2023-11-27},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
	year = {2020},
	pages = {7871--7880},
	file = {Lewis et al. - 2020 - BART Denoising Sequence-to-Sequence Pre-training .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\HFJHXNZ8\\Lewis et al. - 2020 - BART Denoising Sequence-to-Sequence Pre-training .pdf:application/pdf},
}

@misc{liu_roberta_2019,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
	url = {http://arxiv.org/abs/1907.11692},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	language = {en},
	urldate = {2023-11-27},
	publisher = {arXiv},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
	note = {arXiv:1907.11692 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\IGNL2KYH\\Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf:application/pdf},
}

@article{he_deberta_2021,
	title = {{DEBERTA}: {DECODING}-{ENHANCED} {BERT} {WITH} {DIS}- {ENTANGLED} {ATTENTION}},
	abstract = {Recent progress in pre-trained neural language models has signiﬁcantly improved the performance of many natural language processing (NLP) tasks. In this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled attention) that improves the BERT and RoBERTa models using two novel techniques. The ﬁrst is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively, and the attention weights among words are computed using disentangled matrices on their contents and relative positions, respectively. Second, an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre-training. In addition, a new virtual adversarial training method is used for ﬁne-tuning to improve models’ generalization. We show that these techniques signiﬁcantly improve the efﬁciency of model pre-training and the performance of both natural language understand (NLU) and natural langauge generation (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model trained on half of the training data performs consistently better on a wide range of NLP tasks, achieving improvements on MNLI by +0.9\% (90.2\% vs. 91.1\%), on SQuAD v2.0 by +2.3\% (88.4\% vs. 90.7\%) and RACE by +3.6\% (83.2\% vs. 86.8\%). Notably, we scale up DeBERTa by training a larger version that consists of 48 Transform layers with 1.5 billion parameters. The signiﬁcant performance boost makes the single DeBERTa model surpass the human performance on the SuperGLUE benchmark (Wang et al., 2019a) for the ﬁrst time in terms of macro-average score (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the SuperGLUE leaderboard as of January 6, 2021, outperforming the human baseline by a decent margin (90.3 versus 89.8). The pre-trained DeBERTa models and the source code were released at: https://github.com/microsoft/DeBERTa1.},
	language = {en},
	author = {He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
	year = {2021},
	file = {He et al. - 2021 - DEBERTA DECODING-ENHANCED BERT WITH DIS- ENTANGLE.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\8BIJ59H5\\He et al. - 2021 - DEBERTA DECODING-ENHANCED BERT WITH DIS- ENTANGLE.pdf:application/pdf},
}

@misc{raiaan_review_2023,
	title = {A {Review} on {Large} {Language} {Models}: {Architectures}, {Applications}, {Taxonomies}, {Open} {Issues} and {Challenges}},
	shorttitle = {A {Review} on {Large} {Language} {Models}},
	url = {https://www.techrxiv.org/articles/preprint/A_Review_on_Large_Language_Models_Architectures_Applications_Taxonomies_Open_Issues_and_Challenges/24171183/1},
	doi = {10.36227/techrxiv.24171183.v1},
	abstract = {Large Language Models (LLMs) recently demonstrated extraordinary capability, including natural language processing (NLP), language translation, text generation, question answering, etc. Moreover, LLMs are a new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies for the situation. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a lot of new research on LLMs is coming out quickly, it is getting tough to get an overview of all of them in a short note. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLM training phase. It then provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. It also demonstrated the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. It also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Then it also explores open issues and challenges to deploying LLMs in real-world aspects, including ethical issues, model biases, computing resources, interoperability, contextual constraints, privacy, security, etc. It also discusses methods to improve the robustness and controllability of LLMs. Finally, the study analyses the future of LLM research and issues that need to be overcome to make LLMs more impactful and reliable. However, this review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals. Furthermore, it serves as a valuable reference for future development and application of LLM in numerous practical domains.},
	language = {en},
	urldate = {2023-11-27},
	publisher = {TechRxiv},
	author = {Raiaan, Mohaimenul Azam Khan and Mukta, Md Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
	month = sep,
	year = {2023},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\SJWLSN2I\\Raiaan et al. - 2023 - A Review on Large Language Models Architectures, .pdf:application/pdf},
}

@misc{wang_beyond_2023,
	title = {Beyond {Boundaries}: {A} {Comprehensive} {Survey} of {Transferable} {Attacks} on {AI} {Systems}},
	shorttitle = {Beyond {Boundaries}},
	url = {http://arxiv.org/abs/2311.11796},
	abstract = {Artificial Intelligence (AI) systems such as autonomous vehicles, facial recognition, and speech recognition systems are increasingly integrated into our daily lives. However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, model inversion, and model stealing attacks. In particular, numerous attacks are designed to target a particular model or system, yet their effects can spread to additional targets, referred to as transferable attacks. Although considerable efforts have been directed toward developing transferable attacks, a holistic understanding of the advancements in transferable attacks remains elusive. In this paper, we comprehensively explore learning-based attacks from the perspective of transferability, particularly within the context of cyber-physical security. We delve into different domains – the image, text, graph, audio, and video domains – to highlight the ubiquitous and pervasive nature of transferable attacks. This paper categorizes and reviews the architecture of existing attacks from various viewpoints: data, process, model, and system. We further examine the implications of transferable attacks in practical scenarios such as autonomous driving, speech recognition, and large language models (LLMs). Additionally, we outline the potential research directions to encourage efforts in exploring the landscape of transferable attacks. This survey offers a holistic understanding of the prevailing transferable attacks and their impacts across different domains.},
	language = {en},
	urldate = {2023-11-27},
	publisher = {arXiv},
	author = {Wang, Guangjing and Zhou, Ce and Wang, Yuanda and Chen, Bocheng and Guo, Hanqing and Yan, Qiben},
	month = nov,
	year = {2023},
	note = {arXiv:2311.11796 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition},
	file = {Wang et al. - 2023 - Beyond Boundaries A Comprehensive Survey of Trans.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\XYIK2YX3\\Wang et al. - 2023 - Beyond Boundaries A Comprehensive Survey of Trans.pdf:application/pdf},
}

@misc{xia_principles_2023,
	title = {From {Principles} to {Practice}: {An} {Accountability} {Metrics} {Catalogue} for {Managing} {AI} {Risks}},
	shorttitle = {From {Principles} to {Practice}},
	url = {http://arxiv.org/abs/2311.13158},
	abstract = {Artificial Intelligence (AI), particularly through the advent of large-scale generative AI (GenAI) models such as Large Language Models (LLMs), has become a transformative element in contemporary technology. While these models have unlocked new possibilities, they simultaneously present significant challenges, such as concerns over data privacy and the propensity to generate misleading or fabricated content. Current frameworks for Responsible AI (RAI) often fall short in providing the granular guidance necessary for tangible application, especially for Accountability—a principle that is pivotal for ensuring transparent and auditable decision-making, bolstering public trust, and meeting increasing regulatory expectations. This study bridges the Accountability gap by introducing a comprehensive metrics catalogue, formulated through a systematic multivocal literature review (MLR) that integrates findings from both academic and grey literature. Our catalogue delineates process metrics that underpin procedural integrity, resource metrics that provide necessary tools and frameworks, and product metrics that reflect the outputs of AI systems. This tripartite framework is designed to operationalize Accountability in AI, with a special emphasis on addressing the intricacies of GenAI. The proposed metrics catalogue provides a robust framework for instilling Accountability in AI systems. It offers practical, actionable guidance for organizations, thereby shaping responsible practices in the field.},
	language = {en},
	urldate = {2023-11-28},
	publisher = {arXiv},
	author = {Xia, Boming and Lu, Qinghua and Zhu, Liming and Lee, Sung Une and Liu, Yue and Xing, Zhenchang},
	month = nov,
	year = {2023},
	note = {arXiv:2311.13158 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {Xia et al. - 2023 - From Principles to Practice An Accountability Met.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\V5W6GK8D\\Xia et al. - 2023 - From Principles to Practice An Accountability Met.pdf:application/pdf},
}

@article{gruetzemacher_international_nodate,
	title = {An {International} {Consortium} for {Evaluations} of {Societal}-{Scale} {Risks} from {Advanced} {AI}},
	abstract = {Given rapid progress toward advanced AI and risks from frontier AI systems—advanced AI systems pushing the boundaries of the AI capabilities frontier—the creation and implementation of AI governance and regulatory schemes deserves prioritization and substantial investment. However, the status quo is untenable and, frankly, dangerous. A regulatory gap has permitted AI labs to conduct research, development, and deployment activities with minimal oversight. In response, frontier AI system evaluations have been proposed as a way of assessing risks from the development and deployment of frontier AI systems. Yet, the budding AI risk evaluation ecosystem faces significant coordination challenges, such as limited diversity and independence of evaluators, suboptimal allocation of effort, and perverse incentives. This paper proposes a solution in the form of an international consortium for AI risk evaluations, comprising both AI developers and third-party AI risk evaluators. Such a consortium could play a critical role in international efforts to mitigate societal-scale risks from advanced AI, including in managing responsible scaling policies and coordinated evaluation-based risk response. In this paper, we discuss the current evaluation ecosystem and its shortcomings, propose an international consortium for advanced AI risk evaluations, discuss issues regarding its implementation, discuss lessons that can be learned from previous international institutions and existing proposals for international AI governance institutions, and finally, we recommend concrete steps to advance the establishment of the proposed consortium: solicit feedback from stakeholders, conduct additional research, conduct a workshop(s) for stakeholders, create a final proposal and solicit funding, and create a consortium.},
	language = {en},
	author = {Gruetzemacher, Ross and Chan, Alan and Frazier, Kevin and Manning, Christy and Fox, James and Hernández-Orallo, José and Burden, John and Franklin, Matija and Ghuidhir, Clíodhna Ní and Bailey, Mark and Pilditch, Toby and Eth, Daniel and Campos, Siméon and Kilian, Kyle},
	file = {Gruetzemacher et al. - An International Consortium for Evaluations of Soc.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\7WUWVAJP\\Gruetzemacher et al. - An International Consortium for Evaluations of Soc.pdf:application/pdf},
}

@article{koehn_europarl_nodate,
	title = {Europarl: a parallel corpus for statistical machine translation},
	abstract = {We collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web1. This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation (SMT). We trained SMT systems for 110 language pairs, which reveal interesting clues into the challenges ahead.},
	language = {en},
	author = {Koehn, Philipp},
	file = {Koehn - Europarl a parallel corpus for statistical machin.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\DFX2A5CE\\Koehn - Europarl a parallel corpus for statistical machin.pdf:application/pdf},
}

@misc{noauthor_wikipediahauptseite_2023,
	title = {Wikipedia:{Hauptseite}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	shorttitle = {Wikipedia},
	url = {https://de.wikipedia.org/w/index.php?title=Wikipedia:Hauptseite&oldid=230654295},
	abstract = {Artikel des Tages
Was geschah am …?
In den Nachrichten
Verstorben
Schon gewusst?
Schwesterprojekte},
	language = {de},
	urldate = {2023-11-28},
	journal = {Die freie Enzyklopädie},
	month = feb,
	year = {2023},
	note = {Page Version ID: 230654295},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\RZJTRI9Q\\WikipediaHauptseite.html:text/html},
}

@misc{noauthor_conll2003_2023,
	title = {conll2003 · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/conll2003},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = may,
	year = {2023},
}

@misc{noauthor_wikipedia_2023,
	title = {wikipedia · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/wikipedia},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = jun,
	year = {2023},
}

@misc{noauthor_hugging_2023,
	title = {Hugging {Face} – {The} {AI} community building the future.},
	url = {https://huggingface.co/datasets},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = nov,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\DUDV9F29\\datasets.html:text/html},
}

@inproceedings{leitner_fine-grained_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Fine-{Grained} {Named} {Entity} {Recognition} in {Legal} {Documents}},
	isbn = {978-3-030-33220-4},
	doi = {10.1007/978-3-030-33220-4_20},
	abstract = {This paper describes an approach at Named Entity Recognition (NER) in German language documents from the legal domain. For this purpose, a dataset consisting of German court decisions was developed. The source texts were manually annotated with 19 semantic classes: person, judge, lawyer, country, city, street, landscape, organization, company, institution, court, brand, law, ordinance, European legal norm, regulation, contract, court decision, and legal literature. The dataset consists of approx. 67,000 sentences and contains 54,000 annotated entities. The 19 fine-grained classes were automatically generalised to seven more coarse-grained classes (person, location, organization, legal norm, case-by-case regulation, court decision, and legal literature). Thus, the dataset includes two annotation variants, i.e., coarse- and fine-grained. For the task of NER, Conditional Random Fields (CRFs) and bidirectional Long-Short Term Memory Networks (BiLSTMs) were applied to the dataset as state of the art models. Three different models were developed for each of these two model families and tested with the coarse- and fine-grained annotations. The BiLSTM models achieve the best performance with an 95.46 F\$\$\_1\$\$score for the fine-grained classes and 95.95 for the coarse-grained ones. The CRF models reach a maximum of 93.23 for the fine-grained classes and 93.22 for the coarse-grained ones. The work presented in this paper was carried out under the umbrella of the European project LYNX that develops a semantic platform that enables the development of various document processing and analysis applications for the legal domain.},
	language = {en},
	booktitle = {Semantic {Systems}. {The} {Power} of {AI} and {Knowledge} {Graphs}},
	publisher = {Springer International Publishing},
	author = {Leitner, Elena and Rehm, Georg and Moreno-Schneider, Julian},
	editor = {Acosta, Maribel and Cudré-Mauroux, Philippe and Maleshkova, Maria and Pellegrini, Tassilo and Sack, Harald and Sure-Vetter, York},
	year = {2019},
	keywords = {BiLSTM, CRF, Curation technologies, Language technology, Legal processing, Legal technologies, LT, Named Entity Recognition, Natural Language Processing, NER, NLP},
	pages = {272--287},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\HPUCMYEI\\Leitner et al. - 2019 - Fine-Grained Named Entity Recognition in Legal Doc.pdf:application/pdf},
}

@misc{noauthor_german_legal_entity_recognition_nodate,
	title = {german\_legal\_entity\_recognition · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/german_legal_entity_recognition},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\E36SN7TL\\german_legal_entity_recognition.html:text/html},
}

@misc{noauthor_bigbiomuchmore_2023,
	title = {bigbio/muchmore · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/bigbio/muchmore},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = aug,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\7UCTBYEZ\\muchmore.html:text/html},
}

@misc{noauthor_bigbiobronco_nodate,
	title = {bigbio/bronco · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/bigbio/bronco},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\FNGW75I2\\bronco.html:text/html},
}

@misc{noauthor_dfki-sltmultitacred_nodate,
	title = {{DFKI}-{SLT}/multitacred · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/DFKI-SLT/multitacred},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\Q49ZHUST\\multitacred.html:text/html},
}

@misc{noauthor_ex4cds_2022,
	title = {{Ex4CDS} - {Textual} {Explanations} for {Clinical} {Decision} {Support}},
	copyright = {Apache-2.0},
	url = {https://github.com/DFKI-NLP/Ex4CDS},
	abstract = {The repository for our annotated corpus of textual explanations for clinical decision support.},
	urldate = {2023-11-28},
	publisher = {DFKI-NLP},
	month = nov,
	year = {2022},
	note = {original-date: 2022-04-29T10:59:05Z},
}

@misc{noauthor_wmt16_2023,
	title = {wmt16 · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/wmt16},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = jan,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\XK9SDFXR\\wmt16.html:text/html},
}

@misc{noauthor_facebookflores_2023,
	title = {facebook/flores · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/facebook/flores},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = oct,
	year = {2023},
}

@misc{noauthor_wmt_2022,
	title = {wmt ({WMT}: {Workshop} on {Statistical} {Machine} {Translation})},
	shorttitle = {wmt ({WMT}},
	url = {https://huggingface.co/wmt},
	abstract = {machine translation},
	urldate = {2023-11-28},
	month = dec,
	year = {2022},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\RP94C3ZI\\wmt.html:text/html},
}

@misc{noauthor_wmteuroparl_2023,
	title = {wmt/europarl · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/wmt/europarl},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = nov,
	year = {2023},
}

@misc{noauthor_archimob_nodate,
	title = {{ArchiMob} corpus of spoken {Swiss} {German} {Release} 2 {Notes}},
	url = {http://www.spur.uzh.ch/en/departments/research/textgroup/ArchiMob/ArchiMob_r2_notes.html},
	language = {en},
	urldate = {2023-11-28},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\3R9V5I4E\\ArchiMob_r2_notes.html:text/html},
}

@misc{noauthor_phonetik_nodate,
	title = {Phonetik {BAS}},
	url = {https://www.phonetik.uni-muenchen.de/forschung/Bas/BasPHONSTATeng.html},
	urldate = {2023-11-28},
	file = {Phonetik BAS:C\:\\Users\\bar35643\\Zotero\\storage\\GZUQ3JKJ\\BasPHONSTATeng.html:text/html},
}

@misc{noauthor_juletxaramgsm_nodate,
	title = {juletxara/mgsm · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/juletxara/mgsm/viewer/de},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\L6375F5S\\de.html:text/html},
}

@misc{noauthor_juletxaramgsm_2023,
	title = {juletxara/mgsm · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/juletxara/mgsm},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = sep,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\GXRYSJ8U\\mgsm.html:text/html},
}

@misc{noauthor_helsinki-nlptatoeba_mt_2023,
	title = {Helsinki-{NLP}/tatoeba\_mt · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = jun,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\GZ2ZY5UU\\tatoeba_mt.html:text/html},
}

@article{cattoni_must-c_2021,
	title = {{MuST}-{C}: {A} multilingual corpus for end-to-end speech translation},
	volume = {66},
	issn = {08852308},
	shorttitle = {{MuST}-{C}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0885230820300887},
	doi = {10.1016/j.csl.2020.101155},
	language = {en},
	urldate = {2023-11-28},
	journal = {Computer Speech \& Language},
	author = {Cattoni, Roldano and Di Gangi, Mattia Antonino and Bentivogli, Luisa and Negri, Matteo and Turchi, Marco},
	month = mar,
	year = {2021},
	pages = {101155},
}

@misc{noauthor_covost2_2023,
	title = {covost2 · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/covost2},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = jan,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\R7WXRHSR\\covost2.html:text/html},
}

@misc{noauthor_facebookvoxpopuli_2023,
	title = {facebook/voxpopuli · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/facebook/voxpopuli},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = jul,
	year = {2023},
}

@misc{noauthor_iwslt2017_2023,
	title = {iwslt2017 · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/iwslt2017},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = apr,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\BG8CJL63\\iwslt2017.html:text/html},
}

@misc{noauthor_open_subtitles_2023,
	title = {open\_subtitles · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/open_subtitles},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = jan,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\AAM9W56H\\open_subtitles.html:text/html},
}

@article{borchert_ggponc_nodate,
	title = {{GGPONC} 2.0 - {The} {German} {Clinical} {Guideline} {Corpus} for {Oncology}: {Curation} {Workflow}, {Annotation} {Policy}, {Baseline} {NER} {Taggers}},
	abstract = {Despite remarkable advances in the development of language resources over the recent years, there is still a shortage of annotated, publicly available corpora covering (German) medical language. With the initial release of the German Guideline Program in Oncology NLP Corpus (GGPONC), we have demonstrated how such corpora can be built upon clinical guidelines, a widely available resource in many natural languages with a reasonable coverage of medical terminology. In this work, we describe a major new release for GGPONC. The corpus has been substantially extended in size and re-annotated with a new annotation scheme based on SNOMED CT top level hierarchies, reaching high inter-annotator agreement (γ = .94). Moreover, we annotated elliptical coordinated noun phrases and their resolutions, a common language phenomenon in (not only German) scientiﬁc documents. We also trained BERT-based named entity recognition models on this new data set, which achieve high performance on short, coarse-grained entity spans (F1 = .89), while the rate of boundary errors increases for long entity spans. GGPONC is freely available through a data use agreement. The trained named entity recognition models, as well as the detailed annotation guide, are also made publicly available.},
	language = {en},
	author = {Borchert, Florian and Lohr, Christina and Modersohn, Luise and Witt, Jonas and Langer, Thomas and Follmann, Markus and Gietzelt, Matthias and Arnrich, Bert and Hahn, Udo and Schapranow, Matthieu-P},
	file = {Borchert et al. - GGPONC 2.0 - The German Clinical Guideline Corpus .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\XBIR2YRD\\Borchert et al. - GGPONC 2.0 - The German Clinical Guideline Corpus .pdf:application/pdf},
}

@misc{noauthor_bigbioggponc2_nodate,
	title = {bigbio/ggponc2 · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/bigbio/ggponc2},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\XM6DVKXL\\ggponc2.html:text/html},
}

@misc{reinig_wogli_2023,
	title = {wogli},
	url = {https://github.com/ireinig/wogli},
	abstract = {Repository containing WOGLI datasets},
	urldate = {2023-11-28},
	author = {Reinig, Ines},
	month = jun,
	year = {2023},
	note = {original-date: 2023-03-17T10:28:35Z},
}

@misc{noauthor_xnli_2023,
	title = {xnli · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/xnli},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = mar,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\XTLZ6FPG\\xnli.html:text/html},
}

@misc{noauthor_flores_2023,
	title = {The {FLORES}+ evaluation benchmark for multilingual machine translation},
	copyright = {CC-BY-SA-4.0},
	url = {https://github.com/openlanguagedata/flores},
	abstract = {The FLORES benchmark dataset},
	urldate = {2023-11-28},
	publisher = {openlanguagedata},
	month = nov,
	year = {2023},
	note = {original-date: 2023-10-12T20:11:21Z},
}

@misc{noauthor_wmt19_2023,
	title = {wmt19 · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/wmt19},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = jan,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\SDGCAL2S\\wmt19.html:text/html},
}

@misc{noauthor_europarl_bilingual_2023,
	title = {europarl\_bilingual · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/europarl_bilingual},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = oct,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\WJDGQ54U\\europarl_bilingual.html:text/html},
}

@misc{noauthor_oscar_2023,
	title = {oscar · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/oscar},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = may,
	year = {2023},
}

@misc{noauthor_opus100_2023,
	title = {opus100 · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/opus100},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = aug,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\GSQKR7P9\\opus100.html:text/html},
}

@misc{noauthor_common_voice_2023,
	title = {common\_voice · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/common_voice},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = mar,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\MRLFPVXM\\common_voice.html:text/html},
}

@misc{noauthor_facebookbelebele_2023,
	title = {facebook/belebele · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/facebook/belebele},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = oct,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\NP6MDMI2\\belebele.html:text/html},
}

@misc{noauthor_xtreme_2023,
	title = {xtreme · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/xtreme},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-11-28},
	month = mar,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\DPPC6MRD\\xtreme.html:text/html},
}

@misc{noauthor_europarl_nodate,
	title = {Europarl {Parallel} {Corpus}},
	url = {https://www.statmt.org/europarl/},
	urldate = {2023-11-29},
	file = {Europarl Parallel Corpus:C\:\\Users\\bar35643\\Zotero\\storage\\GLCQQNQR\\europarl.html:text/html},
}

@misc{noauthor_phonetik_nodate-1,
	title = {Phonetik {BAS}},
	url = {https://www.phonetik.uni-muenchen.de/forschung/Bas/BasPHONSTATeng.html},
	urldate = {2023-11-29},
	file = {Phonetik BAS:C\:\\Users\\bar35643\\Zotero\\storage\\YNJBY9VW\\BasPHONSTATeng.html:text/html},
}

@article{schiel_bastat_nodate,
	title = {{BAStat} : {New} {Statistical} {Resources} at the {Bavarian} {Archive} for {Speech} {Signals}},
	abstract = {A new type of language resource ’BAStat’ has been released by the Bavarian Archive for Speech Signals. In contrast to primary resources like speech and text corpora BAStat comprises statistical estimates based on a number of primary resources: ﬁrst and second order occurrence probability of phones, syllables and words, duration statistics, probabilities of pronunciation variants of words and probabilities of context information. Unlike other statistical speech resources BAStat is based solely on recordings of conversational German and therefore models spoken language. It consists of 7-bit ASCII tables and matrices to maximize inter-operability between different platforms and can be downloaded from the BAS web-site. This paper gives a detailed description about the empirical basis, the contained data types, some interesting interpretations and a brief comparison to the text-based statistical resource CELEX.},
	language = {en},
	author = {Schiel, Florian},
	file = {Schiel - BAStat  New Statistical Resources at the Bavarian.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\9YYV85YL\\Schiel - BAStat  New Statistical Resources at the Bavarian.pdf:application/pdf},
}

@misc{noauthor_language-independent_nodate,
	title = {Language-{Independent} {Named} {Entity} {Recognition} ({II})},
	url = {https://www.clips.uantwerpen.be/conll2003/ner/},
	urldate = {2023-12-07},
	file = {Language-Independent Named Entity Recognition (II):C\:\\Users\\bar35643\\Zotero\\storage\\CVHMH768\\ner.html:text/html},
}

@misc{noauthor_papers_nodate,
	title = {Papers with {Code} - {CoNLL} 2003 {Dataset}},
	url = {https://paperswithcode.com/dataset/conll-2003},
	abstract = {CoNLL-2003 is a named entity recognition dataset released as a part of CoNLL-2003 shared task: language-independent named entity recognition.
The data consists of eight files covering two languages: English and German.
For each of the languages there is a training file, a development file, a test file and a large file with unannotated data.

The English data was taken from the Reuters Corpus. This corpus consists of Reuters news stories between August 1996 and August 1997.
For the training and development set, ten days worth of data were taken from the files representing the end of August 1996.
For the test set, the texts were from December 1996. The preprocessed raw data covers the month of September 1996.

The text for the German data was taken from the ECI Multilingual Text Corpus. This corpus consists of texts in many languages. The portion of data that
was used for this task, was extracted from the German newspaper Frankfurter Rundshau. All three of the training, development and test sets were taken
from articles written in one week at the end of August 1992.
The raw data were taken from the months of September to December 1992.

{\textbar} English      data {\textbar} Articles {\textbar} Sentences {\textbar} Tokens  {\textbar} LOC  {\textbar} MISC {\textbar} ORG  {\textbar} PER  {\textbar}
{\textbar}-------------------{\textbar}----------{\textbar}-----------{\textbar}---------{\textbar}------{\textbar}------{\textbar}------{\textbar}------{\textbar}
{\textbar} Training     set  {\textbar} 946      {\textbar} 14,987    {\textbar} 203,621 {\textbar} 7140 {\textbar} 3438 {\textbar} 6321 {\textbar} 6600 {\textbar}
{\textbar} Development  set  {\textbar} 216      {\textbar} 3,466     {\textbar} 51,362  {\textbar} 1837 {\textbar} 922  {\textbar} 1341 {\textbar} 1842 {\textbar}
{\textbar} Test         set  {\textbar} 231      {\textbar} 3,684     {\textbar} 46,435  {\textbar} 1668 {\textbar} 702  {\textbar} 1661 {\textbar} 1617 {\textbar}

Number of articles, sentences, tokens and entities (locations, miscellaneous, organizations, and persons) in English data files.

{\textbar} German       data {\textbar} Articles {\textbar} Sentences {\textbar} Tokens  {\textbar} LOC  {\textbar} MISC {\textbar} ORG  {\textbar} PER  {\textbar}
{\textbar}-------------------{\textbar}----------{\textbar}-----------{\textbar}---------{\textbar}------{\textbar}------{\textbar}------{\textbar}------{\textbar}
{\textbar} Training     set  {\textbar} 553      {\textbar} 12,705    {\textbar} 206,931 {\textbar} 4363 {\textbar} 2288 {\textbar} 2427 {\textbar} 2773 {\textbar}
{\textbar} Development  set  {\textbar} 201      {\textbar} 3,068     {\textbar} 51,444  {\textbar} 1181 {\textbar} 1010 {\textbar} 1241 {\textbar} 1401 {\textbar}
{\textbar} Test         set  {\textbar} 155      {\textbar} 3,160     {\textbar} 51,943  {\textbar} 1035 {\textbar} 670  {\textbar} 773  {\textbar} 1195 {\textbar}

Number of articles, sentences, tokens and entities (locations, miscellaneous, organizations, and persons) in German data files.},
	language = {en},
	urldate = {2023-12-07},
}

@misc{noauthor_googlextreme_s_2022,
	title = {google/xtreme\_s · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/google/xtreme_s},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-12-07},
	month = apr,
	year = {2022},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\IBX4DDXP\\xtreme_s.html:text/html},
}

@misc{noauthor_googlextreme_s_2022-1,
	title = {google/xtreme\_s · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/google/xtreme_s},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-12-07},
	month = apr,
	year = {2022},
}

@article{cattoni_must-c_2021-1,
	title = {{MuST}-{C}: {A} multilingual corpus for end-to-end speech translation},
	volume = {66},
	issn = {08852308},
	shorttitle = {{MuST}-{C}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0885230820300887},
	doi = {10.1016/j.csl.2020.101155},
	language = {en},
	urldate = {2023-12-07},
	journal = {Computer Speech \& Language},
	author = {Cattoni, Roldano and Di Gangi, Mattia Antonino and Bentivogli, Luisa and Negri, Matteo and Turchi, Marco},
	month = mar,
	year = {2021},
	pages = {101155},
}

@misc{noauthor_elenanereissgerman-ler_2022,
	title = {elenanereiss/german-ler · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/elenanereiss/german-ler},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-12-07},
	month = nov,
	year = {2022},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\R3SBTJ77\\german-ler.html:text/html},
}

@misc{noauthor_papers_nodate-1,
	title = {Papers with {Code} - {Tatoeba} {Translation} {Challenge} {Dataset}},
	url = {https://paperswithcode.com/dataset/tatoeba-translation-challenge},
	abstract = {The Tatoeba Translation Challenge is a benchmark for machine translation that provides training and test data for thousands of language pairs covering over 500 languages.

The Tatoeba translation challenge includes shuffled training data taken from OPUS, an open collection of parallel corpora, and test data from Tatoeba, a crowd-sourced collection of user-provided translations in a large number of languages. 

The current release includes over 500GB of compressed data for 2,961 language pairs covering 555 languages. The data sets are released per language pair with the following structure (using deu-eng as an example):
data/deu-eng/
data/deu-eng/train.src.gz
data/deu-eng/train.trg.gz
data/deu-eng/train.id.gz
data/deu-eng/dev.id
data/deu-eng/dev.src
data/deu-eng/dev.trg
data/deu-eng/test.src
data/deu-eng/test.trg
data/deu-eng/test.id},
	language = {en},
	urldate = {2023-12-13},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\96P7IF8T\\tatoeba-translation-challenge.html:text/html},
}

@misc{tiedemann_tatoeba_2020,
	title = {The {Tatoeba} {Translation} {Challenge} -- {Realistic} {Data} {Sets} for {Low} {Resource} and {Multilingual} {MT}},
	url = {http://arxiv.org/abs/2010.06354},
	abstract = {This paper describes the development of a new benchmark for machine translation that provides training and test data for thousands of language pairs covering over 500 languages and tools for creating state-of-the-art translation models from that collection. The main goal is to trigger the development of open translation tools and models with a much broader coverage of the World’s languages. Using the package it is possible to work on realistic low-resource scenarios avoiding artiﬁcially reduced setups that are common when demonstrating zero-shot or few-shot learning. For the ﬁrst time, this package provides a comprehensive collection of diverse data sets in hundreds of languages with systematic language and script annotation and data splits to extend the narrow coverage of existing benchmarks. Together with the data release, we also provide a growing number of pre-trained baseline models for individual language pairs and selected language groups.},
	language = {en},
	urldate = {2023-12-13},
	publisher = {arXiv},
	author = {Tiedemann, Jörg},
	month = oct,
	year = {2020},
	note = {arXiv:2010.06354 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: to be appear at the 5th Conference on Machine Translation (WMT20)},
	file = {Tiedemann - 2020 - The Tatoeba Translation Challenge -- Realistic Dat.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4KKRFKRJ\\Tiedemann - 2020 - The Tatoeba Translation Challenge -- Realistic Dat.pdf:application/pdf},
}

@misc{raiaan_review_2023-1,
	title = {A {Review} on {Large} {Language} {Models}: {Architectures}, {Applications}, {Taxonomies}, {Open} {Issues} and {Challenges}},
	shorttitle = {A {Review} on {Large} {Language} {Models}},
	url = {https://www.techrxiv.org/articles/preprint/A_Review_on_Large_Language_Models_Architectures_Applications_Taxonomies_Open_Issues_and_Challenges/24171183/1},
	doi = {10.36227/techrxiv.24171183.v1},
	abstract = {Large Language Models (LLMs) recently demonstrated extraordinary capability, including natural language processing (NLP), language translation, text generation, question answering, etc. Moreover, LLMs are a new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies for the situation. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a lot of new research on LLMs is coming out quickly, it is getting tough to get an overview of all of them in a short note. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLM training phase. It then provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. It also demonstrated the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. It also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Then it also explores open issues and challenges to deploying LLMs in real-world aspects, including ethical issues, model biases, computing resources, interoperability, contextual constraints, privacy, security, etc. It also discusses methods to improve the robustness and controllability of LLMs. Finally, the study analyses the future of LLM research and issues that need to be overcome to make LLMs more impactful and reliable. However, this review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals. Furthermore, it serves as a valuable reference for future development and application of LLM in numerous practical domains.},
	language = {en},
	urldate = {2023-11-27},
	publisher = {TechRxiv},
	author = {Raiaan, Mohaimenul Azam Khan and Mukta, Md Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
	month = sep,
	year = {2023},
}

@article{koehn_europarl_nodate-1,
	title = {Europarl: a parallel corpus for statistical machine translation},
	abstract = {We collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web1. This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation (SMT). We trained SMT systems for 110 language pairs, which reveal interesting clues into the challenges ahead.},
	language = {en},
	author = {Koehn, Philipp},
	file = {Koehn - Europarl a parallel corpus for statistical machin.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\XVZT7VRX\\Koehn - Europarl a parallel corpus for statistical machin.pdf:application/pdf},
}

@misc{hennig_multitacred_2023,
	title = {{MultiTACRED}: {A} {Multilingual} {Version} of the {TAC} {Relation} {Extraction} {Dataset}},
	shorttitle = {{MultiTACRED}},
	url = {http://arxiv.org/abs/2305.04582},
	abstract = {Relation extraction (RE) is a fundamental task in information extraction, whose extension to multilingual settings has been hindered by the lack of supervised resources comparable in size to large English datasets such as TACRED (Zhang et al., 2017). To address this gap, we introduce the MultiTACRED dataset, covering 12 typologically diverse languages from 9 language families, which is created by machine-translating TACRED instances and automatically projecting their entity annotations. We analyze translation and annotation projection quality, identify error categories, and experimentally evaluate ﬁne-tuned pretrained mono- and multilingual language models in common transfer learning scenarios. Our analyses show that machine translation is a viable strategy to transfer RE instances, with native speakers judging more than 83\% of the translated instances to be linguistically and semantically acceptable. We ﬁnd monolingual RE model performance to be comparable to the English original for many of the target languages, and that multilingual models trained on a combination of English and target language data can outperform their monolingual counterparts. However, we also observe a variety of translation and annotation projection errors, both due to the MT systems and linguistic features of the target languages, such as pronoun-dropping, compounding and inﬂection, that degrade dataset quality and RE model performance.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Hennig, Leonhard and Thomas, Philippe and Möller, Sebastian},
	month = may,
	year = {2023},
	note = {arXiv:2305.04582 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted at ACL 2023},
	file = {Hennig et al. - 2023 - MultiTACRED A Multilingual Version of the TAC Rel.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\S2AIDTLP\\Hennig et al. - 2023 - MultiTACRED A Multilingual Version of the TAC Rel.pdf:application/pdf},
}

@misc{tiedemann_tatoeba_2020-1,
	title = {The {Tatoeba} {Translation} {Challenge} -- {Realistic} {Data} {Sets} for {Low} {Resource} and {Multilingual} {MT}},
	url = {http://arxiv.org/abs/2010.06354},
	abstract = {This paper describes the development of a new benchmark for machine translation that provides training and test data for thousands of language pairs covering over 500 languages and tools for creating state-of-the-art translation models from that collection. The main goal is to trigger the development of open translation tools and models with a much broader coverage of the World’s languages. Using the package it is possible to work on realistic low-resource scenarios avoiding artiﬁcially reduced setups that are common when demonstrating zero-shot or few-shot learning. For the ﬁrst time, this package provides a comprehensive collection of diverse data sets in hundreds of languages with systematic language and script annotation and data splits to extend the narrow coverage of existing benchmarks. Together with the data release, we also provide a growing number of pre-trained baseline models for individual language pairs and selected language groups.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Tiedemann, Jörg},
	month = oct,
	year = {2020},
	note = {arXiv:2010.06354 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: to be appear at the 5th Conference on Machine Translation (WMT20)},
	file = {Tiedemann - 2020 - The Tatoeba Translation Challenge -- Realistic Dat.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\E6ZIYQJ3\\Tiedemann - 2020 - The Tatoeba Translation Challenge -- Realistic Dat.pdf:application/pdf},
}

@misc{shi_language_2022-1,
	title = {Language {Models} are {Multilingual} {Chain}-of-{Thought} {Reasoners}},
	url = {http://arxiv.org/abs/2210.03057},
	abstract = {We evaluate the reasoning abilities of large language models in multilingual settings. We introduce the Multilingual Grade School Math (MGSM) benchmark, by manually translating 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) into ten typologically diverse languages. We ﬁnd that the ability to solve MGSM problems via chain-of-thought prompting emerges with increasing model scale, and that models have strikingly strong multilingual reasoning abilities, even in underrepresented languages such as Bengali and Swahili. Finally, we show that the multilingual reasoning abilities of language models extend to other tasks such as commonsense reasoning and wordin-context semantic judgment. The MGSM benchmark is publicly available at https://github.com/google-research/url-nlp.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Shi, Freda and Suzgun, Mirac and Freitag, Markus and Wang, Xuezhi and Srivats, Suraj and Vosoughi, Soroush and Chung, Hyung Won and Tay, Yi and Ruder, Sebastian and Zhou, Denny and Das, Dipanjan and Wei, Jason},
	month = oct,
	year = {2022},
	note = {arXiv:2210.03057 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Shi et al. - 2022 - Language Models are Multilingual Chain-of-Thought .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\UA9ZRFKB\\Shi et al. - 2022 - Language Models are Multilingual Chain-of-Thought .pdf:application/pdf},
}

@misc{wang_voxpopuli_2021,
	title = {{VoxPopuli}: {A} {Large}-{Scale} {Multilingual} {Speech} {Corpus} for {Representation} {Learning}, {Semi}-{Supervised} {Learning} and {Interpretation}},
	shorttitle = {{VoxPopuli}},
	url = {http://arxiv.org/abs/2101.00390},
	abstract = {We introduce VoxPopuli, a large-scale multilingual corpus providing 400K hours of unlabeled speech data in 23 languages. It is the largest open data to date for unsupervised representation learning as well as semisupervised learning. VoxPopuli also contains 1.8K hours of transcribed speeches in 15 languages and their aligned oral interpretations into 15 target languages totaling 17.3K hours. We provide speech recognition (ASR) baselines and validate the versatility of VoxPopuli unlabeled data in semisupervised ASR and speech-to-text translation under challenging out-of-domain settings. The corpus is available at https://github. com/facebookresearch/voxpopuli.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Wang, Changhan and Rivière, Morgane and Lee, Ann and Wu, Anne and Talnikar, Chaitanya and Haziza, Daniel and Williamson, Mary and Pino, Juan and Dupoux, Emmanuel},
	month = jul,
	year = {2021},
	note = {arXiv:2101.00390 [cs, eess]},
	keywords = {Computer Science - Computation and Language, Electrical Engineering and Systems Science - Audio and Speech Processing},
	annote = {Comment: Accepted to ACL 2021 (long paper)},
	file = {Wang et al. - 2021 - VoxPopuli A Large-Scale Multilingual Speech Corpu.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\GNGGRWHW\\Wang et al. - 2021 - VoxPopuli A Large-Scale Multilingual Speech Corpu.pdf:application/pdf},
}

@article{cettolo_overview_nodate,
	title = {Overview of the {IWSLT} 2017 {Evaluation} {Campaign}},
	abstract = {The IWSLT 2017 evaluation campaign has organised three tasks. The Multilingual task, which is about training machine translation systems handling many-to-many language directions, including so-called zero-shot directions. The Dialogue task, which calls for the integration of context information in machine translation, in order to resolve anaphoric references that typically occur in human-human dialogue turns. And, ﬁnally, the Lecture task, which offers the challenge of automatically transcribing and translating real-life university lectures. Following the tradition of these reports, we will described all tasks in detail and present the results of all runs submitted by their participants.},
	language = {en},
	author = {Cettolo, M and Federico, M and Bentivogli, L and Niehues, J and Stuker, S and Sudoh, K and Yoshino, K and Federmann, C},
	file = {Cettolo et al. - Overview of the IWSLT 2017 Evaluation Campaign.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\PCGJJ4S2\\Cettolo et al. - Overview of the IWSLT 2017 Evaluation Campaign.pdf:application/pdf},
}

@misc{conneau_xnli_2018,
	title = {{XNLI}: {Evaluating} {Cross}-lingual {Sentence} {Representations}},
	shorttitle = {{XNLI}},
	url = {http://arxiv.org/abs/1809.05053},
	abstract = {State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models. These models are generally trained on data in a single language (usually English), and cannot be directly used beyond that language. Since collecting data in every language is not realistic, there has been a growing interest in crosslingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15 languages, including low-resource languages such as Swahili and Urdu. We hope that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We ﬁnd that XNLI represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available baselines.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Conneau, Alexis and Lample, Guillaume and Rinott, Ruty and Williams, Adina and Bowman, Samuel R. and Schwenk, Holger and Stoyanov, Veselin},
	month = sep,
	year = {2018},
	note = {arXiv:1809.05053 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: EMNLP 2018},
	file = {Conneau et al. - 2018 - XNLI Evaluating Cross-lingual Sentence Representa.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\T3XCTWIA\\Conneau et al. - 2018 - XNLI Evaluating Cross-lingual Sentence Representa.pdf:application/pdf},
}

@article{lison_opensubtitles2016_nodate,
	title = {{OpenSubtitles2016}: {Extracting} {Large} {Parallel} {Corpora} from {Movie} and {TV} {Subtitles}},
	abstract = {We present a new major release of the OpenSubtitles collection of parallel corpora. The release is compiled from a large database of movie and TV subtitles and includes a total of 1689 bitexts spanning 2.6 billion sentences across 60 languages. The release also incorporates a number of enhancements in the preprocessing and alignment of the subtitles, such as the automatic correction of OCR errors and the use of meta-data to estimate the quality of each subtitle and score subtitle pairs.},
	language = {en},
	author = {Lison, Pierre and Tiedemann, Jorg},
	file = {Lison und Tiedemann - OpenSubtitles2016 Extracting Large Parallel Corpo.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\RCDVYJ7X\\Lison und Tiedemann - OpenSubtitles2016 Extracting Large Parallel Corpo.pdf:application/pdf},
}

@inproceedings{suarez_monolingual_2020,
	title = {A {Monolingual} {Approach} to {Contextualized} {Word} {Embeddings} for {Mid}-{Resource} {Languages}},
	url = {http://arxiv.org/abs/2006.06202},
	doi = {10.18653/v1/2020.acl-main.156},
	abstract = {We use the multilingual OSCAR corpus, extracted from Common Crawl via language classiﬁcation, ﬁltering and cleaning, to train monolingual contextualized word embeddings (ELMo) for ﬁve mid-resource languages. We then compare the performance of OSCARbased and Wikipedia-based ELMo embeddings for these languages on the part-ofspeech tagging and parsing tasks. We show that, despite the noise in the Common-Crawlbased OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all ﬁve languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the beneﬁt of a larger, more diverse corpus surpasses the crosslingual beneﬁt of multilingual embedding architectures.},
	language = {en},
	urldate = {2023-12-16},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	author = {Suárez, Pedro Javier Ortiz and Romary, Laurent and Sagot, Benoît},
	year = {2020},
	note = {arXiv:2006.06202 [cs]},
	keywords = {Computer Science - Computation and Language},
	pages = {1703--1714},
	file = {Suárez et al. - 2020 - A Monolingual Approach to Contextualized Word Embe.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\FHMFXSLY\\Suárez et al. - 2020 - A Monolingual Approach to Contextualized Word Embe.pdf:application/pdf},
}

@misc{zhang_improving_2020,
	title = {Improving {Massively} {Multilingual} {Neural} {Machine} {Translation} and {Zero}-{Shot} {Translation}},
	url = {http://arxiv.org/abs/2004.11867},
	abstract = {Massively multilingual models for neural machine translation (NMT) are theoretically attractive, but often underperform bilingual models and deliver poor zero-shot translations. In this paper, we explore ways to improve them. We argue that multilingual NMT requires stronger modeling capacity to support language pairs with varying typological characteristics, and overcome this bottleneck via language-specific components and deepening NMT architectures. We identify the off-target translation issue (i.e. translating into a wrong target language) as the major source of the inferior zero-shot performance, and propose random online backtranslation to enforce the translation of unseen training language pairs. Experiments on OPUS-100 (a novel multilingual dataset with 100 languages) show that our approach substantially narrows the performance gap with bilingual models in both one-to-many and many-to-many settings, and improves zero-shot performance by {\textasciitilde}10 BLEU, approaching conventional pivot-based methods.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Zhang, Biao and Williams, Philip and Titov, Ivan and Sennrich, Rico},
	month = apr,
	year = {2020},
	note = {arXiv:2004.11867 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: ACL2020},
	file = {Zhang et al. - 2020 - Improving Massively Multilingual Neural Machine Tr.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\T9AL8VW5\\Zhang et al. - 2020 - Improving Massively Multilingual Neural Machine Tr.pdf:application/pdf},
}

@misc{ardila_common_2020,
	title = {Common {Voice}: {A} {Massively}-{Multilingual} {Speech} {Corpus}},
	shorttitle = {Common {Voice}},
	url = {http://arxiv.org/abs/1912.06670},
	abstract = {The Common Voice corpus is a massively-multilingual collection of transcribed speech intended for speech technology research and development. Common Voice is designed for Automatic Speech Recognition purposes but can be useful in other domains (e.g. language identiﬁcation). To achieve scale and sustainability, the Common Voice project employs crowdsourcing for both data collection and data validation. The most recent release includes 29 languages, and as of November 2019 there are a total of 38 languages collecting data. Over 50,000 individuals have participated so far, resulting in 2,500 hours of collected audio. To our knowledge this is the largest audio corpus in the public domain for speech recognition, both in terms of number of hours and number of languages. As an example use case for Common Voice, we present speech recognition experiments using Mozilla’s DeepSpeech Speech-to-Text toolkit. By applying transfer learning from a source English model, we ﬁnd an average Character Error Rate improvement of 5.99 ± 5.48 for twelve target languages (German, French, Italian, Turkish, Catalan, Slovenian, Welsh, Irish, Breton, Tatar, Chuvash, and Kabyle). For most of these languages, these are the ﬁrst ever published results on end-to-end Automatic Speech Recognition.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M. and Weber, Gregor},
	month = mar,
	year = {2020},
	note = {arXiv:1912.06670 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Accepted to LREC 2020},
	file = {Ardila et al. - 2020 - Common Voice A Massively-Multilingual Speech Corp.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\Y3HWDJHF\\Ardila et al. - 2020 - Common Voice A Massively-Multilingual Speech Corp.pdf:application/pdf},
}

@misc{bandarkar_belebele_2023,
	title = {The {Belebele} {Benchmark}: a {Parallel} {Reading} {Comprehension} {Dataset} in 122 {Language} {Variants}},
	shorttitle = {The {Belebele} {Benchmark}},
	url = {http://arxiv.org/abs/2308.16884},
	abstract = {We present BELEBELE, a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. Significantly expanding the language coverage of natural language understanding (NLU) benchmarks, this dataset enables the evaluation of text models in high-, medium-, and low-resource languages. Each question is based on a short passage from the FLORES-200 dataset and has four multiplechoice answers. The questions were carefully curated to discriminate between models with different levels of general language comprehension. The English dataset on its own proves difficult enough to challenge state-of-the-art language models. Being fully parallel, this dataset enables direct comparison of model performance across all languages. We use this dataset to evaluate the capabilities of multilingual masked language models (MLMs) and large language models (LLMs). We present extensive results and find that despite significant cross-lingual transfer in English-centric LLMs, much smaller MLMs pretrained on balanced multilingual data still understand far more languages. We also observe that larger vocabulary size and conscious vocabulary construction correlate with better performance on low-resource languages. Overall, BELEBELE opens up new avenues for evaluating and analyzing the multilingual capabilities of NLP systems.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Bandarkar, Lucas and Liang, Davis and Muller, Benjamin and Artetxe, Mikel and Shukla, Satya Narayan and Husa, Donald and Goyal, Naman and Krishnan, Abhinandan and Zettlemoyer, Luke and Khabsa, Madian},
	month = aug,
	year = {2023},
	note = {arXiv:2308.16884 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, I.2.7},
	annote = {Comment: 27 pages, 13 figures},
	file = {Bandarkar et al. - 2023 - The Belebele Benchmark a Parallel Reading Compreh.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\CI4QI5QA\\Bandarkar et al. - 2023 - The Belebele Benchmark a Parallel Reading Compreh.pdf:application/pdf},
}

@misc{hu_xtreme_2020,
	title = {{XTREME}: {A} {Massively} {Multilingual} {Multi}-task {Benchmark} for {Evaluating} {Cross}-lingual {Generalization}},
	shorttitle = {{XTREME}},
	url = {http://arxiv.org/abs/2003.11080},
	abstract = {Much recent progress in applications of machine learning models to NLP has been driven by benchmarks that evaluate models across a wide variety of tasks. However, these broad-coverage benchmarks have been mostly limited to English, and despite an increasing interest in multilingual models, a benchmark that enables the comprehensive evaluation of such methods on a diverse range of languages and tasks is still missing. To this end, we introduce the Cross-lingual TRansfer Evaluation of Multilingual Encoders (XTREME) benchmark, a multi-task benchmark for evaluating the cross-lingual generalization capabilities of multilingual representations across 40 languages and 9 tasks. We demonstrate that while models tested on English reach human performance on many tasks, there is still a sizable gap in the performance of cross-lingually transferred models, particularly on syntactic and sentence retrieval tasks. There is also a wide spread of results across languages. We release the benchmark1 to encourage research on cross-lingual learning methods that transfer linguistic knowledge across a diverse and representative set of languages and tasks.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Hu, Junjie and Ruder, Sebastian and Siddhant, Aditya and Neubig, Graham and Firat, Orhan and Johnson, Melvin},
	month = sep,
	year = {2020},
	note = {arXiv:2003.11080 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: In Proceedings of the 37th International Conference on Machine Learning (ICML). July 2020},
	file = {Hu et al. - 2020 - XTREME A Massively Multilingual Multi-task Benchm.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\3T8Y4RLY\\Hu et al. - 2020 - XTREME A Massively Multilingual Multi-task Benchm.pdf:application/pdf},
}

@misc{conneau_xtreme-s_2022,
	title = {{XTREME}-{S}: {Evaluating} {Cross}-lingual {Speech} {Representations}},
	shorttitle = {{XTREME}-{S}},
	url = {http://arxiv.org/abs/2203.10752},
	abstract = {We introduce XTREME-S, a new benchmark to evaluate universal cross-lingual speech representations in many languages. XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102 languages from 10+ language families, 3 different domains and 4 task families, XTREME-S aims to simplify multilingual speech representation evaluation, as well as catalyze research in "universal" speech representation learning. This paper describes the new benchmark and establishes the first speech-only and speech-text baselines using XLS-R and mSLAM on all downstream tasks. We motivate the design choices and detail how to use the benchmark. Datasets and fine-tuning scripts are made easily accessible at https://hf.co/datasets/google/xtreme\_s.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Conneau, Alexis and Bapna, Ankur and Zhang, Yu and Ma, Min and von Platen, Patrick and Lozhkov, Anton and Cherry, Colin and Jia, Ye and Rivera, Clara and Kale, Mihir and Van Esch, Daan and Axelrod, Vera and Khanuja, Simran and Clark, Jonathan H. and Firat, Orhan and Auli, Michael and Ruder, Sebastian and Riesa, Jason and Johnson, Melvin},
	month = apr,
	year = {2022},
	note = {arXiv:2203.10752 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Minor fix: language code for Filipino (Tagalog), "tg" -{\textgreater} "tl"},
	file = {Conneau et al. - 2022 - XTREME-S Evaluating Cross-lingual Speech Represen.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\7FPIZAGL\\Conneau et al. - 2022 - XTREME-S Evaluating Cross-lingual Speech Represen.pdf:application/pdf},
}

@misc{guzman_flores_2019,
	title = {The {FLoRes} {Evaluation} {Datasets} for {Low}-{Resource} {Machine} {Translation}: {Nepali}-{English} and {Sinhala}-{English}},
	shorttitle = {The {FLoRes} {Evaluation} {Datasets} for {Low}-{Resource} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1902.01382},
	abstract = {For machine translation, a vast majority of language pairs in the world are considered low-resource because they have little parallel data available. Besides the technical challenges of learning with limited supervision, it is difﬁcult to evaluate methods trained on lowresource language pairs because of the lack of freely and publicly available benchmarks. In this work, we introduce the FLORES evaluation datasets for Nepali–English and Sinhala–English, based on sentences translated from Wikipedia. Compared to English, these are languages with very different morphology and syntax, for which little out-of-domain parallel data is available and for which relatively large amounts of monolingual data are freely available. We describe our process to collect and cross-check the quality of translations, and we report baseline performance using several learning settings: fully supervised, weakly supervised, semi-supervised, and fully unsupervised. Our experiments demonstrate that current state-of-the-art methods perform rather poorly on this benchmark, posing a challenge to the research community working on lowresource MT. Data and code to reproduce our experiments are available at https://github. com/facebookresearch/flores.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Guzmán, Francisco and Chen, Peng-Jen and Ott, Myle and Pino, Juan and Lample, Guillaume and Koehn, Philipp and Chaudhary, Vishrav and Ranzato, Marc'Aurelio},
	month = sep,
	year = {2019},
	note = {arXiv:1902.01382 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: EMNLP 2019},
	file = {Guzmán et al. - 2019 - The FLoRes Evaluation Datasets for Low-Resource Ma.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\TPXYANGV\\Guzmán et al. - 2019 - The FLoRes Evaluation Datasets for Low-Resource Ma.pdf:application/pdf},
}

@misc{wang_covost_2020,
	title = {{CoVoST} 2 and {Massively} {Multilingual} {Speech}-to-{Text} {Translation}},
	url = {http://arxiv.org/abs/2007.10310},
	abstract = {Speech-to-text translation (ST) has recently become an increasingly popular topic of research, partly due to the development of benchmark datasets. Nevertheless, current datasets cover a limited number of languages. With the aim to foster research in massive multilingual ST and ST for low resource language pairs, we release CoVoST 2, a large-scale multilingual ST corpus covering translations from 21 languages into English and from English into 15 languages. This represents the largest open dataset available to date from total volume and language coverage perspective. Data sanity checks provide evidence about the quality of the data, which is released under CC0 license. We also provide extensive speech recognition, bilingual and multilingual machine translation and ST baselines with open-source implementation 1.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Wang, Changhan and Wu, Anne and Pino, Juan},
	month = oct,
	year = {2020},
	note = {arXiv:2007.10310 [cs, eess]},
	keywords = {Computer Science - Computation and Language, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	file = {Wang et al. - 2020 - CoVoST 2 and Massively Multilingual Speech-to-Text.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4DD3FWCI\\Wang et al. - 2020 - CoVoST 2 and Massively Multilingual Speech-to-Text.pdf:application/pdf},
}

@misc{borchert_ggponc_2020,
	title = {{GGPONC}: {A} {Corpus} of {German} {Medical} {Text} with {Rich} {Metadata} {Based} on {Clinical} {Practice} {Guidelines}},
	shorttitle = {{GGPONC}},
	url = {http://arxiv.org/abs/2007.06400},
	abstract = {The lack of publicly accessible text corpora is a major obstacle for progress in natural language processing. For medical applications, unfortunately, all language communities other than English are low-resourced. In this work, we present GGPONC (German Guideline Program in Oncology NLP Corpus), a freely distributable German language corpus based on clinical practice guidelines for oncology. This corpus is one of the largest ever built from German medical documents. Unlike clinical documents, clinical guidelines do not contain any patient-related information and can therefore be used without data protection restrictions. Moreover, GGPONC is the ﬁrst corpus for the German language covering diverse conditions in a large medical subﬁeld and provides a variety of metadata, such as literature references and evidence levels. By applying and evaluating existing medical information extraction pipelines for German text, we are able to draw comparisons for the use of medical language to other corpora, medical and non-medical ones.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Borchert, Florian and Lohr, Christina and Modersohn, Luise and Langer, Thomas and Follmann, Markus and Sachs, Jan Philipp and Hahn, Udo and Schapranow, Matthieu-P.},
	month = nov,
	year = {2020},
	note = {arXiv:2007.06400 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: LOUHI Workshop @ EMNLP '20. Proceedings of the 11th International Workshop on Health Text Mining and Information Analysis. 2020},
	file = {Borchert et al. - 2020 - GGPONC A Corpus of German Medical Text with Rich .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\EMSI5KX9\\Borchert et al. - 2020 - GGPONC A Corpus of German Medical Text with Rich .pdf:application/pdf},
}

@article{kittner_annotation_2021,
	title = {Annotation and initial evaluation of a large annotated {German} oncological corpus},
	volume = {4},
	issn = {2574-2531},
	url = {https://academic.oup.com/jamiaopen/article/doi/10.1093/jamiaopen/ooab025/6236337},
	doi = {10.1093/jamiaopen/ooab025},
	abstract = {Objective: We present the Berlin-Tu¨ bingen-Oncology corpus (BRONCO), a large and freely available corpus of shufﬂed sentences from German oncological discharge summaries annotated with diagnosis, treatments, medications, and further attributes including negation and speculation. The aim of BRONCO is to foster reproducible and openly available research on Information Extraction from German medical texts. Materials and Methods: BRONCO consists of 200 manually deidentiﬁed discharge summaries of cancer patients. Annotation followed a structured and quality-controlled process involving 2 groups of medical experts to ensure consistency, comprehensiveness, and high quality of annotations. We present results of several stateof-the-art techniques for different IE tasks as baselines for subsequent research.
Results: The annotated corpus consists of 11 434 sentences and 89 942 tokens, annotated with 11 124 annotations for medical entities and 3118 annotations of related attributes. We publish 75\% of the corpus as a set of shufﬂed sentences, and keep 25\% as held-out data set for unbiased evaluation of future IE tools. On this heldout dataset, our baselines reach depending on the speciﬁc entity types F1-scores of 0.72–0.90 for named entity recognition, 0.10–0.68 for entity normalization, 0.55 for negation detection, and 0.33 for speculation detection. Discussion: Medical corpus annotation is a complex and time-consuming task. This makes sharing of such resources even more important.
Conclusion: To our knowledge, BRONCO is the ﬁrst sizable and freely available German medical corpus. Our baseline results show that more research efforts are necessary to lift the quality of information extraction in German medical texts to the level already possible for English.},
	language = {en},
	number = {2},
	urldate = {2023-12-16},
	journal = {JAMIA Open},
	author = {Kittner, Madeleine and Lamping, Mario and Rieke, Damian T and Götze, Julian and Bajwa, Bariya and Jelas, Ivan and Rüter, Gina and Hautow, Hanjo and Sänger, Mario and Habibi, Maryam and Zettwitz, Marit and Bortoli, Till De and Ostermann, Leonie and Ševa, Jurica and Starlinger, Johannes and Kohlbacher, Oliver and Malek, Nisar P and Keilholz, Ulrich and Leser, Ulf},
	month = apr,
	year = {2021},
	pages = {ooab025},
	file = {Kittner et al. - 2021 - Annotation and initial evaluation of a large annot.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\GT98QR35\\Kittner et al. - 2021 - Annotation and initial evaluation of a large annot.pdf:application/pdf},
}

@inproceedings{leitner_fine-grained_2019-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Fine-{Grained} {Named} {Entity} {Recognition} in {Legal} {Documents}},
	isbn = {978-3-030-33220-4},
	doi = {10.1007/978-3-030-33220-4_20},
	abstract = {This paper describes an approach at Named Entity Recognition (NER) in German language documents from the legal domain. For this purpose, a dataset consisting of German court decisions was developed. The source texts were manually annotated with 19 semantic classes: person, judge, lawyer, country, city, street, landscape, organization, company, institution, court, brand, law, ordinance, European legal norm, regulation, contract, court decision, and legal literature. The dataset consists of approx. 67,000 sentences and contains 54,000 annotated entities. The 19 fine-grained classes were automatically generalised to seven more coarse-grained classes (person, location, organization, legal norm, case-by-case regulation, court decision, and legal literature). Thus, the dataset includes two annotation variants, i.e., coarse- and fine-grained. For the task of NER, Conditional Random Fields (CRFs) and bidirectional Long-Short Term Memory Networks (BiLSTMs) were applied to the dataset as state of the art models. Three different models were developed for each of these two model families and tested with the coarse- and fine-grained annotations. The BiLSTM models achieve the best performance with an 95.46 F\$\$\_1\$\$score for the fine-grained classes and 95.95 for the coarse-grained ones. The CRF models reach a maximum of 93.23 for the fine-grained classes and 93.22 for the coarse-grained ones. The work presented in this paper was carried out under the umbrella of the European project LYNX that develops a semantic platform that enables the development of various document processing and analysis applications for the legal domain.},
	language = {en},
	booktitle = {Semantic {Systems}. {The} {Power} of {AI} and {Knowledge} {Graphs}},
	publisher = {Springer International Publishing},
	author = {Leitner, Elena and Rehm, Georg and Moreno-Schneider, Julian},
	editor = {Acosta, Maribel and Cudré-Mauroux, Philippe and Maleshkova, Maria and Pellegrini, Tassilo and Sack, Harald and Sure-Vetter, York},
	year = {2019},
	keywords = {BiLSTM, CRF, Curation technologies, Language technology, Legal processing, Legal technologies, LT, Named Entity Recognition, Natural Language Processing, NER, NLP},
	pages = {272--287},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\H3I52QXW\\Leitner et al. - 2019 - Fine-Grained Named Entity Recognition in Legal Doc.pdf:application/pdf},
}

@article{samardzic_archimob_nodate,
	title = {{ArchiMob} — {A} corpus of {Spoken} {Swiss} {German}},
	abstract = {Swiss dialects of German are, unlike most dialects of well standardised languages, widely used in everyday communication. Despite this fact, automatic processing of Swiss German is still a considerable challenge due to the fact that it is mostly a spoken variety rarely recorded and that it is subject to considerable regional variation. This paper presents a freely available general-purpose corpus of spoken Swiss German suitable for linguistic research, but also for training automatic tools. The corpus is a result of a long design process, intensive manual work and specially adapted computational processing. We ﬁrst describe how the documents were transcribed, segmented and aligned with the sound source, and how inconsistent transcriptions were uniﬁed through an additional normalisation layer. We then present a bootstrapping approach to automatic normalisation using different machine-translation-inspired methods. Furthermore, we evaluate the performance of part-of-speech taggers on our data and show how the same bootstrapping approach improves part-of-speech tagging by 10\% over four rounds. Finally, we present the modalities of access of the corpus as well as the data format.},
	language = {en},
	author = {Samardzˇic, Tanja and Scherrer, Yves and Glaser, Elvira},
	file = {Samardzˇic et al. - ArchiMob — A corpus of Spoken Swiss German.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\TX2X5R9W\\Samardzˇic et al. - ArchiMob — A corpus of Spoken Swiss German.pdf:application/pdf},
}

@article{roller_annotated_nodate,
	title = {An {Annotated} {Corpus} of {Textual} {Explanations} for {Clinical} {Decision} {Support}},
	abstract = {In recent years, machine learning for clinical decision support has gained more and more attention. In order to introduce such applications into clinical practice, a good performance might be essential, however, the aspect of trust should not be underestimated. For the treating physician using such a system and being (legally) responsible for the decision made, it is particularly important to understand the system’s recommendation. To provide insights into a model’s decision, various techniques from the field of explainability (XAI) have been proposed whose output is often enough not targeted to the domain experts that want to use the model. To close this gap, in this work, we explore how explanations could possibly look like in future. To this end, this work presents a dataset of textual explanations in context of decision support. Within a reader study, human physicians estimated the likelihood of possible negative patient outcomes in the near future and justified each decision with a few sentences. Using those sentences, we created a novel corpus, annotated with different semantic layers. Moreover, we provide an analysis of how those explanations are constructed, and how they change depending on physician, on the estimated risk and also in comparison to an automatic clinical decision support system with feature importance.},
	language = {en},
	author = {Roller, Roland and Burchardt, Aljoscha and Feldhus, Nils and Seiffe, Laura and Budde, Klemens and Ronicke, Simon and Osmanodja, Bilgin},
	file = {Roller et al. - An Annotated Corpus of Textual Explanations for Cl.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2638FPNC\\Roller et al. - An Annotated Corpus of Textual Explanations for Cl.pdf:application/pdf},
}

@misc{noauthor_wikimedia_nodate,
	title = {Wikimedia {Downloads}},
	url = {https://dumps.wikimedia.org/},
	urldate = {2023-12-16},
	file = {Wikimedia Downloads:C\:\\Users\\bar35643\\Zotero\\storage\\USBVJCGK\\dumps.wikimedia.org.html:text/html},
}

@article{buitelaar_multi-layered_nodate,
	title = {A {Multi}-{Layered}, {XML}-{Based} {Approach} to the {Integration} of {Linguis}- tic and {Semantic} {Annotations}},
	abstract = {In this paper we present a multi-layered approach to document annotation that allows for the structural integration of linguistic and semantic annotations produced by various language technology tools and using knowledge encoded in different domain ontologies as needed for semantic web applications.},
	language = {en},
	author = {Buitelaar, Paul and Declerck, Thierry and Sacaleanu, Bogdan and Vintar, Špela and Raileanu, Diana and Crispi, Claudia},
	file = {Buitelaar et al. - A Multi-Layered, XML-Based Approach to the Integra.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\PZVGXWSZ\\Buitelaar et al. - A Multi-Layered, XML-Based Approach to the Integra.pdf:application/pdf},
}

@misc{sang_introduction_2003,
	title = {Introduction to the {CoNLL}-2003 {Shared} {Task}: {Language}-{Independent} {Named} {Entity} {Recognition}},
	shorttitle = {Introduction to the {CoNLL}-2003 {Shared} {Task}},
	url = {http://arxiv.org/abs/cs/0306050},
	abstract = {We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance.},
	language = {en},
	urldate = {2023-12-16},
	publisher = {arXiv},
	author = {Sang, Erik F. Tjong Kim and De Meulder, Fien},
	month = jun,
	year = {2003},
	note = {arXiv:cs/0306050},
	keywords = {Computer Science - Computation and Language, I.2.7},
	file = {Sang und De Meulder - 2003 - Introduction to the CoNLL-2003 Shared Task Langua.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4F6A5HTF\\Sang und De Meulder - 2003 - Introduction to the CoNLL-2003 Shared Task Langua.pdf:application/pdf},
}

@article{barrault_findings_nodate,
	title = {Findings of the 2020 {Conference} on {Machine} {Translation} ({WMT20})},
	abstract = {This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe speciﬁc aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages.},
	language = {en},
	author = {Barrault, Loïc and Biesialska, Magdalena and Bojar, Ondřej and Costa-jussà, Marta R and Federmann, Christian and Graham, Yvette and Grundkiewicz, Roman and Haddow, Barry and Huck, Matthias and Joanis, Eric and Kocmi, Tom and Koehn, Philipp and Lo, Chi-kiu and Ljubešić, Nikola and Monz, Christof and Morishita, Makoto and Nagata, Masaaki and Nakazawa, Toshiaki and Pal, Santanu and Post, Matt and Zampieri, Marcos},
	file = {Barrault et al. - Findings of the 2020 Conference on Machine Transla.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\REFIFCWI\\Barrault et al. - Findings of the 2020 Conference on Machine Transla.pdf:application/pdf},
}

@misc{noauthor_statistical_nodate,
	title = {Statistical and {Neural} {Machine} {Translation}},
	url = {http://www2.statmt.org/},
	urldate = {2023-12-16},
	file = {Statistical and Neural Machine Translation:C\:\\Users\\bar35643\\Zotero\\storage\\CLASJ769\\www2.statmt.org.html:text/html},
}

@misc{noauthor_statistical_nodate-1,
	title = {Statistical and {Neural} {Machine} {Translation}},
	url = {https://statmt.org/},
	urldate = {2023-12-16},
	file = {Statistical and Neural Machine Translation:C\:\\Users\\bar35643\\Zotero\\storage\\U3UAXXHE\\statmt.org.html:text/html},
}

@inproceedings{kocmi_findings_2023,
	address = {Singapore},
	title = {Findings of the 2023 {Conference} on {Machine} {Translation} ({WMT23}): {LLMs} {Are} {Here} but {Not} {Quite} {There} {Yet}},
	shorttitle = {Findings of the 2023 {Conference} on {Machine} {Translation} ({WMT23})},
	url = {https://aclanthology.org/2023.wmt-1.1},
	doi = {10.18653/v1/2023.wmt-1.1},
	language = {en},
	urldate = {2023-12-16},
	booktitle = {Proceedings of the {Eighth} {Conference} on {Machine} {Translation}},
	publisher = {Association for Computational Linguistics},
	author = {Kocmi, Tom and Avramidis, Eleftherios and Bawden, Rachel and Bojar, Ondřej and Dvorkovich, Anton and Federmann, Christian and Fishel, Mark and Freitag, Markus and Gowda, Thamme and Grundkiewicz, Roman and Haddow, Barry and Koehn, Philipp and Marie, Benjamin and Monz, Christof and Morishita, Makoto and Murray, Kenton and Nagata, Makoto and Nakazawa, Toshiaki and Popel, Martin and Popović, Maja and Shmatova, Mariya},
	year = {2023},
	pages = {1--42},
	file = {Kocmi et al. - 2023 - Findings of the 2023 Conference on Machine Transla.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\74SBNHCV\\Kocmi et al. - 2023 - Findings of the 2023 Conference on Machine Transla.pdf:application/pdf},
}

@article{reinig_can_nodate,
	title = {Can current {NLI} systems handle {German} word order? {Investigating} language model performance on a new {German} challenge set of minimal pairs},
	abstract = {Compared to English, German word order is freer and therefore poses additional challenges for natural language inference (NLI). We create WOGLI (Word Order in German Language Inference), the first adversarial NLI dataset for German word order that has the following properties: (i) each premise has an entailed and a non-entailed hypothesis; (ii) premise and hypotheses differ only in word order and necessary morphological changes to mark case and number. In particular, each premise and its two hypotheses contain exactly the same lemmata. Our adversarial examples require the model to use morphological markers in order to recognise or reject entailment. We show that current German autoencoding models fine-tuned on translated NLI data can struggle on this challenge set, reflecting the fact that translated NLI datasets will not mirror all necessary language phenomena in the target language. We also examine performance after data augmentation as well as on related word order phenomena derived from WOGLI. Our datasets are publically available at https: //github.com/ireinig/wogli.},
	language = {en},
	author = {Reinig, Ines and Markert, Katja},
	file = {Reinig und Markert - Can current NLI systems handle German word order .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\SXRV7I3K\\Reinig und Markert - Can current NLI systems handle German word order .pdf:application/pdf},
}

@article{buitelaar_multi-layered_nodate-1,
	title = {A {Multi}-{Layered}, {XML}-{Based} {Approach} to the {Integration} of {Linguis}- tic and {Semantic} {Annotations}},
	abstract = {In this paper we present a multi-layered approach to document annotation that allows for the structural integration of linguistic and semantic annotations produced by various language technology tools and using knowledge encoded in different domain ontologies as needed for semantic web applications.},
	language = {en},
	author = {Buitelaar, Paul and Declerck, Thierry and Sacaleanu, Bogdan and Vintar, Špela and Raileanu, Diana and Crispi, Claudia},
	file = {Buitelaar et al. - A Multi-Layered, XML-Based Approach to the Integra.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\LXGZLNLT\\Buitelaar et al. - A Multi-Layered, XML-Based Approach to the Integra.pdf:application/pdf},
}

@misc{noauthor_untitled_nodate,
	title = {Untitled {Document}},
	url = {https://muchmore.dfki.de/},
	urldate = {2023-12-16},
	file = {Untitled Document:C\:\\Users\\bar35643\\Zotero\\storage\\4DFCZP58\\muchmore.dfki.de.html:text/html},
}

@misc{noauthor_muchmore_nodate,
	title = {much.more},
	url = {https://muchmore.dfki.de/resources_index.htm},
	urldate = {2023-12-16},
	file = {much.more:C\:\\Users\\bar35643\\Zotero\\storage\\2P93MGN3\\resources_index.html:text/html},
}

@inproceedings{sap_risk_2019,
	address = {Florence, Italy},
	title = {The {Risk} of {Racial} {Bias} in {Hate} {Speech} {Detection}},
	url = {https://aclanthology.org/P19-1163},
	doi = {10.18653/v1/P19-1163},
	abstract = {We investigate how annotators' insensitivity to differences in dialect can lead to racial bias in automatic hate speech detection models, potentially amplifying harm against minority populations. We first uncover unexpected correlations between surface markers of African American English (AAE) and ratings of toxicity in several widely-used hate speech datasets. Then, we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others. Finally, we propose *dialect* and *race priming* as ways to reduce the racial bias in annotation, showing that when annotators are made explicitly aware of an AAE tweet's dialect they are significantly less likely to label the tweet as offensive.},
	urldate = {2023-12-16},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Sap, Maarten and Card, Dallas and Gabriel, Saadia and Choi, Yejin and Smith, Noah A.},
	editor = {Korhonen, Anna and Traum, David and Màrquez, Lluís},
	month = jul,
	year = {2019},
	pages = {1668--1678},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\4B8WTSGN\\Sap et al. - 2019 - The Risk of Racial Bias in Hate Speech Detection.pdf:application/pdf},
}

@inproceedings{blodgett_language_2020,
	address = {Online},
	title = {Language ({Technology}) is {Power}: {A} {Critical} {Survey} of “{Bias}” in {NLP}},
	shorttitle = {Language ({Technology}) is {Power}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.485},
	doi = {10.18653/v1/2020.acl-main.485},
	abstract = {We survey 146 papers analyzing “bias” in NLP systems, fnding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing “bias” is an inherently normative process. We further fnd that these papers’ proposed quantitative techniques for measuring or mitigating “bias” are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these fndings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing “bias” in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of “bias”—i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements—and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.},
	language = {en},
	urldate = {2023-12-16},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Blodgett, Su Lin and Barocas, Solon and Daumé Iii, Hal and Wallach, Hanna},
	year = {2020},
	pages = {5454--5476},
	file = {Blodgett et al. - 2020 - Language (Technology) is Power A Critical Survey .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\C7T5UHFP\\Blodgett et al. - 2020 - Language (Technology) is Power A Critical Survey .pdf:application/pdf},
}

@misc{ke_continual_2022,
	title = {Continual {Training} of {Language} {Models} for {Few}-{Shot} {Learning}},
	url = {http://arxiv.org/abs/2210.05549},
	abstract = {Recent work on applying large language models (LMs) achieves impressive performance in many NLP applications. Adapting or posttraining an LM using an unlabeled domain corpus can produce even better performance for end-tasks in the domain. This paper proposes the problem of continually extending an LM by incrementally post-train the LM with a sequence of unlabeled domain corpora to expand its knowledge without forgetting its previous skills. The goal is to improve the few-shot end-task learning in these domains. The resulting system is called CPT (Continual PostTraining), which to our knowledge, is the first continual post-training system. Experimental results verify its effectiveness.},
	language = {en},
	urldate = {2023-12-18},
	publisher = {arXiv},
	author = {Ke, Zixuan and Lin, Haowei and Shao, Yijia and Xu, Hu and Shu, Lei and Liu, Bing},
	month = oct,
	year = {2022},
	note = {arXiv:2210.05549 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	file = {2210.05549.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\DU9AUGKR\\2210.05549.pdf:application/pdf},
}

@misc{gupta_continual_2023,
	title = {Continual {Pre}-{Training} of {Large} {Language} {Models}: {How} to (re)warm your model?},
	shorttitle = {Continual {Pre}-{Training} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2308.04014},
	abstract = {Large language models (LLMs) are routinely pretrained on billions of tokens, only to restart the process over again once new data becomes available. A much cheaper and more efficient solution would be to enable the continual pre-training of these models, i.e. updating pre-trained models with new data instead of re-training them from scratch. However, the distribution shift induced by novel data typically results in degraded performance on past data. Taking a step towards efficient continual pre-training, in this work, we examine the effect of different warm-up strategies. Our hypothesis is that the learning rate must be re-increased to improve compute efficiency when training on a new dataset. We study the warmup phase of models pre-trained on the Pile (upstream data, 300B tokens) as we continue to pre-train on SlimPajama (downstream data, 297B tokens), following a linear warmup and cosine decay schedule. We conduct all experiments on the Pythia 410M language model architecture and evaluate performance through validation perplexity. We experiment with different pre-training checkpoints, various maximum learning rates, and various warmup lengths. Our results show that while rewarming models first increases the loss on upstream and downstream data, in the longer run it improves the downstream performance, outperforming models trained from scratch—even for a large downstream dataset.},
	language = {en},
	urldate = {2023-12-18},
	publisher = {arXiv},
	author = {Gupta, Kshitij and Thérien, Benjamin and Ibrahim, Adam and Richter, Mats L. and Anthony, Quentin and Belilovsky, Eugene and Rish, Irina and Lesort, Timothée},
	month = sep,
	year = {2023},
	note = {arXiv:2308.04014 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Gupta et al. - 2023 - Continual Pre-Training of Large Language Models H.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\NPYS7SJB\\Gupta et al. - 2023 - Continual Pre-Training of Large Language Models H.pdf:application/pdf},
}

@misc{noauthor_nli4ct_nodate,
	title = {{NLI4CT}},
	url = {https://sites.google.com/view/nli4ct/semeval-2024},
	abstract = {Codalab competition
Please visit the Codalab to participate in the task, and join the Slack channel for more information and help!
See the SemEval 2023 Task 7 overview paper
See the Dataset paper},
	language = {de},
	urldate = {2023-12-24},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\ZB2ZKZNA\\semeval-2024.html:text/html},
}

@misc{gao_simcse_2022,
	title = {{SimCSE}: {Simple} {Contrastive} {Learning} of {Sentence} {Embeddings}},
	shorttitle = {{SimCSE}},
	url = {http://arxiv.org/abs/2104.08821},
	abstract = {This paper presents SimCSE, a simple contrastive learning framework that greatly advances state-of-the-art sentence embeddings. We first describe an unsupervised approach, which takes an input sentence and predicts itself in a contrastive objective, with only standard dropout used as noise. This simple method works surprisingly well, performing on par with previous supervised counterparts. We find that dropout acts as minimal data augmentation, and removing it leads to a representation collapse. Then, we propose a supervised approach, which incorporates annotated pairs from natural language inference datasets into our contrastive learning framework by using "entailment" pairs as positives and "contradiction" pairs as hard negatives. We evaluate SimCSE on standard semantic textual similarity (STS) tasks, and our unsupervised and supervised models using BERT base achieve an average of 76.3\% and 81.6\% Spearman's correlation respectively, a 4.2\% and 2.2\% improvement compared to the previous best results. We also show -- both theoretically and empirically -- that the contrastive learning objective regularizes pre-trained embeddings' anisotropic space to be more uniform, and it better aligns positive pairs when supervised signals are available.},
	language = {en},
	urldate = {2023-12-24},
	publisher = {arXiv},
	author = {Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
	month = may,
	year = {2022},
	note = {arXiv:2104.08821 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Accepted to EMNLP 2021. The code and pre-trained models are available at https://github.com/princeton-nlp/simcse},
	file = {Gao et al. - 2022 - SimCSE Simple Contrastive Learning of Sentence Em.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\PZ5ZKFLM\\Gao et al. - 2022 - SimCSE Simple Contrastive Learning of Sentence Em.pdf:application/pdf},
}

@inproceedings{wang_knowcomp_2023,
	address = {Toronto, Canada},
	title = {{KnowComp} at {SemEval}-2023 {Task} 7: {Fine}-tuning {Pre}-trained {Language} {Models} for {Clinical} {Trial} {Entailment} {Identification}},
	shorttitle = {{KnowComp} at {SemEval}-2023 {Task} 7},
	url = {https://aclanthology.org/2023.semeval-1.1},
	doi = {10.18653/v1/2023.semeval-1.1},
	abstract = {In this paper, we present our system for the textual entailment identification task as a subtask of the SemEval-2023 Task 7: Multi-evidence Natural Language Inference for Clinical Trial Data. The entailment identification task aims to determine whether a medical statement affirms a valid entailment given a clinical trial premise or forms a contradiction with it. Since the task is inherently a text classification task, we propose a system that performs binary classification given a statement and its associated clinical trial. Our proposed system leverages a human-defined prompt to aggregate the information contained in the statement, section name, and clinical trials. Pre-trained language models are then finetuned on the prompted input sentences to learn to discriminate the inferential relation between the statement and clinical trial. To validate our system, we conduct extensive experiments with a wide variety of pre-trained language models. Our best system is built on DeBERTa-v3-large, which achieves an F1 score of 0.764 and secures the fifth rank in the official leaderboard. Further analysis indicates that leveraging our designed prompt is effective, and our model suffers from a low recall. Our code and pre-trained models are available at https://github.com/HKUSTKnowComp/NLI4CT.},
	language = {en},
	urldate = {2023-12-24},
	booktitle = {Proceedings of the {The} 17th {International} {Workshop} on {Semantic} {Evaluation} ({SemEval}-2023)},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Weiqi and Xu, Baixuan and Fang, Tianqing and Zhang, Lirong and Song, Yangqiu},
	year = {2023},
	pages = {1--9},
	file = {Wang et al. - 2023 - KnowComp at SemEval-2023 Task 7 Fine-tuning Pre-t.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\7AZJKHQT\\Wang et al. - 2023 - KnowComp at SemEval-2023 Task 7 Fine-tuning Pre-t.pdf:application/pdf},
}

@inproceedings{alissa_just-km_2023,
	address = {Toronto, Canada},
	title = {{JUST}-{KM} at {SemEval}-2023 {Task} 7: {Multi}-evidence {Natural} {Language} {Inference} using {Role}-based {Double} {Roberta}-{Large}},
	shorttitle = {{JUST}-{KM} at {SemEval}-2023 {Task} 7},
	url = {https://aclanthology.org/2023.semeval-1.61},
	doi = {10.18653/v1/2023.semeval-1.61},
	language = {en},
	urldate = {2023-12-24},
	booktitle = {Proceedings of the {The} 17th {International} {Workshop} on {Semantic} {Evaluation} ({SemEval}-2023)},
	publisher = {Association for Computational Linguistics},
	author = {Alissa, Kefah and Abdullah, Malak},
	year = {2023},
	pages = {447--452},
	file = {Alissa und Abdullah - 2023 - JUST-KM at SemEval-2023 Task 7 Multi-evidence Nat.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\I2SF6DT2\\Alissa und Abdullah - 2023 - JUST-KM at SemEval-2023 Task 7 Multi-evidence Nat.pdf:application/pdf},
}

@inproceedings{takehana_stanford_2023,
	address = {Toronto, Canada},
	title = {Stanford {MLab} at {SemEval} 2023 {Task} 7: {Neural} {Methods} for {Clinical} {Trial} {Report} {NLI}},
	shorttitle = {Stanford {MLab} at {SemEval} 2023 {Task} 7},
	url = {https://aclanthology.org/2023.semeval-1.245},
	doi = {10.18653/v1/2023.semeval-1.245},
	abstract = {We present a system for natural language inference in breast cancer clinical trial reports, as framed by SemEval 2023 Task 7: Multievidence Natural Language Inference for Clinical Trial Data. In particular, we propose a suite of techniques for two related inference subtasks: entailment and evidence retrieval. The purpose of the textual entailment identification subtask is to determine the inference relation (either entailment or contradiction) between given statement pairs, while the goal of the evidence retrieval task is to identify a set of sentences that support this inference relation. To this end, we propose fine-tuning Bio+Clinical BERT, a BERT-based model pre-trained on clinical data. Along with presenting our system, we analyze our architectural decisions in the context of our model’s accuracy and conduct an error analysis. Overall, our system ranked 20 / 40 on the entailment subtask.},
	language = {en},
	urldate = {2023-12-24},
	booktitle = {Proceedings of the {The} 17th {International} {Workshop} on {Semantic} {Evaluation} ({SemEval}-2023)},
	publisher = {Association for Computational Linguistics},
	author = {Takehana, Conner and Lim, Dylan and Kurtulus, Emirhan and Iyer, Ramya and Tanimura, Ellie and Aggarwal, Pankhuri and Cantillon, Molly and Yu, Alfred and Khan, Sarosh and Chi, Nathan},
	year = {2023},
	pages = {1769--1775},
	file = {Takehana et al. - 2023 - Stanford MLab at SemEval 2023 Task 7 Neural Metho.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\T33PNKMP\\Takehana et al. - 2023 - Stanford MLab at SemEval 2023 Task 7 Neural Metho.pdf:application/pdf},
}

@inproceedings{rajamanickam_i2r_2023,
	address = {Toronto, Canada},
	title = {{I2R} at {SemEval}-2023 {Task} 7: {Explanations}-driven {Ensemble} {Approach} for {Natural} {Language} {Inference} over {Clinical} {Trial} {Data}},
	shorttitle = {{I2R} at {SemEval}-2023 {Task} 7},
	url = {https://aclanthology.org/2023.semeval-1.226},
	doi = {10.18653/v1/2023.semeval-1.226},
	abstract = {In this paper, we describe our system for SemEval-2023 Task 7: Multi-evidence Natural Language Inference for Clinical Trial Data. Given a CTR premise, and a statement, this task involves 2 sub-tasks (i) identifying the inference relation between CTR - statement pairs (Task 1: Textual Entailment), and (ii) extracting a set of supporting facts, from the premise, to justify the label predicted in Task 1 (Task 2: Evidence Retrieval). We adopt an explanation driven NLI approach to tackle the tasks. Given a statement to verify, the idea is to first identify relevant evidence from the target CTR(s), perform evidence level inferences and then ensemble them to arrive at the final inference. We have experimented with various BERT based models and T5 models. Our final model uses T5 base that achieved better performance compared to BERT models. In summary, our system achieves F1 score of 70.1\% for Task 1 and 80.2\% for Task 2. We ranked 8th respectively under both the tasks. Moreover, ours was one of the 5 systems that ranked within the Top 10 under both tasks.},
	language = {en},
	urldate = {2023-12-24},
	booktitle = {Proceedings of the {The} 17th {International} {Workshop} on {Semantic} {Evaluation} ({SemEval}-2023)},
	publisher = {Association for Computational Linguistics},
	author = {Rajamanickam, Saravanan and Rajaraman, Kanagasabai},
	year = {2023},
	pages = {1630--1635},
	file = {Rajamanickam und Rajaraman - 2023 - I2R at SemEval-2023 Task 7 Explanations-driven En.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\KQXSFGJ5\\Rajamanickam und Rajaraman - 2023 - I2R at SemEval-2023 Task 7 Explanations-driven En.pdf:application/pdf},
}

@article{alameldin_clemson_nodate,
	title = {Clemson {NLP} at {SemEval}-2023 {Task} 7: {Applying} {GatorTron} to {Multi}-{Evidence} {Clinical} {NLI}},
	language = {en},
	author = {Alameldin, Ahmed and Williamson, Ashton},
	file = {Alameldin und Williamson - Clemson NLP at SemEval-2023 Task 7 Applying Gator.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\3M6UW3D7\\Alameldin und Williamson - Clemson NLP at SemEval-2023 Task 7 Applying Gator.pdf:application/pdf},
}

@misc{vladika_sebis_2023,
	title = {Sebis at {SemEval}-2023 {Task} 7: {A} {Joint} {System} for {Natural} {Language} {Inference} and {Evidence} {Retrieval} from {Clinical} {Trial} {Reports}},
	shorttitle = {Sebis at {SemEval}-2023 {Task} 7},
	url = {http://arxiv.org/abs/2304.13180},
	abstract = {With the increasing number of clinical trial reports generated every day, it is becoming hard to keep up with novel discoveries that inform evidence-based healthcare recommendations. To help automate this process and assist medical experts, NLP solutions are being developed. This motivated the SemEval-2023 Task 7, where the goal was to develop an NLP system for two tasks: evidence retrieval and natural language inference from clinical trial data. In this paper, we describe our two developed systems. The ﬁrst one is a pipeline system that models the two tasks separately, while the second one is a joint system that learns the two tasks simultaneously with a shared representation and a multi-task learning approach. The ﬁnal system combines their outputs in an ensemble system. We formalize the models, present their characteristics and challenges, and provide an analysis of achieved results. Our system ranked 3rd out of 40 participants with a ﬁnal submission.},
	language = {en},
	urldate = {2023-12-24},
	publisher = {arXiv},
	author = {Vladika, Juraj and Matthes, Florian},
	month = may,
	year = {2023},
	note = {arXiv:2304.13180 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 6 pages, SemEval 2023},
	file = {Vladika und Matthes - 2023 - Sebis at SemEval-2023 Task 7 A Joint System for N.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\X8Y5RDJD\\Vladika und Matthes - 2023 - Sebis at SemEval-2023 Task 7 A Joint System for N.pdf:application/pdf},
}

@inproceedings{volosincu_fii_2023,
	address = {Toronto, Canada},
	title = {{FII} {SMART} at {SemEval} 2023 {Task7}: {Multi}-evidence {Natural} {Language} {Inference} for {Clinical} {Trial} {Data}},
	shorttitle = {{FII} {SMART} at {SemEval} 2023 {Task7}},
	url = {https://aclanthology.org/2023.semeval-1.30},
	doi = {10.18653/v1/2023.semeval-1.30},
	abstract = {The “Multi-evidence Natural Language Inference for Clinical Trial Data” task at SemEval 2023 competition focuses on extracting essential information on clinical trial data, by posing two subtasks on textual entailment and evidence retrieval. In the context of SemEval, we present a comparison between a method based on the BioBERT model and a CNN model. The task is based on a collection of breast cancer Clinical Trial Reports (CTRs), statements, explanations, and labels annotated by domain expert annotators. We achieved F1 scores of 0.69 for determining the inference relation (entailment vs contradiction) between CTR - statement pairs. The implementation of our system is made available via Github1.},
	language = {en},
	urldate = {2023-12-24},
	booktitle = {Proceedings of the {The} 17th {International} {Workshop} on {Semantic} {Evaluation} ({SemEval}-2023)},
	publisher = {Association for Computational Linguistics},
	author = {Volosincu, Mihai and Lupu, Cosmin and Trandabat, Diana and Gifu, Daniela},
	year = {2023},
	pages = {212--220},
	file = {Volosincu et al. - 2023 - FII SMART at SemEval 2023 Task7 Multi-evidence Na.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\NR5K56X5\\Volosincu et al. - 2023 - FII SMART at SemEval 2023 Task7 Multi-evidence Na.pdf:application/pdf},
}

@article{feng_ynu-hpcc_nodate,
	title = {{YNU}-{HPCC} at {SemEval}-2023 {Task7}: {Multi}-evidence {Natural} {Language} {Inference} for {Clinical} {Trial} {Data} based on a {BioBERT} {Model}},
	abstract = {This paper describes the system for the YNUHPCC team in subtask 1 of the SemEval2023 Task 7: Multi-evidence Natural Language Inference for Clinical Trial Data (NLI4CT). This task requires judging the textual entailment relationship between the given CTR and the statement annotated by the expert annotator. This system is based on the finetuned Bi-directional Encoder Representation from Transformers for Biomedical Text Mining (BioBERT) model with supervised contrastive learning and back translation. Supervised contrastive learning is to enhance the classification, and back translation is to enhance the training data. Our system achieved relatively good results on the competition’s official leaderboard. The code of this paper is available at https://github.com/facanhe/SemEval-2023Task7.},
	language = {en},
	author = {Feng, Chao and Wang, Jin and Zhang, Xuejie},
	file = {Feng et al. - YNU-HPCC at SemEval-2023 Task7 Multi-evidence Nat.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\H4YAMW9D\\Feng et al. - YNU-HPCC at SemEval-2023 Task7 Multi-evidence Nat.pdf:application/pdf},
}

@inproceedings{kanakarajan_saama_2023,
	address = {Toronto, Canada},
	title = {Saama {AI} {Research} at {SemEval}-2023 {Task} 7: {Exploring} the {Capabilities} of {Flan}-{T5} for {Multi}-evidence {Natural} {Language} {Inference} in {Clinical} {Trial} {Data}},
	shorttitle = {Saama {AI} {Research} at {SemEval}-2023 {Task} 7},
	url = {https://aclanthology.org/2023.semeval-1.137},
	doi = {10.18653/v1/2023.semeval-1.137},
	abstract = {The goal of the NLI4CT task is to build a Natural Language Inference system for Clinical Trial Reports that will be used for evidence interpretation and retrieval. Large Language models have demonstrated state-of-the-art performance in various natural language processing tasks across multiple domains. We suggest using an instruction-finetuned Large Language Models (LLMs) to take on this particular task in light of these developments. We have evaluated the publicly available LLMs under zeroshot setting, and finetuned the best performing Flan-T5 model for this task. On the leaderboard, our system ranked second, with an F1 Score of 0.834 on the official test set.},
	language = {en},
	urldate = {2023-12-24},
	booktitle = {Proceedings of the {The} 17th {International} {Workshop} on {Semantic} {Evaluation} ({SemEval}-2023)},
	publisher = {Association for Computational Linguistics},
	author = {Kanakarajan, Kamal Raj and Sankarasubbu, Malaikannan},
	year = {2023},
	pages = {995--1003},
	file = {Kanakarajan und Sankarasubbu - 2023 - Saama AI Research at SemEval-2023 Task 7 Explorin.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\AP4SB95D\\Kanakarajan und Sankarasubbu - 2023 - Saama AI Research at SemEval-2023 Task 7 Explorin.pdf:application/pdf},
}

@misc{noauthor_lightning_nodate,
	title = {Lightning {AI} {\textbar} {Turn} ideas into {AI}, {Lightning} fast},
	url = {https://lightning.ai/},
	abstract = {The all-in-one platform for AI development. Code together. Prototype. Train. Scale. Serve. From your browser - with zero setup. From the creators of PyTorch Lightning.},
	language = {en},
	urldate = {2023-12-24},
}

@misc{noauthor_pytorch_nodate,
	title = {{PyTorch}},
	url = {https://pytorch.org/},
	urldate = {2023-12-24},
	file = {PyTorch:C\:\\Users\\bar35643\\Zotero\\storage\\V43WMMYJ\\pytorch.org.html:text/html},
}

@misc{noauthor_hugging_2023-1,
	title = {Hugging {Face} – {The} {AI} community building the future.},
	url = {https://huggingface.co/},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-12-24},
	month = dec,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\KCMEVDHE\\huggingface.co.html:text/html},
}

@misc{noauthor_dwaddenhealthver_entailment_nodate,
	title = {dwadden/healthver\_entailment · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/dwadden/healthver_entailment},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-12-24},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\5284JQLI\\healthver_entailment.html:text/html},
}

@misc{noauthor_snli_2023,
	title = {snli · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/snli},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-12-24},
	month = nov,
	year = {2023},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\RUMVEN7B\\snli.html:text/html},
}

@misc{noauthor_allenaiscifact_entailment_nodate,
	title = {allenai/scifact\_entailment · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/allenai/scifact_entailment},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2023-12-24},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\C98NIMPD\\scifact_entailment.html:text/html},
}

@misc{zhang_semantics-aware_2020,
	title = {Semantics-aware {BERT} for {Language} {Understanding}},
	url = {http://arxiv.org/abs/1909.02209},
	abstract = {The latest work on language representations carefully integrates contextualized features into language model training, which enables a series of success especially in various machine reading comprehension and natural language inference tasks. However, the existing language representation models including ELMo, GPT and BERT only exploit plain context-sensitive features such as character or word embeddings. They rarely consider incorporating structured semantic information which can provide rich semantics for language representation. To promote natural language understanding, we propose to incorporate explicit contextual semantics from pre-trained semantic role labeling, and introduce an improved language representation model, Semanticsaware BERT (SemBERT), which is capable of explicitly absorbing contextual semantics over a BERT backbone. SemBERT keeps the convenient usability of its BERT precursor in a light ﬁne-tuning way without substantial task-speciﬁc modiﬁcations. Compared with BERT, semantics-aware BERT is as simple in concept but more powerful. It obtains new state-ofthe-art or substantially improves results on ten reading comprehension and language inference tasks.},
	language = {en},
	urldate = {2023-12-24},
	publisher = {arXiv},
	author = {Zhang, Zhuosheng and Wu, Yuwei and Zhao, Hai and Li, Zuchao and Zhang, Shuailiang and Zhou, Xi and Zhou, Xiang},
	month = feb,
	year = {2020},
	note = {arXiv:1909.02209 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)},
	file = {Zhang et al. - 2020 - Semantics-aware BERT for Language Understanding.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\V9YVAGFX\\Zhang et al. - 2020 - Semantics-aware BERT for Language Understanding.pdf:application/pdf},
}

@misc{reimers_sentence-bert_2019,
	title = {Sentence-{BERT}: {Sentence} {Embeddings} using {Siamese} {BERT}-{Networks}},
	shorttitle = {Sentence-{BERT}},
	url = {http://arxiv.org/abs/1908.10084},
	abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.},
	language = {en},
	urldate = {2023-12-24},
	publisher = {arXiv},
	author = {Reimers, Nils and Gurevych, Iryna},
	month = aug,
	year = {2019},
	note = {arXiv:1908.10084 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Published at EMNLP 2019},
	file = {Reimers und Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese B.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\L4GKTGAN\\Reimers und Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese B.pdf:application/pdf},
}

@article{zaigrajew_contrastive_nodate,
	title = {Contrastive {Learning} for {Multi}-{Label} {Classification}},
	abstract = {Contrastive learning is one of the most popular methods in self-supervised learning in recent years, achieving state-of-the-art performance in unsupervised training of deep neural networks for computer vision tasks. However, these methods mainly deal with binary classification, leaving out multi-label tasks, where additional dependency information between classes is needed to achieve satisfying performance. Although several proposed methods in contrastive learning have been developed to learn complex cross-label structures, they rely on specific architectures that introduce constraints and computational complexity. In this work, we propose a novel approach to contrastive supervised learning for multi-label classification (MultiSupCon). The main contribution is a new loss function that allows us to gain knowledge about the degree of label overlap between pairs of samples. We analyze our MultiSupCon loss to achieve best performance on CelebA dataset with top-1 mAP of 73.9\% on the TResNet-M model, which is 2.8\% above the best results for compared contrastive learning methods reported for this architecture.},
	language = {en},
	author = {Zaigrajew, Vladimir and Zieba, Maciej},
	file = {Zaigrajew und Zieba - Contrastive Learning for Multi-Label Classificatio.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\VUEULGTK\\Zaigrajew und Zieba - Contrastive Learning for Multi-Label Classificatio.pdf:application/pdf},
}

@misc{noauthor_sentence-transformersexamplestrainingnli_nodate,
	title = {sentence-transformers/examples/training/nli at master · {UKPLab}/sentence-transformers},
	url = {https://github.com/UKPLab/sentence-transformers/tree/master/examples/training/nli},
	abstract = {Multilingual Sentence \& Image Embeddings with BERT - UKPLab/sentence-transformers},
	language = {en},
	urldate = {2023-12-24},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\NZZQTPYU\\nli.html:text/html},
}

@misc{sosnowski_distance_2022,
	title = {Distance {Metric} {Learning} {Loss} {Functions} in {Few}-{Shot} {Scenarios} of {Supervised} {Language} {Models} {Fine}-{Tuning}},
	url = {http://arxiv.org/abs/2211.15195},
	abstract = {This paper presents an analysis regarding an inﬂuence of the Distance Metric Learning (DML) loss functions on the supervised ﬁne-tuning of the language models for classiﬁcation tasks. We experimented with known datasets from SentEval Transfer Tasks.},
	language = {en},
	urldate = {2023-12-24},
	publisher = {arXiv},
	author = {Sosnowski, Witold and Seweryn, Karolina and Wróblewska, Anna and Gawrysiak, Piotr},
	month = nov,
	year = {2022},
	note = {arXiv:2211.15195 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Sosnowski et al. - 2022 - Distance Metric Learning Loss Functions in Few-Sho.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4ZVAXRDN\\Sosnowski et al. - 2022 - Distance Metric Learning Loss Functions in Few-Sho.pdf:application/pdf},
}

@misc{noauthor_nli4ct_nodate-1,
	title = {{NLI4CT}},
	url = {https://sites.google.com/view/nli4ct/semeval-2024},
	abstract = {Codalab competition
Please visit the Codalab to participate in the task, and join the Slack channel for more information and help!
See the SemEval 2023 Task 7 overview paper
See the Dataset paper},
	language = {de},
	urldate = {2023-12-29},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\9CGZJE9X\\semeval-2024.html:text/html},
}

@article{jullien_semeval-2023_nodate,
	title = {{SemEval}-2023 {Task} 7: {Multi}-{Evidence} {Natural} {Language} {Inference} for {Clinical} {Trial} {Data}},
	abstract = {This paper describes the results of SemEval 2023 task 7 – Multi-Evidence Natural Language Inference for Clinical Trial Data (NLI4CT) – consisting of 2 tasks, a Natural Language Inference (NLI) task, and an evidence selection task on clinical trial data. The proposed challenges require multi-hop biomedical and numerical reasoning, which are of significant importance to the development of systems capable of large-scale interpretation and retrieval of medical evidence, to provide personalized evidence-based care. Task 1, the entailment task, received 643 submissions from 40 participants, and Task 2, the evidence selection task, received 364 submissions from 23 participants. The tasks are challenging, with the majority of submitted systems failing to significantly outperform the majority class baseline on the entailment task, and we observe significantly better performance on the evidence selection task than on the entailment task. Increasing the number of model parameters leads to a direct increase in performance, far more significant than the effect of biomedical pre-training. Future works could explore the limitations of large models for generalization and numerical inference, and investigate methods to augment clinical datasets to allow for more rigorous testing and to facilitate finetuning. We envisage that the dataset, models, and results of this task will be useful to the biomedical NLI and evidence retrieval communities. The dataset1, competition leaderboard2, and website3 are publicly available.},
	language = {en},
	author = {Jullien, Maël and Valentino, Marco and Frost, Hannah and O’Regan, Paul and Landers, Donal and Freitas, André},
	file = {Jullien et al. - SemEval-2023 Task 7 Multi-Evidence Natural Langua.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2858ETB6\\Jullien et al. - SemEval-2023 Task 7 Multi-Evidence Natural Langua.pdf:application/pdf},
}

@misc{jullien_nli4ct_2023,
	title = {{NLI4CT}: {Multi}-{Evidence} {Natural} {Language} {Inference} for {Clinical} {Trial} {Reports}},
	shorttitle = {{NLI4CT}},
	url = {http://arxiv.org/abs/2305.03598},
	abstract = {How can we interpret and retrieve medical evidence to support clinical decisions? Clinical trial reports (CTR) amassed over the years contain indispensable information for the development of personalized medicine. However, it is practically infeasible to manually inspect over 400,000+ clinical trial reports in order to find the best evidence for experimental treatments. Natural Language Inference (NLI) offers a potential solution to this problem, by allowing the scalable computation of textual entailment. However, existing NLI models perform poorly on biomedical corpora, and previously published datasets fail to capture the full complexity of inference over CTRs.},
	language = {en},
	urldate = {2023-12-29},
	publisher = {arXiv},
	author = {Jullien, Maël and Valentino, Marco and Frost, Hannah and O'Regan, Paul and Landers, Donal and Freitas, André},
	month = oct,
	year = {2023},
	note = {arXiv:2305.03598 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: EMNLP 2023 Camera-ready, 15 pages},
	file = {Jullien et al. - 2023 - NLI4CT Multi-Evidence Natural Language Inference .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\EE6B3WZ8\\Jullien et al. - 2023 - NLI4CT Multi-Evidence Natural Language Inference .pdf:application/pdf},
}

@misc{ai_product_nodate,
	title = {Product},
	url = {https://mistral.ai/product/},
	abstract = {Frontier AI in your hands},
	language = {en-us},
	urldate = {2024-01-04},
	author = {AI, Mistral},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\XMCKUSZV\\product.html:text/html},
}

@misc{jiang_mistral_2023,
	title = {Mistral {7B}},
	url = {http://arxiv.org/abs/2310.06825},
	abstract = {We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.},
	language = {en},
	urldate = {2024-01-04},
	publisher = {arXiv},
	author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and Lavaud, Lélio Renard and Lachaux, Marie-Anne and Stock, Pierre and Scao, Teven Le and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and Sayed, William El},
	month = oct,
	year = {2023},
	note = {arXiv:2310.06825 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Models and code are available at https://mistral.ai/news/announcing-mistral-7b/},
	file = {Jiang et al. - 2023 - Mistral 7B.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\JRBCT9E2\\Jiang et al. - 2023 - Mistral 7B.pdf:application/pdf},
}

@misc{ai_mistral_nodate,
	title = {Mistral {AI} {\textbar} {Open}-weight models},
	url = {https://mistral.ai/},
	abstract = {Frontier AI in your hands},
	language = {en-us},
	urldate = {2024-01-04},
	author = {AI, Mistral},
}

@misc{huang_bias_2023,
	title = {Bias {Assessment} and {Mitigation} in {LLM}-based {Code} {Generation}},
	url = {http://arxiv.org/abs/2309.14345},
	abstract = {Utilizing state-of-the-art Large Language Models (LLMs), automatic code generation models play a pivotal role in enhancing the productivity and efficiency of software development coding procedures. As the adoption of LLMs becomes more widespread in software coding ecosystems, a pressing issue has emerged: does the generated code contain social biases, such as those related to age, gender, and race? This issue concerns the integrity, fairness, and ethical foundation of software applications that depend on the code generated by these models, yet is under-explored in the literature. This paper presents a novel bias assessment framework that is specifically designed for code generation tasks. Based on this framework, we conduct an extensive evaluation on the bias of nine state-of-the-art LLM-based code generation models. Our findings reveal that first, 31.45\% to 79.93\% code functions generated by our evaluated code generation models are biased, and 9.68\% to 37.37\% code functions’ functionality are affected by the bias, which means biases not only exist in code generation models but in some cases, directly affect the functionality of the generated code, posing risks of unintended and possibly harmful software behaviors. To mitigate bias from code generation models, we propose three mitigation strategies, which can decrease the biased code ratio to a very low level of 0.4\% to 4.57\%1.},
	language = {en},
	urldate = {2024-01-05},
	publisher = {arXiv},
	author = {Huang, Dong and Bu, Qingwen and Zhang, Jie and Xie, Xiaofei and Chen, Junjie and Cui, Heming},
	month = sep,
	year = {2023},
	note = {arXiv:2309.14345 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {Huang et al. - 2023 - Bias Assessment and Mitigation in LLM-based Code G.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2CP9PZ2J\\Huang et al. - 2023 - Bias Assessment and Mitigation in LLM-based Code G.pdf:application/pdf},
}

@misc{jiang_identifying_2023,
	title = {Identifying and {Mitigating} {Vulnerabilities} in {LLM}-{Integrated} {Applications}},
	url = {http://arxiv.org/abs/2311.16153},
	abstract = {Large language models (LLMs) are increasingly deployed as the service backend for LLM-integrated applications such as code completion and AI-powered search. Compared with the traditional usage of LLMs where users directly send queries to an LLM, LLM-integrated applications serve as middleware to refine users’ queries with domain-specific knowledge to better inform LLMs and enhance the responses. Despite numerous opportunities and benefits, LLM-integrated applications also introduce new attack surfaces. Understanding, minimizing, and eliminating these emerging attack surfaces is a new area of research. In this work, we consider a setup where the user and LLM interact via an LLM-integrated application in the middle. We focus on the communication rounds that begin with user’s queries and end with LLM-integrated application returning responses to the queries, powered by LLMs at the service backend. For this query-response protocol, we identify potential high-risk vulnerabilities that can originate from the malicious application developer or from an outsider threat initiator that is able to control the database access, manipulate and poison data that are high-risk for the user. Successful exploits of the identified vulnerabilities result in the users receiving responses tailored to the intent of a threat initiator (e.g., biased preferences for certain products). We assess such threats against LLM-integrated applications empowered by OpenAI GPT-3.5 and GPT-4. Our empirical results show that the threats can effectively bypass the restrictions and moderation policies of OpenAI, resulting in users receiving responses that contain bias, toxic content, privacy risk, and disinformation. To mitigate those threats, we identify and define four key properties, namely integrity, source identification, attack detectability, and utility preservation, that need to be satisfied by a safe LLM-integrated application. Based on these properties, we develop a lightweight, threat-agnostic defense that mitigates both insider and outsider threats. Our evaluations demonstrate the efficacy of our defense.},
	language = {en},
	urldate = {2024-01-05},
	publisher = {arXiv},
	author = {Jiang, Fengqing and Xu, Zhangchen and Niu, Luyao and Wang, Boxin and Jia, Jinyuan and Li, Bo and Poovendran, Radha},
	month = nov,
	year = {2023},
	note = {arXiv:2311.16153 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Jiang et al. - 2023 - Identifying and Mitigating Vulnerabilities in LLM-.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\WFI64YM6\\Jiang et al. - 2023 - Identifying and Mitigating Vulnerabilities in LLM-.pdf:application/pdf},
}

@misc{jiang_identifying_2023-1,
	title = {Identifying and {Mitigating} {Vulnerabilities} in {LLM}-{Integrated} {Applications}},
	url = {http://arxiv.org/abs/2311.16153},
	abstract = {Large language models (LLMs) are increasingly deployed as the service backend for LLM-integrated applications such as code completion and AI-powered search. Compared with the traditional usage of LLMs where users directly send queries to an LLM, LLM-integrated applications serve as middleware to refine users’ queries with domain-specific knowledge to better inform LLMs and enhance the responses. Despite numerous opportunities and benefits, LLM-integrated applications also introduce new attack surfaces. Understanding, minimizing, and eliminating these emerging attack surfaces is a new area of research. In this work, we consider a setup where the user and LLM interact via an LLM-integrated application in the middle. We focus on the communication rounds that begin with user’s queries and end with LLM-integrated application returning responses to the queries, powered by LLMs at the service backend. For this query-response protocol, we identify potential high-risk vulnerabilities that can originate from the malicious application developer or from an outsider threat initiator that is able to control the database access, manipulate and poison data that are high-risk for the user. Successful exploits of the identified vulnerabilities result in the users receiving responses tailored to the intent of a threat initiator (e.g., biased preferences for certain products). We assess such threats against LLM-integrated applications empowered by OpenAI GPT-3.5 and GPT-4. Our empirical results show that the threats can effectively bypass the restrictions and moderation policies of OpenAI, resulting in users receiving responses that contain bias, toxic content, privacy risk, and disinformation. To mitigate those threats, we identify and define four key properties, namely integrity, source identification, attack detectability, and utility preservation, that need to be satisfied by a safe LLM-integrated application. Based on these properties, we develop a lightweight, threat-agnostic defense that mitigates both insider and outsider threats. Our evaluations demonstrate the efficacy of our defense.},
	language = {en},
	urldate = {2024-01-05},
	publisher = {arXiv},
	author = {Jiang, Fengqing and Xu, Zhangchen and Niu, Luyao and Wang, Boxin and Jia, Jinyuan and Li, Bo and Poovendran, Radha},
	month = nov,
	year = {2023},
	note = {arXiv:2311.16153 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Jiang et al. - 2023 - Identifying and Mitigating Vulnerabilities in LLM-.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\MYJBKBI4\\Jiang et al. - 2023 - Identifying and Mitigating Vulnerabilities in LLM-.pdf:application/pdf},
}

@misc{noauthor_kaggle_nodate,
	title = {Kaggle: {Your} {Home} for {Data} {Science}},
	url = {https://www.kaggle.com/},
	urldate = {2024-01-08},
	file = {Kaggle\: Your Home for Data Science:C\:\\Users\\bar35643\\Zotero\\storage\\6NIFI24Y\\www.kaggle.com.html:text/html},
}

@misc{noauthor_google_nodate,
	title = {Google {Colaboratory}},
	url = {https://colab.research.google.com/},
	language = {en},
	urldate = {2024-01-08},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\IDJ9QED8\\colab.research.google.com.html:text/html},
}

@misc{noauthor_lightning_nodate-1,
	title = {Lightning {AI} {\textbar} {Turn} ideas into {AI}, {Lightning} fast},
	url = {https://lightning.ai/},
	abstract = {The all-in-one platform for AI development. Code together. Prototype. Train. Scale. Serve. From your browser - with zero setup. From the creators of PyTorch Lightning.},
	language = {en},
	urldate = {2024-01-08},
}

@misc{noauthor_hugging_2024,
	title = {Hugging {Face} – {The} {AI} community building the future.},
	url = {https://huggingface.co/},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-01-08},
	month = jan,
	year = {2024},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\TTZGJHS2\\huggingface.co.html:text/html},
}

@misc{zhou_thifly_2023,
	title = {{THiFLY} {Research} at {SemEval}-2023 {Task} 7: {A} {Multi}-granularity {System} for {CTR}-based {Textual} {Entailment} and {Evidence} {Retrieval}},
	shorttitle = {{THiFLY} {Research} at {SemEval}-2023 {Task} 7},
	url = {http://arxiv.org/abs/2306.01245},
	abstract = {The NLI4CT task aims to entail hypotheses based on Clinical Trial Reports (CTRs) and retrieve the corresponding evidence supporting the justification. This task poses a significant challenge, as verifying hypotheses in the NLI4CT task requires the integration of multiple pieces of evidence from one or two CTR(s) and the application of diverse levels of reasoning, including textual and numerical. To address these problems, we present a multi-granularity system for CTR-based textual entailment and evidence retrieval in this paper. Specifically, we construct a Multigranularity Inference Network (MGNet) that exploits sentence-level and token-level encoding to handle both textual entailment and evidence retrieval tasks. Moreover, we enhance the numerical inference capability of the system by leveraging a T5-based model, SciFive, which is pre-trained on the medical corpus. Model ensembling and a joint inference method are further utilized in the system to increase the stability and consistency of inference. The system achieves f1-scores of 0.856 and 0.853 on textual entailment and evidence retrieval tasks, resulting in the best performance on both subtasks. The experimental results corroborate the effectiveness of our proposed method. Our code is publicly available at https:// github.com/THUMLP/NLI4CT.},
	language = {en},
	urldate = {2024-01-08},
	publisher = {arXiv},
	author = {Zhou, Yuxuan and Jin, Ziyu and Li, Meiwei and Li, Miao and Liu, Xien and You, Xinxin and Wu, Ji},
	month = jun,
	year = {2023},
	note = {arXiv:2306.01245 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted by SemEval2023},
	file = {2306.01245.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\ERKIBDU3\\2306.01245.pdf:application/pdf},
}

@article{alameldin_clemson_nodate-1,
	title = {Clemson {NLP} at {SemEval}-2023 {Task} 7: {Applying} {GatorTron} to {Multi}-{Evidence} {Clinical} {NLI}},
	language = {en},
	author = {Alameldin, Ahmed and Williamson, Ashton},
	file = {Alameldin und Williamson - Clemson NLP at SemEval-2023 Task 7 Applying Gator.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\GTFMRPAI\\Alameldin und Williamson - Clemson NLP at SemEval-2023 Task 7 Applying Gator.pdf:application/pdf},
}

@article{you_graph_nodate,
	title = {Graph {Contrastive} {Learning} with {Augmentations}},
	abstract = {Generalizable, transferrable, and robust representation learning on graph-structured data remains a challenge for current graph neural networks (GNNs). Unlike what has been developed for convolutional neural networks (CNNs) for image data, self-supervised learning and pre-training are less explored for GNNs. In this paper, we propose a graph contrastive learning (GraphCL) framework for learning unsupervised representations of graph data. We ﬁrst design four types of graph augmentations to incorporate various priors. We then systematically study the impact of various combinations of graph augmentations on multiple datasets, in four different settings: semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. The results show that, even without tuning augmentation extents nor using sophisticated GNN architectures, our GraphCL framework can produce graph representations of similar or better generalizability, transferrability, and robustness compared to state-of-the-art methods. We also investigate the impact of parameterized graph augmentation extents and patterns, and observe further performance gains in preliminary experiments. Our codes are available at: https://github.com/Shen-Lab/GraphCL.},
	language = {en},
	author = {You, Yuning and Chen, Tianlong and Sui, Yongduo and Chen, Ting and Wang, Zhangyang and Shen, Yang},
	file = {You et al. - Graph Contrastive Learning with Augmentations.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\HC97RZII\\You et al. - Graph Contrastive Learning with Augmentations.pdf:application/pdf},
}

@article{feng_how_nodate,
	title = {How {Powerful} are {K}-hop {Message} {Passing} {Graph} {Neural} {Networks}},
	abstract = {The most popular design paradigm for Graph Neural Networks (GNNs) is 1-hop message passing—aggregating information from 1-hop neighbors repeatedly. However, the expressive power of 1-hop message passing is bounded by the WeisfeilerLehman (1-WL) test. Recently, researchers extended 1-hop message passing to K-hop message passing by aggregating information from K-hop neighbors of nodes simultaneously. However, there is no work on analyzing the expressive power of K-hop message passing. In this work, we theoretically characterize the expressive power of K-hop message passing. Speciﬁcally, we ﬁrst formally differentiate two different kernels of K-hop message passing which are often misused in previous works. We then characterize the expressive power of K-hop message passing by showing that it is more powerful than 1-WL and can distinguish almost all regular graphs. Despite the higher expressive power, we show that K-hop message passing still cannot distinguish some simple regular graphs and its expressive power is bounded by 3-WL. To further enhance its expressive power, we introduce a KP-GNN framework, which improves K-hop message passing by leveraging the peripheral subgraph information in each hop. We show that KP-GNN can distinguish many distance regular graphs which could not be distinguished by previous distance encoding or 3-WL methods. Experimental results verify the expressive power and effectiveness of KP-GNN. KP-GNN achieves competitive results across all benchmark datasets.},
	language = {en},
	author = {Feng, Jiarui and Chen, Yixin and Li, Fuhai and Sarkar, Anindya and Zhang, Muhan},
	file = {Feng et al. - How Powerful are K-hop Message Passing Graph Neura.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\RUN8M7HG\\Feng et al. - How Powerful are K-hop Message Passing Graph Neura.pdf:application/pdf},
}

@article{ying_transformers_nodate,
	title = {Do {Transformers} {Really} {Perform} {Bad} for {Graph} {Representation}?},
	abstract = {The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding the structural information of graphs, many popular GNN variants could be covered as the special cases of Graphormer. The code and models of Graphormer will be made publicly available at https://github.com/Microsoft/Graphormer.},
	language = {en},
	author = {Ying, Chengxuan and Cai, Tianle and Luo, Shengjie and Zheng, Shuxin and Ke, Guolin and He, Di and Shen, Yanming and Liu, Tie-Yan},
	file = {Ying et al. - Do Transformers Really Perform Bad for Graph Repre.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\YXRWVQY8\\Ying et al. - Do Transformers Really Perform Bad for Graph Repre.pdf:application/pdf},
}

@article{bojchevski_deep_nodate,
	title = {Deep {Gaussian} {Embedding} of {Graphs}:  {Unsupervised} {Inductive} {Learning} via {Ranking}},
	abstract = {Methods that learn representations of nodes in a graph play a critical role in network analysis since they enable many downstream learning tasks. We propose Graph2Gauss – an approach that can efﬁciently learn versatile node embeddings on large scale (attributed) graphs that show strong performance on tasks such as link prediction and node classiﬁcation. Unlike most approaches that represent nodes as point vectors in a low-dimensional continuous space, we embed each node as a Gaussian distribution, allowing us to capture uncertainty about the representation. Furthermore, we propose an unsupervised method that handles inductive learning scenarios and is applicable to different types of graphs: plain/attributed, directed/undirected. By leveraging both the network structure and the associated node attributes, we are able to generalize to unseen nodes without additional training. To learn the embeddings we adopt a personalized ranking formulation w.r.t. the node distances that exploits the natural ordering of the nodes imposed by the network structure. Experiments on real world networks demonstrate the high performance of our approach, outperforming state-of-the-art network embedding methods on several different tasks. Additionally, we demonstrate the beneﬁts of modeling uncertainty – by analyzing it we can estimate neighborhood diversity and detect the intrinsic latent dimensionality of a graph.},
	language = {en},
	author = {Bojchevski, Aleksandar and Guennemann, Stephan},
	file = {Bojchevski und Guennemann - Deep Gaussian Embedding of Graphs  Unsupervised I.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\PYNIAV7N\\Bojchevski und Guennemann - Deep Gaussian Embedding of Graphs  Unsupervised I.pdf:application/pdf},
}

@article{cheng_wiener_2023,
	title = {Wiener {Graph} {Deconvolutional} {Network} {Improves} {Graph} {Self}-{Supervised} {Learning}},
	volume = {37},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/25870},
	doi = {10.1609/aaai.v37i6.25870},
	abstract = {Graph self-supervised learning (SSL) has been vastly employed to learn representations from unlabeled graphs. Existing methods can be roughly divided into predictive learning and contrastive learning, where the latter one attracts more research attention with better empirical performance. We argue that, however, predictive models weaponed with powerful decoder could achieve comparable or even better representation power than contrastive models. In this work, we propose a Wiener Graph Deconvolutional Network (WGDN), an augmentation-adaptive decoder empowered by graph wiener ﬁlter to perform information reconstruction. Theoretical analysis proves the superior reconstruction ability of graph wiener ﬁlter. Extensive experimental results on various datasets demonstrate the effectiveness of our approach.},
	language = {en},
	number = {6},
	urldate = {2024-01-12},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Cheng, Jiashun and Li, Man and Li, Jia and Tsung, Fugee},
	month = jun,
	year = {2023},
	pages = {7131--7139},
	file = {Cheng et al. - 2023 - Wiener Graph Deconvolutional Network Improves Grap.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\EGTHJJ54\\Cheng et al. - 2023 - Wiener Graph Deconvolutional Network Improves Grap.pdf:application/pdf},
}

@misc{dwivedi_generalization_2021,
	title = {A {Generalization} of {Transformer} {Networks} to {Graphs}},
	url = {http://arxiv.org/abs/2012.09699},
	abstract = {We propose a generalization of transformer neural network architecture for arbitrary graphs. The original transformer was designed for Natural Language Processing (NLP), which operates on fully connected graphs representing all connections between the words in a sequence. Such architecture does not leverage the graph connectivity inductive bias, and can perform poorly when the graph topology is important and has not been encoded into the node features. We introduce a graph transformer with four new properties compared to the standard model. First, the attention mechanism is a function of the neighborhood connectivity for each node in the graph. Second, the positional encoding is represented by the Laplacian eigenvectors, which naturally generalize the sinusoidal positional encodings often used in NLP. Third, the layer normalization is replaced by a batch normalization layer, which provides faster training and better generalization performance. Finally, the architecture is extended to edge feature representation, which can be critical to tasks s.a. chemistry (bond type) or link prediction (entity relationship in knowledge graphs). Numerical experiments on a graph benchmark demonstrate the performance of the proposed graph transformer architecture. This work closes the gap between the original transformer, which was designed for the limited case of line graphs, and graph neural networks, that can work with arbitrary graphs. As our architecture is simple and generic, we believe it can be used as a black box for future applications that wish to consider transformer and graphs.},
	language = {en},
	urldate = {2024-01-12},
	publisher = {arXiv},
	author = {Dwivedi, Vijay Prakash and Bresson, Xavier},
	month = jan,
	year = {2021},
	note = {arXiv:2012.09699 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: AAAI 2021 Workshop on Deep Learning on Graphs: Methods and Applications (DLG-AAAI 2021); Code at https://github.com/graphdeeplearning/graphtransformer},
	file = {Dwivedi und Bresson - 2021 - A Generalization of Transformer Networks to Graphs.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\NGFZ95Q3\\Dwivedi und Bresson - 2021 - A Generalization of Transformer Networks to Graphs.pdf:application/pdf},
}

@misc{reimers_sentence-bert_2019-1,
	title = {Sentence-{BERT}: {Sentence} {Embeddings} using {Siamese} {BERT}-{Networks}},
	shorttitle = {Sentence-{BERT}},
	url = {http://arxiv.org/abs/1908.10084},
	abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.},
	language = {en},
	urldate = {2024-01-13},
	publisher = {arXiv},
	author = {Reimers, Nils and Gurevych, Iryna},
	month = aug,
	year = {2019},
	note = {arXiv:1908.10084 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Published at EMNLP 2019},
	file = {Reimers und Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese B.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\CTIRMJ8Z\\Reimers und Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese B.pdf:application/pdf},
}

@misc{gao_simcse_2022-1,
	title = {{SimCSE}: {Simple} {Contrastive} {Learning} of {Sentence} {Embeddings}},
	shorttitle = {{SimCSE}},
	url = {http://arxiv.org/abs/2104.08821},
	abstract = {This paper presents SimCSE, a simple contrastive learning framework that greatly advances state-of-the-art sentence embeddings. We first describe an unsupervised approach, which takes an input sentence and predicts itself in a contrastive objective, with only standard dropout used as noise. This simple method works surprisingly well, performing on par with previous supervised counterparts. We find that dropout acts as minimal data augmentation, and removing it leads to a representation collapse. Then, we propose a supervised approach, which incorporates annotated pairs from natural language inference datasets into our contrastive learning framework by using "entailment" pairs as positives and "contradiction" pairs as hard negatives. We evaluate SimCSE on standard semantic textual similarity (STS) tasks, and our unsupervised and supervised models using BERT base achieve an average of 76.3\% and 81.6\% Spearman's correlation respectively, a 4.2\% and 2.2\% improvement compared to the previous best results. We also show -- both theoretically and empirically -- that the contrastive learning objective regularizes pre-trained embeddings' anisotropic space to be more uniform, and it better aligns positive pairs when supervised signals are available.},
	language = {en},
	urldate = {2024-01-13},
	publisher = {arXiv},
	author = {Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
	month = may,
	year = {2022},
	note = {arXiv:2104.08821 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Accepted to EMNLP 2021. The code and pre-trained models are available at https://github.com/princeton-nlp/simcse},
	file = {Gao et al. - 2022 - SimCSE Simple Contrastive Learning of Sentence Em.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\95ELDMHM\\Gao et al. - 2022 - SimCSE Simple Contrastive Learning of Sentence Em.pdf:application/pdf},
}

@article{hamilton_inductive_nodate,
	title = {Inductive {Representation} {Learning} on {Large} {Graphs}},
	abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general inductive framework that leverages node feature information (e.g., text attributes) to efﬁciently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node’s local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classiﬁcation benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
	language = {en},
	author = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
	file = {Hamilton et al. - Inductive Representation Learning on Large Graphs.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4AG87Q8K\\Hamilton et al. - Inductive Representation Learning on Large Graphs.pdf:application/pdf},
}

@misc{velickovic_graph_2018,
	title = {Graph {Attention} {Networks}},
	url = {http://arxiv.org/abs/1710.10903},
	abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods’ features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).},
	language = {en},
	urldate = {2024-01-13},
	publisher = {arXiv},
	author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
	month = feb,
	year = {2018},
	note = {arXiv:1710.10903 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Social and Information Networks, Statistics - Machine Learning},
	annote = {Comment: To appear at ICLR 2018. 12 pages, 2 figures},
	file = {Veličković et al. - 2018 - Graph Attention Networks.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\AM88JFGB\\Veličković et al. - 2018 - Graph Attention Networks.pdf:application/pdf},
}

@misc{xu_how_2019,
	title = {How {Powerful} are {Graph} {Neural} {Networks}?},
	url = {http://arxiv.org/abs/1810.00826},
	abstract = {Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classiﬁcation tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the WeisfeilerLehman graph isomorphism test. We empirically validate our theoretical ﬁndings on a number of graph classiﬁcation benchmarks, and demonstrate that our model achieves state-of-the-art performance.},
	language = {en},
	urldate = {2024-01-13},
	publisher = {arXiv},
	author = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
	month = feb,
	year = {2019},
	note = {arXiv:1810.00826 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {Xu et al. - 2019 - How Powerful are Graph Neural Networks.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\EXID6447\\Xu et al. - 2019 - How Powerful are Graph Neural Networks.pdf:application/pdf},
}

@article{gilmer_neural_nodate,
	title = {Neural {Message} {Passing} for {Quantum} {Chemistry}},
	abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to ﬁnd a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
	language = {en},
	author = {Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
	file = {Gilmer et al. - Neural Message Passing for Quantum Chemistry.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\NB5A3LXL\\Gilmer et al. - Neural Message Passing for Quantum Chemistry.pdf:application/pdf},
}

@misc{bruna_spectral_2014,
	title = {Spectral {Networks} and {Locally} {Connected} {Networks} on {Graphs}},
	url = {http://arxiv.org/abs/1312.6203},
	abstract = {Convolutional Neural Networks are extremely efﬁcient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals deﬁned on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for lowdimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efﬁcient deep architectures.},
	language = {en},
	urldate = {2024-01-13},
	publisher = {arXiv},
	author = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
	month = may,
	year = {2014},
	note = {arXiv:1312.6203 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 14 pages},
	file = {Bruna et al. - 2014 - Spectral Networks and Locally Connected Networks o.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\K5Q9LW3T\\Bruna et al. - 2014 - Spectral Networks and Locally Connected Networks o.pdf:application/pdf},
}

@misc{noauthor_vapnikchervonenkis_nodate,
	title = {The {Vapnik}–{Chervonenkis} dimension of graph and recursive neural networks - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608018302363},
	urldate = {2024-01-13},
	file = {The Vapnik–Chervonenkis dimension of graph and recursive neural networks - ScienceDirect:C\:\\Users\\bar35643\\Zotero\\storage\\3RQALCXV\\S0893608018302363.html:text/html},
}

@misc{zhang_hierarchical_2022,
	title = {Hierarchical {Graph} {Transformer} with {Adaptive} {Node} {Sampling}},
	url = {http://arxiv.org/abs/2210.03930},
	abstract = {The Transformer architecture has achieved remarkable success in a number of domains including natural language processing and computer vision. However, when it comes to graph-structured data, transformers have not achieved competitive performance, especially on large graphs. In this paper, we identify the main deﬁciencies of current graph transformers: (1) Existing node sampling strategies in Graph Transformers are agnostic to the graph characteristics and the training process. (2) Most sampling strategies only focus on local neighbors and neglect the long-range dependencies in the graph. We conduct experimental investigations on synthetic datasets to show that existing sampling strategies are sub-optimal. To tackle the aforementioned problems, we formulate the optimization strategies of node sampling in Graph Transformer as an adversary bandit problem, where the rewards are related to the attention weights and can vary in the training procedure. Meanwhile, we propose a hierarchical attention scheme with graph coarsening to capture the long-range interactions while reducing computational complexity. Finally, we conduct extensive experiments on real-world datasets to demonstrate the superiority of our method over existing graph transformers and popular GNNs. Our code is open-sourced at https://github.com/zaixizhang/ANS-GT.},
	language = {en},
	urldate = {2024-01-15},
	publisher = {arXiv},
	author = {Zhang, Zaixi and Liu, Qi and Hu, Qingyong and Lee, Chee-Kong},
	month = oct,
	year = {2022},
	note = {arXiv:2210.03930 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Accepted by NeurIPS 2022},
	file = {Zhang et al. - 2022 - Hierarchical Graph Transformer with Adaptive Node .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\2B4Q65SB\\Zhang et al. - 2022 - Hierarchical Graph Transformer with Adaptive Node .pdf:application/pdf},
}

@misc{zhao_gophormer_2021,
	title = {Gophormer: {Ego}-{Graph} {Transformer} for {Node} {Classification}},
	shorttitle = {Gophormer},
	url = {http://arxiv.org/abs/2110.13094},
	abstract = {Transformers have achieved remarkable performance in a myriad of fields including natural language processing and computer vision. However, when it comes to the graph mining area, where graph neural network (GNN) has been the dominant paradigm, transformers haven’t achieved competitive performance, especially on the node classification task. Existing graph transformer models typically adopt fully-connected attention mechanism on the whole input graph and thus suffer from severe scalability issues and are intractable to train in data insufficient cases. To alleviate these issues, we propose a novel Gophormer model which applies transformers on ego-graphs instead of full-graphs. Specifically, Node2Seq module is proposed to sample ego-graphs as the input of transformers, which alleviates the challenge of scalability and serves as an effective data augmentation technique to boost model performance. Moreover, different from the feature-based attention strategy in vanilla transformers, we propose a proximity-enhanced attention mechanism to capture the fine-grained structural bias. In order to handle the uncertainty introduced by the ego-graph sampling, we further propose a consistency regularization and a multi-sample inference strategy for stabilized training and testing, respectively. Extensive experiments on six benchmark datasets are conducted to demonstrate the superiority of Gophormer over existing graph transformers and popular GNNs, revealing the promising future of graph transformers.},
	language = {en},
	urldate = {2024-01-15},
	publisher = {arXiv},
	author = {Zhao, Jianan and Li, Chaozhuo and Wen, Qianlong and Wang, Yiqi and Liu, Yuming and Sun, Hao and Xie, Xing and Ye, Yanfang},
	month = oct,
	year = {2021},
	note = {arXiv:2110.13094 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Zhao et al. - 2021 - Gophormer Ego-Graph Transformer for Node Classifi.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4IEYR39C\\Zhao et al. - 2021 - Gophormer Ego-Graph Transformer for Node Classifi.pdf:application/pdf},
}

@article{weisfeiler_reduction_nodate,
	title = {{THE} {REDUCTION} {OF} {A} {GRAPH} {TO} {CANONICAL} {FORM} {AND} {THE} {ALGEBRA} {WHICH} {APPEARS} {THEREIN}},
	abstract = {We consider an algorithm for the reduction of a given ﬁnite multigraph Γ to canonical form. Therein the new invariant of a graph appears — the algebra A(Γ). The study of properties of the algebra A(Γ) turns out to be helpful in solving a number of graph-theoretic problems. We pose and discuss some conjectures on the relation between properties of the algebra A(Γ) and the automorphism group Aut(Γ) of a graph Γ. We give an example of undirected graph Γ whose algebra A(Γ) coincides with the group algebra of some noncommutative group.},
	language = {en},
	author = {Weisfeiler, B Yu and Leman, A A},
	file = {Weisfeiler und Leman - THE REDUCTION OF A GRAPH TO CANONICAL FORM AND THE.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\DA7ZFKIC\\Weisfeiler und Leman - THE REDUCTION OF A GRAPH TO CANONICAL FORM AND THE.pdf:application/pdf},
}

@misc{errica_fair_2022,
	title = {A {Fair} {Comparison} of {Graph} {Neural} {Networks} for {Graph} {Classification}},
	url = {http://arxiv.org/abs/1912.09893},
	abstract = {Experimental reproducibility and replicability are critical topics in machine learning. Authors have often raised concerns about their lack in scientiﬁc publications to improve the quality of the ﬁeld. Recently, the graph representation learning ﬁeld has attracted the attention of a wide research community, which resulted in a large stream of works. As such, several Graph Neural Network models have been developed to effectively tackle graph classiﬁcation. However, experimental procedures often lack rigorousness and are hardly reproducible. Motivated by this, we provide an overview of common practices that should be avoided to fairly compare with the state of the art. To counter this troubling trend, we ran more than 47000 experiments in a controlled and uniform framework to re-evaluate ﬁve popular models across nine common benchmarks. Moreover, by comparing GNNs with structure-agnostic baselines we provide convincing evidence that, on some datasets, structural information has not been exploited yet. We believe that this work can contribute to the development of the graph learning ﬁeld, by providing a much needed grounding for rigorous evaluations of graph classiﬁcation models.},
	language = {en},
	urldate = {2024-01-15},
	publisher = {arXiv},
	author = {Errica, Federico and Podda, Marco and Bacciu, Davide and Micheli, Alessio},
	month = feb,
	year = {2022},
	note = {arXiv:1912.09893 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Extended version of the paper published at the International Conference on Learning Representations (ICLR), 2020. Additional results are shown in the appendix},
	file = {Errica et al. - 2022 - A Fair Comparison of Graph Neural Networks for Gra.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\ZBE8Y8JA\\Errica et al. - 2022 - A Fair Comparison of Graph Neural Networks for Gra.pdf:application/pdf},
}

@misc{hou_graphmae_2022,
	title = {{GraphMAE}: {Self}-{Supervised} {Masked} {Graph} {Autoencoders}},
	shorttitle = {{GraphMAE}},
	url = {http://arxiv.org/abs/2205.10803},
	abstract = {Self-supervised learning (SSL) has been extensively explored in recent years. Particularly, generative SSL has seen emerging success in natural language processing and other AI fields, such as the wide adoption of BERT and GPT. Despite this, contrastive learning—which heavily relies on structural data augmentation and complicated training strategies—has been the dominant approach in graph SSL, while the progress of generative SSL on graphs, especially graph autoencoders (GAEs), has thus far not reached the potential as promised in other fields. In this paper, we identify and examine the issues that negatively impact the development of GAEs, including their reconstruction objective, training robustness, and error metric. We present a masked graph autoencoder GraphMAE1 that mitigates these issues for generative self-supervised graph pretraining. Instead of reconstructing graph structures, we propose to focus on feature reconstruction with both a masking strategy and scaled cosine error that benefit the robust training of GraphMAE. We conduct extensive experiments on 21 public datasets for three different graph learning tasks. The results manifest that GraphMAE—a simple graph autoencoder with careful designs—can consistently generate outperformance over both contrastive and generative state-of-the-art baselines. This study provides an understanding of graph autoencoders and demonstrates the potential of generative self-supervised pre-training on graphs.},
	language = {en},
	urldate = {2024-01-16},
	publisher = {arXiv},
	author = {Hou, Zhenyu and Liu, Xiao and Cen, Yukuo and Dong, Yuxiao and Yang, Hongxia and Wang, Chunjie and Tang, Jie},
	month = jul,
	year = {2022},
	note = {arXiv:2205.10803 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 11 pages; Accepted to KDD'22},
	file = {Hou et al. - 2022 - GraphMAE Self-Supervised Masked Graph Autoencoder.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\G2X4NHFW\\Hou et al. - 2022 - GraphMAE Self-Supervised Masked Graph Autoencoder.pdf:application/pdf},
}

@misc{chen_path-augmented_2019,
	title = {Path-{Augmented} {Graph} {Transformer} {Network}},
	url = {http://arxiv.org/abs/1905.12712},
	abstract = {Much of the recent work on learning molecular representations has been based on Graph Convolution Networks (GCN). These models rely on local aggregation operations and can therefore miss higher-order graph properties. To remedy this, we propose Path-Augmented Graph Transformer Networks (PAGTN) that are explicitly built on longer-range dependencies in graphstructured data. Speciﬁcally, we use path features in molecular graphs to create global attention layers. We compare our PAGTN model against the GCN model and show that our model consistently outperforms GCNs on molecular property prediction datasets including quantum chemistry (QM7, QM8, QM9), physical chemistry (ESOL, Lipophilictiy) and biochemistry (BACE, BBBP)2.},
	language = {en},
	urldate = {2024-01-16},
	publisher = {arXiv},
	author = {Chen, Benson and Barzilay, Regina and Jaakkola, Tommi},
	month = may,
	year = {2019},
	note = {arXiv:1905.12712 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Appears in ICML LRG Workshop},
	file = {Chen et al. - 2019 - Path-Augmented Graph Transformer Network.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\5XYQBCRS\\Chen et al. - 2019 - Path-Augmented Graph Transformer Network.pdf:application/pdf},
}

@misc{mei_notable_2023,
	title = {{NOTABLE}: {Transferable} {Backdoor} {Attacks} {Against} {Prompt}-based {NLP} {Models}},
	shorttitle = {{NOTABLE}},
	url = {http://arxiv.org/abs/2305.17826},
	abstract = {Prompt-based learning is vulnerable to backdoor attacks. Existing backdoor attacks against prompt-based models consider injecting backdoors into the entire embedding layers or word embedding vectors. Such attacks can be easily affected by retraining on downstream tasks and with different prompting strategies, limiting the transferability of backdoor attacks. In this work, we propose transferable backdoor attacks against prompt-based models, called NOTABLE, which is independent of downstream tasks and prompting strategies. Specifically, NOTABLE injects backdoors into the encoders of PLMs by utilizing an adaptive verbalizer to bind triggers to specific words (i.e., anchors). It activates the backdoor by pasting input with triggers to reach adversary-desired anchors, achieving independence from downstream tasks and prompting strategies. We conduct experiments on six NLP tasks, three popular models, and three prompting strategies. Empirical results show that NOTABLE achieves superior attack performance (i.e., attack success rate over 90\% on all the datasets), and outperforms two state-ofthe-art baselines. Evaluations on three defenses show the robustness of NOTABLE. Our code can be found at https://github.com/RU-SystemSoftware-and-Security/Notable.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Mei, Kai and Li, Zheng and Wang, Zhenting and Zhang, Yang and Ma, Shiqing},
	month = may,
	year = {2023},
	note = {arXiv:2305.17826 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security},
	file = {Mei et al. - 2023 - NOTABLE Transferable Backdoor Attacks Against Pro.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\SKSVI3G6\\Mei et al. - 2023 - NOTABLE Transferable Backdoor Attacks Against Pro.pdf:application/pdf},
}

@misc{carlini_are_2023,
	title = {Are aligned neural networks adversarially aligned?},
	url = {http://arxiv.org/abs/2306.15447},
	abstract = {Large language models are now tuned to align with the goals of their creators, namely to be “helpful and harmless.” These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study to what extent these models remain aligned, even when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Carlini, Nicholas and Nasr, Milad and Choquette-Choo, Christopher A. and Jagielski, Matthew and Gao, Irena and Awadalla, Anas and Koh, Pang Wei and Ippolito, Daphne and Lee, Katherine and Tramer, Florian and Schmidt, Ludwig},
	month = jun,
	year = {2023},
	note = {arXiv:2306.15447 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Carlini et al. - 2023 - Are aligned neural networks adversarially aligned.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\YUN8QDT3\\Carlini et al. - 2023 - Are aligned neural networks adversarially aligned.pdf:application/pdf},
}

@article{liu_adversarial_2023,
	title = {Adversarial {Attacks} on {Large} {Language} {Model}-{Based} {System} and {Mitigating} {Strategies}: {A} {Case} {Study} on {ChatGPT}},
	volume = {2023},
	issn = {1939-0122, 1939-0114},
	shorttitle = {Adversarial {Attacks} on {Large} {Language} {Model}-{Based} {System} and {Mitigating} {Strategies}},
	url = {https://www.hindawi.com/journals/scn/2023/8691095/},
	doi = {10.1155/2023/8691095},
	abstract = {Machine learning algorithms are at the forefront of the development of advanced information systems. The rapid progress in machine learning technology has enabled cutting-edge large language models (LLMs), represented by GPT-3 and ChatGPT, to perform a wide range of NLP tasks with a stunning performance. However, research on adversarial machine learning highlights the need for these intelligent systems to be more robust. Adversarial machine learning aims to evaluate attack and defense mechanisms to prevent the malicious exploitation of these systems. In the case of ChatGPT, adversarial induction prompt can cause the model to generate toxic texts that could pose serious security risks or propagate false information. To address this challenge, we first analyze the effectiveness of inducing attacks on ChatGPT. Then, two effective mitigating mechanisms are proposed. The first is a training-free prefix prompt mechanism to detect and prevent the generation of toxic texts. The second is a RoBERTa-based mechanism that identifies manipulative or misleading input text via external detection models. The availability of this method is demonstrated through experiments.},
	language = {en},
	urldate = {2024-01-19},
	journal = {Security and Communication Networks},
	author = {Liu, Bowen and Xiao, Boao and Jiang, Xutong and Cen, Siyuan and He, Xin and Dou, Wanchun},
	editor = {Chen, Huaming},
	month = jun,
	year = {2023},
	pages = {1--10},
	file = {Liu et al. - 2023 - Adversarial Attacks on Large Language Model-Based .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\WYAZWGWR\\Liu et al. - 2023 - Adversarial Attacks on Large Language Model-Based .pdf:application/pdf},
}

@misc{wei_jailbroken_2023,
	title = {Jailbroken: {How} {Does} {LLM} {Safety} {Training} {Fail}?},
	shorttitle = {Jailbroken},
	url = {http://arxiv.org/abs/2307.02483},
	abstract = {Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of “jailbreak” attacks on early releases of ChatGPT that elicit undesired behavior. Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created. We hypothesize two failure modes of safety training: competing objectives and mismatched generalization. Competing objectives arise when a model’s capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist. We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI’s GPT-4 and Anthropic’s Claude v1.3, against both existing and newly designed attacks. We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models. Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models’ red-teaming evaluation sets and outperform existing ad hoc jailbreaks. Our analysis emphasizes the need for safety-capability parity—that safety mechanisms should be as sophisticated as the underlying model—and argues against the idea that scaling alone can resolve these safety failure modes.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
	month = jul,
	year = {2023},
	note = {arXiv:2307.02483 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security},
	annote = {Comment:},
	file = {Wei et al. - 2023 - Jailbroken How Does LLM Safety Training Fail.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\VYGFSDYN\\Wei et al. - 2023 - Jailbroken How Does LLM Safety Training Fail.pdf:application/pdf},
}

@misc{liu_prompt_2023,
	title = {Prompt {Injection} {Attacks} and {Defenses} in {LLM}-{Integrated} {Applications}},
	url = {http://arxiv.org/abs/2310.12815},
	abstract = {Large Language Models (LLMs) are increasingly deployed as the backend for a variety of real-world applications called LLM-Integrated Applications. Multiple recent works showed that LLM-Integrated Applications are vulnerable to prompt injection attacks, in which an attacker injects malicious instruction/data into the input of those applications such that they produce results as the attacker desires. However, existing works are limited to case studies. As a result, the literature lacks a systematic understanding of prompt injection attacks and their defenses. We aim to bridge the gap in this work. In particular, we propose a general framework to formalize prompt injection attacks. Existing attacks, which are discussed in research papers and blog posts, are special cases in our framework. Our framework enables us to design a new attack by combining existing attacks. Moreover, we also propose a framework to systematize defenses against prompt injection attacks. Using our frameworks, we conduct a systematic evaluation on prompt injection attacks and their defenses with 10 LLMs and 7 tasks. We hope our frameworks can inspire future research in this field. Our code is available at https://github.com/liu00222/Open-Prompt-Injection.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
	month = oct,
	year = {2023},
	note = {arXiv:2310.12815 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Liu et al. - 2023 - Prompt Injection Attacks and Defenses in LLM-Integ.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\DVMW8RLU\\Liu et al. - 2023 - Prompt Injection Attacks and Defenses in LLM-Integ.pdf:application/pdf},
}

@misc{zhao_causality_2023,
	title = {Causality {Analysis} for {Evaluating} the {Security} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2312.07876},
	abstract = {Large Language Models (LLMs) such as GPT and Llama2 are increasingly adopted in many safety-critical applications. Their security is thus essential. Even with considerable efforts spent on reinforcement learning from human feedback (RLHF), recent studies have shown that LLMs are still subject to attacks such as adversarial perturbation and Trojan attacks. Further research is thus needed to evaluate their security and/or understand the lack of it. In this work, we propose a framework for conducting light-weight causality-analysis of LLMs at the token, layer, and neuron level. We applied our framework to open-source LLMs such as Llama2 and Vicuna and had multiple interesting discoveries. Based on a layerlevel causality analysis, we show that RLHF has the effect of overfitting a model to harmful prompts. It implies that such security can be easily overcome by ‘unusual’ harmful prompts. As evidence, we propose an adversarial perturbation method that achieves 100\% attack success rate on the red-teaming tasks of the Trojan Detection Competition 2023. Furthermore, we show the existence of one mysterious neuron in both Llama2 and Vicuna that has an unreasonably high causal effect on the output. While we are uncertain on why such a neuron exists, we show that it is possible to conduct a “Trojan” attack targeting that particular neuron to completely cripple the LLM, i.e., we can generate transferable suffixes to prompts that frequently make the LLM produce meaningless responses.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Zhao, Wei and Li, Zhe and Sun, Jun},
	month = dec,
	year = {2023},
	note = {arXiv:2312.07876 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Zhao et al. - 2023 - Causality Analysis for Evaluating the Security of .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\DWT8ZWGI\\Zhao et al. - 2023 - Causality Analysis for Evaluating the Security of .pdf:application/pdf},
}

@misc{lou_trojtext_2023,
	title = {{TrojText}: {Test}-time {Invisible} {Textual} {Trojan} {Insertion}},
	shorttitle = {{TrojText}},
	url = {http://arxiv.org/abs/2303.02242},
	abstract = {In Natural Language Processing (NLP), intelligent neuron models can be susceptible to textual Trojan attacks. Such attacks occur when Trojan models behave normally for standard inputs but generate malicious output for inputs that contain a specific trigger. Syntactic-structure triggers, which are invisible, are becoming more popular for Trojan attacks because they are difficult to detect and defend against. However, these types of attacks require a large corpus of training data to generate poisoned samples with the necessary syntactic structures for Trojan insertion. Obtaining such data can be difficult for attackers, and the process of generating syntactic poisoned triggers and inserting Trojans can be time-consuming. This paper proposes a solution called TrojText, which aims to determine whether invisible textual Trojan attacks can be performed more efficiently and cost-effectively without training data. The proposed approach, called the Representation-Logit Trojan Insertion (RLI) algorithm, uses smaller sampled test data instead of large training data to achieve the desired attack. The paper also introduces two additional techniques, namely the accumulated gradient ranking (AGR) and Trojan Weights Pruning (TWP), to reduce the number of tuned parameters and the attack overhead. The TrojText approach was evaluated on three datasets (AG’s News, SST-2, and OLID) using three NLP models (BERT, XLNet, and DeBERTa). The experiments demonstrated that the TrojText approach achieved a 98.35\% classification accuracy for test sentences in the target class on the BERT model for the AG’s News dataset. The source code for TrojText is available at https://github.com/UCF-ML-Research/TrojText.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Lou, Qian and Liu, Yepeng and Feng, Bo},
	month = aug,
	year = {2023},
	note = {arXiv:2303.02242 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: In The Eleventh International Conference on Learning Representations. 2023 (ICLR 2023)},
	file = {Lou et al. - 2023 - TrojText Test-time Invisible Textual Trojan Inser.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\PG4MTYJG\\Lou et al. - 2023 - TrojText Test-time Invisible Textual Trojan Inser.pdf:application/pdf},
}

@misc{papernot_distillation_2016,
	title = {Distillation as a {Defense} to {Adversarial} {Perturbations} against {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1511.04508},
	abstract = {Deep learning algorithms have been shown to perform extremely well on many classical machine learning problems. However, recent studies have shown that deep learning, like other machine learning techniques, is vulnerable to adversarial samples: inputs crafted to force a deep neural network (DNN) to provide adversary-selected outputs. Such attacks can seriously undermine the security of the system supported by the DNN, sometimes with devastating consequences. For example, autonomous vehicles can be crashed, illicit or illegal content can bypass content ﬁlters, or biometric authentication systems can be manipulated to allow improper access. In this work, we introduce a defensive mechanism called defensive distillation to reduce the effectiveness of adversarial samples on DNNs. We analytically investigate the generalizability and robustness properties granted by the use of defensive distillation when training DNNs. We also empirically study the effectiveness of our defense mechanisms on two DNNs placed in adversarial settings. The study shows that defensive distillation can reduce effectiveness of sample creation from 95\% to less than 0.5\% on a studied DNN. Such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 1030. We also ﬁnd that distillation increases the average minimum number of features that need to be modiﬁed to create adversarial samples by about 800\% on one of the DNNs we tested.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
	month = mar,
	year = {2016},
	note = {arXiv:1511.04508 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {Papernot et al. - 2016 - Distillation as a Defense to Adversarial Perturbat.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\8LEVSY7A\\Papernot et al. - 2016 - Distillation as a Defense to Adversarial Perturbat.pdf:application/pdf},
}

@misc{robey_smoothllm_2023,
	title = {{SmoothLLM}: {Defending} {Large} {Language} {Models} {Against} {Jailbreaking} {Attacks}},
	shorttitle = {{SmoothLLM}},
	url = {http://arxiv.org/abs/2310.03684},
	abstract = {Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our finding that adversariallygenerated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation. Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM. Our code is publicly available at the following link: https://github.com/arobey1/smooth-llm.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Robey, Alexander and Wong, Eric and Hassani, Hamed and Pappas, George J.},
	month = nov,
	year = {2023},
	note = {arXiv:2310.03684 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
	file = {Robey et al. - 2023 - SmoothLLM Defending Large Language Models Against.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\VSHPEBGR\\Robey et al. - 2023 - SmoothLLM Defending Large Language Models Against.pdf:application/pdf},
}

@misc{tramer_ensemble_2020,
	title = {Ensemble {Adversarial} {Training}: {Attacks} and {Defenses}},
	shorttitle = {Ensemble {Adversarial} {Training}},
	url = {http://arxiv.org/abs/1705.07204},
	abstract = {Adversarial examples are perturbed inputs designed to fool machine learning models. Adversarial training injects such examples into training data to increase robustness. To scale this technique to large datasets, perturbations are crafted using fast single-step methods that maximize a linear approximation of the model’s loss. We show that this form of adversarial training converges to a degenerate global minimum, wherein small curvature artifacts near the data points obfuscate a linear approximation of the loss. The model thus learns to generate weak perturbations, rather than defend against strong ones. As a result, we ﬁnd that adversarial training remains vulnerable to black-box attacks, where we transfer perturbations computed on undefended models, as well as to a powerful novel single-step attack that escapes the non-smooth vicinity of the input data via a small random step.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Tramèr, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
	month = apr,
	year = {2020},
	note = {arXiv:1705.07204 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, Statistics - Machine Learning},
	annote = {Comment: 22 pages, 5 figures, International Conference on Learning Representations (ICLR) 2018 (amended in April 2020 to include subsequent attacks that significantly reduced the robustness of our models)},
	file = {Tramèr et al. - 2020 - Ensemble Adversarial Training Attacks and Defense.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\U6KTWPSR\\Tramèr et al. - 2020 - Ensemble Adversarial Training Attacks and Defense.pdf:application/pdf},
}

@inproceedings{zhang_trojaning_2021,
	address = {Vienna, Austria},
	title = {Trojaning {Language} {Models} for {Fun} and {Profit}},
	isbn = {978-1-66541-491-3},
	url = {https://ieeexplore.ieee.org/document/9581257/},
	doi = {10.1109/EuroSP51992.2021.00022},
	abstract = {Recent years have witnessed the emergence of a new paradigm of building natural language processing (NLP) systems: general-purpose, pre-trained language models (LMs) are composed with simple downstream models and ﬁne-tuned for a variety of NLP tasks. This paradigm shift signiﬁcantly simpliﬁes the system development cycles. However, as many LMs are provided by untrusted third parties, their lack of standardization or regulation entails profound security implications, which are largely unexplored.},
	language = {en},
	urldate = {2024-01-19},
	booktitle = {2021 {IEEE} {European} {Symposium} on {Security} and {Privacy} ({EuroS}\&{P})},
	publisher = {IEEE},
	author = {Zhang, Xinyang and Zhang, Zheng and Ji, Shouling and Wang, Ting},
	month = sep,
	year = {2021},
	pages = {179--197},
	file = {Zhang et al. - 2021 - Trojaning Language Models for Fun and Profit.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\SMA7I2NK\\Zhang et al. - 2021 - Trojaning Language Models for Fun and Profit.pdf:application/pdf},
}

@inproceedings{pan_privacy_2020,
	address = {San Francisco, CA, USA},
	title = {Privacy {Risks} of {General}-{Purpose} {Language} {Models}},
	isbn = {978-1-72813-497-0},
	url = {https://ieeexplore.ieee.org/document/9152761/},
	doi = {10.1109/SP40000.2020.00095},
	abstract = {Recently, a new paradigm of building generalpurpose language models (e.g., Google’s Bert and OpenAI’s GPT-2) in Natural Language Processing (NLP) for text feature extraction, a standard procedure in NLP systems that converts texts to vectors (i.e., embeddings) for downstream modeling, has arisen and starts to ﬁnd its application in various downstream NLP tasks and real world systems (e.g., Google’s search engine [6]). To obtain general-purpose text embeddings, these language models have highly complicated architectures with millions of learnable parameters and are usually pretrained on billions of sentences before being utilized. As is widely recognized, such a practice indeed improves the state-of-the-art performance of many downstream NLP tasks.},
	language = {en},
	urldate = {2024-01-19},
	booktitle = {2020 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	publisher = {IEEE},
	author = {Pan, Xudong and Zhang, Mi and Ji, Shouling and Yang, Min},
	month = may,
	year = {2020},
	pages = {1314--1331},
	file = {Pan et al. - 2020 - Privacy Risks of General-Purpose Language Models.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\79YU723Y\\Pan et al. - 2020 - Privacy Risks of General-Purpose Language Models.pdf:application/pdf},
}

@inproceedings{wang_rmlm_2023,
	address = {Toronto, Canada},
	title = {{RMLM}: {A} {Flexible} {Defense} {Framework} for {Proactively} {Mitigating} {Word}-level {Adversarial} {Attacks}},
	shorttitle = {{RMLM}},
	url = {https://aclanthology.org/2023.acl-long.155},
	doi = {10.18653/v1/2023.acl-long.155},
	abstract = {Adversarial attacks on deep neural networks keep raising security concerns in natural language processing research. Existing defenses focus on improving the robustness of the victim model in the training stage. However, they often neglect to proactively mitigate adversarial attacks during inference. Towards this overlooked aspect, we propose a defense framework that aims to mitigate attacks by confusing attackers and correcting adversarial contexts that are caused by malicious perturbations. Our framework comprises three components: (1) a synonym-based transformation to randomly corrupt adversarial contexts in the word level, (2) a developed BERT defender to correct abnormal contexts in the representation level, and (3) a simple detection method to ﬁlter out adversarial examples, any of which can be ﬂexibly combined. Additionally, our framework helps improve the robustness of the victim model during training. Extensive experiments demonstrate the effectiveness of our framework in defending against word-level adversarial attacks.},
	language = {en},
	urldate = {2024-01-19},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Zhaoyang and Liu, Zhiyue and Zheng, Xiaopeng and Su, Qinliang and Wang, Jiahai},
	year = {2023},
	pages = {2757--2774},
	file = {Wang et al. - 2023 - RMLM A Flexible Defense Framework for Proactively.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\I7H5EA76\\Wang et al. - 2023 - RMLM A Flexible Defense Framework for Proactively.pdf:application/pdf},
}

@misc{ngo_mitigating_2021,
	title = {Mitigating harm in language models with conditional-likelihood filtration},
	url = {http://arxiv.org/abs/2108.07790},
	abstract = {Language models trained on large-scale unﬁltered datasets curated from the open web acquire systemic biases, prejudices, and harmful views from their training data. We present a methodology for programmatically identifying and removing harmful text from web-scale datasets. A pretrained language model is used to assess the loglikelihood of researcher-written trigger phrases conditioned on a speciﬁc document, which is used to identify and ﬁlter documents from the dataset. We demonstrate that models trained on this ﬁltered dataset exhibit lower propensity to generate harmful text, with a marginal decrease in performance on standard language modeling benchmarks compared to unﬁltered baselines. We provide a partial explanation for this performance gap by surfacing examples of hate speech and other undesirable content from standard language modeling benchmarks. Finally, we discuss the generalization of this method and how trigger phrases reﬂecting speciﬁc values can be used by researchers to build language models which are more closely aligned with their values.},
	language = {en},
	urldate = {2024-01-19},
	publisher = {arXiv},
	author = {Ngo, Helen and Raterink, Cooper and Araújo, João G. M. and Zhang, Ivan and Chen, Carol and Morisot, Adrien and Frosst, Nicholas},
	month = nov,
	year = {2021},
	note = {arXiv:2108.07790 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Ngo et al. - 2021 - Mitigating harm in language models with conditiona.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\DAIVRJJ8\\Ngo et al. - 2021 - Mitigating harm in language models with conditiona.pdf:application/pdf},
}

@misc{alajrami_how_2022,
	title = {How does the pre-training objective affect what large language models learn about linguistic properties?},
	url = {http://arxiv.org/abs/2203.10415},
	abstract = {Several pre-training objectives, such as masked language modeling (MLM), have been proposed to pre-train language models (e.g. BERT) with the aim of learning better language representations. However, to the best of our knowledge, no previous work so far has investigated how different pre-training objectives affect what BERT learns about linguistics properties. We hypothesize that linguistically motivated objectives such as MLM should help BERT to acquire better linguistic knowledge compared to other non-linguistically motivated objectives that are not intuitive or hard for humans to guess the association between the input and the label to be predicted. To this end, we pre-train BERT with two linguistically motivated objectives and three non-linguistically motivated ones. We then probe for linguistic characteristics encoded in the representation of the resulting models. We find strong evidence that there are only small differences in probing performance between the representations learned by the two different types of objectives. These surprising results question the dominant narrative of linguistically informed pre-training.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Alajrami, Ahmed and Aletras, Nikolaos},
	month = mar,
	year = {2022},
	note = {arXiv:2203.10415 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted at ACL 2022},
	file = {Alajrami und Aletras - 2022 - How does the pre-training objective affect what la.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\6KPH5F52\\Alajrami und Aletras - 2022 - How does the pre-training objective affect what la.pdf:application/pdf},
}

@inproceedings{sun_mitigating_2019,
	address = {Florence, Italy},
	title = {Mitigating {Gender} {Bias} in {Natural} {Language} {Processing}: {Literature} {Review}},
	shorttitle = {Mitigating {Gender} {Bias} in {Natural} {Language} {Processing}},
	url = {https://www.aclweb.org/anthology/P19-1159},
	doi = {10.18653/v1/P19-1159},
	abstract = {As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in popularity, it becomes increasingly vital to recognize the role they play in shaping societal biases and stereotypes. Although NLP models have shown success in modeling various applications, they propagate and may even amplify gender bias found in text corpora. While the study of bias in artiﬁcial intelligence is not new, methods to mitigate gender bias in NLP are relatively nascent. In this paper, we review contemporary studies on recognizing and mitigating gender bias in NLP. We discuss gender bias based on four forms of representation bias and analyze methods recognizing gender bias. Furthermore, we discuss the advantages and drawbacks of existing gender debiasing methods. Finally, we discuss future studies for recognizing and mitigating gender bias in NLP.},
	language = {en},
	urldate = {2024-01-20},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Sun, Tony and Gaut, Andrew and Tang, Shirlyn and Huang, Yuxin and ElSherief, Mai and Zhao, Jieyu and Mirza, Diba and Belding, Elizabeth and Chang, Kai-Wei and Wang, William Yang},
	year = {2019},
	pages = {1630--1640},
	file = {Sun et al. - 2019 - Mitigating Gender Bias in Natural Language Process.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\T9VMY73U\\Sun et al. - 2019 - Mitigating Gender Bias in Natural Language Process.pdf:application/pdf},
}

@inproceedings{dixon_measuring_2018,
	address = {New Orleans LA USA},
	title = {Measuring and {Mitigating} {Unintended} {Bias} in {Text} {Classification}},
	isbn = {978-1-4503-6012-8},
	url = {https://dl.acm.org/doi/10.1145/3278721.3278729},
	doi = {10.1145/3278721.3278729},
	abstract = {We introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. Our deﬁnition of unintended bias is parameterized by a test set and a subset of input features. We illustrate how this can be used to evaluate text classiﬁers using a synthetic test set and a public corpus of comments annotated for toxicity from Wikipedia Talk pages. We also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. We use a set of common demographic identity terms as the subset of input features on which we measure bias. This technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. The mitigation method we introduce is an unsupervised approach based on balancing the training dataset. We demonstrate that this approach reduces the unintended bias without compromising overall model quality.},
	language = {en},
	urldate = {2024-01-20},
	booktitle = {Proceedings of the 2018 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Dixon, Lucas and Li, John and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy},
	month = dec,
	year = {2018},
	pages = {67--73},
	file = {Dixon et al. - 2018 - Measuring and Mitigating Unintended Bias in Text C.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\V3XT8LHB\\Dixon et al. - 2018 - Measuring and Mitigating Unintended Bias in Text C.pdf:application/pdf},
}

@inproceedings{de-arteaga_bias_2019,
	title = {Bias in {Bios}: {A} {Case} {Study} of {Semantic} {Representation} {Bias} in a {High}-{Stakes} {Setting}},
	shorttitle = {Bias in {Bios}},
	url = {http://arxiv.org/abs/1901.09451},
	doi = {10.1145/3287560.3287572},
	abstract = {We present a large-scale study of gender bias in occupation classification, a task where the use of machine learning may lead to negative outcomes on peoples’ lives. We analyze the potential allocation harms that can result from semantic representation bias. To do so, we study the impact on occupation classification of including explicit gender indicators—such as first names and pronouns—in different semantic representations of online biographies. Additionally, we quantify the bias that remains when these indicators are “scrubbed,” and describe proxy behavior that occurs in the absence of explicit gender indicators. As we demonstrate, differences in true positive rates between genders are correlated with existing gender imbalances in occupations, which may compound these imbalances.},
	language = {en},
	urldate = {2024-01-20},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	author = {De-Arteaga, Maria and Romanov, Alexey and Wallach, Hanna and Chayes, Jennifer and Borgs, Christian and Chouldechova, Alexandra and Geyik, Sahin and Kenthapadi, Krishnaram and Kalai, Adam Tauman},
	month = jan,
	year = {2019},
	note = {arXiv:1901.09451 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Information Retrieval, Statistics - Machine Learning},
	pages = {120--128},
	annote = {Comment: Accepted at ACM Conference on Fairness, Accountability, and Transparency (ACM FAT*), 2019},
	file = {De-Arteaga et al. - 2019 - Bias in Bios A Case Study of Semantic Representat.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\699587NH\\De-Arteaga et al. - 2019 - Bias in Bios A Case Study of Semantic Representat.pdf:application/pdf},
}

@inproceedings{zhang_mitigating_2018,
	address = {New York, NY, USA},
	series = {{AIES} '18},
	title = {Mitigating {Unwanted} {Biases} with {Adversarial} {Learning}},
	isbn = {978-1-4503-6012-8},
	url = {https://dl.acm.org/doi/10.1145/3278721.3278779},
	doi = {10.1145/3278721.3278779},
	abstract = {Machine learning is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will reflect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously learning a predictor and an adversary. The input to the network X, here text or census data, produces a prediction Y, such as an analogy completion or income bracket, while the adversary tries to model a protected variable Z, here gender or zip code. The objective is to maximize the predictor's ability to predict Y while minimizing the adversary's ability to predict Z. Applied to analogy completion, this method results in accurate predictions that exhibit less evidence of stereotyping Z. When applied to a classification task using the UCI Adult (Census) Dataset, it results in a predictive model that does not lose much accuracy while achieving very close to equality of odds (Hardt, et al., 2016). The method is flexible and applicable to multiple definitions of fairness as well as a wide range of gradient-based learning models, including both regression and classification tasks.},
	urldate = {2024-01-20},
	booktitle = {Proceedings of the 2018 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Brian Hu and Lemoine, Blake and Mitchell, Margaret},
	month = dec,
	year = {2018},
	keywords = {adversarial learning, debiasing, multi-task learning, unbiasing},
	pages = {335--340},
	file = {Full Text PDF:C\:\\Users\\bar35643\\Zotero\\storage\\85NUQWIA\\Zhang et al. - 2018 - Mitigating Unwanted Biases with Adversarial Learni.pdf:application/pdf},
}

@misc{hardt_equality_2016,
	title = {Equality of {Opportunity} in {Supervised} {Learning}},
	url = {http://arxiv.org/abs/1610.02413},
	abstract = {We propose a criterion for discrimination against a speciﬁed sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our deﬁnition. Our framework also improves incentives by shifting the cost of poor classiﬁcation from disadvantaged groups to the decision maker, who can respond by improving the classiﬁcation accuracy.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
	month = oct,
	year = {2016},
	note = {arXiv:1610.02413 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4YIKYLGN\\Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:application/pdf},
}

@misc{hardt_equality_2016-1,
	title = {Equality of {Opportunity} in {Supervised} {Learning}},
	url = {http://arxiv.org/abs/1610.02413},
	abstract = {We propose a criterion for discrimination against a speciﬁed sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our deﬁnition. Our framework also improves incentives by shifting the cost of poor classiﬁcation from disadvantaged groups to the decision maker, who can respond by improving the classiﬁcation accuracy.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
	month = oct,
	year = {2016},
	note = {arXiv:1610.02413 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\68PP6VUR\\Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:application/pdf},
}

@misc{van_der_wal_birth_2022,
	title = {The {Birth} of {Bias}: {A} case study on the evolution of gender bias in an {English} language model},
	shorttitle = {The {Birth} of {Bias}},
	url = {http://arxiv.org/abs/2207.10245},
	abstract = {Detecting and mitigating harmful biases in modern language models are widely recognized as crucial, open problems. In this paper, we take a step back and investigate how language models come to be biased in the ﬁrst place. We use a relatively small language model, using the LSTM architecture trained on an English Wikipedia corpus. With full access to the data and to the model parameters as they change during every step while training, we can map in detail how the representation of gender develops, what patterns in the dataset drive this, and how the model’s internal state relates to the bias in a downstream task (semantic textual similarity). We ﬁnd that the representation of gender is dynamic and identify different phases during training. Furthermore, we show that gender information is represented increasingly locally in the input embeddings of the model and that, as a consequence, debiasing these can be effective in reducing the downstream bias. Monitoring the training dynamics, allows us to detect an asymmetry in how the female and male gender are represented in the input embeddings. This is important, as it may cause naive mitigation strategies to introduce new undesirable biases. We discuss the relevance of the ﬁndings for mitigation strategies more generally and the prospects of generalizing our methods to larger language models, the Transformer architecture, other languages and other undesirable biases.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {van der Wal, Oskar and Jumelet, Jaap and Schulz, Katrin and Zuidema, Willem},
	month = jul,
	year = {2022},
	note = {arXiv:2207.10245 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: Accepted at the 4th Workshop on Gender Bias in Natural Language Processing (NAACL, 2022)},
	file = {van der Wal et al. - 2022 - The Birth of Bias A case study on the evolution o.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\D77XLULL\\van der Wal et al. - 2022 - The Birth of Bias A case study on the evolution o.pdf:application/pdf},
}

@misc{wambsganss_bias_2022,
	title = {Bias at a {Second} {Glance}: {A} {Deep} {Dive} into {Bias} for {German} {Educational} {Peer}-{Review} {Data} {Modeling}},
	shorttitle = {Bias at a {Second} {Glance}},
	url = {http://arxiv.org/abs/2209.10335},
	abstract = {Natural Language Processing (NLP) has become increasingly utilized to provide adaptivity in educational applications. However, recent research has highlighted a variety of biases in pre-trained language models. While existing studies investigate bias in different domains, they are limited in addressing ﬁnegrained analysis on educational and multilingual corpora. In this work, we analyze bias across text and through multiple architectures on a corpus of 9,165 German peer-reviews collected from university students over ﬁve years. Notably, our corpus includes labels such as helpfulness, quality, and critical aspect ratings from the peer-review recipient as well as demographic attributes. We conduct a Word Embedding Association Test (WEAT) analysis on (1) our collected corpus in connection with the clustered labels, (2) the most common pre-trained German language models (T5, BERT, and GPT-2) and GloVe embeddings, and (3) the language models after ﬁnetuning on our collected data-set. In contrast to our initial expectations, we found that our collected corpus does not reveal many biases in the co-occurrence analysis or in the GloVe embeddings. However, the pre-trained German language models ﬁnd substantial conceptual, racial, and gender bias and have signiﬁcant changes in bias across conceptual and racial axes during ﬁne-tuning on the peer-review data. With our research, we aim to contribute to the fourth UN sustainability goal (quality education) with a novel dataset, an understanding of biases in natural language education data, and the potential harms of not counteracting biases in language models for educational tasks.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Wambsganss, Thiemo and Swamy, Vinitra and Rietsche, Roman and Käser, Tanja},
	month = sep,
	year = {2022},
	note = {arXiv:2209.10335 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
	annote = {Comment: Accepted as a full paper at COLING 2022: The 29th International Conference on Computational Linguistics, 12-17 of October 2022, Gyeongju, Republic of Korea},
	file = {Wambsganss et al. - 2022 - Bias at a Second Glance A Deep Dive into Bias for.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\CC9CQAJA\\Wambsganss et al. - 2022 - Bias at a Second Glance A Deep Dive into Bias for.pdf:application/pdf},
}

@misc{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {arXiv:1301.3781 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\D74KEY8R\\Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf},
}

@misc{kiros_skip-thought_2015,
	title = {Skip-{Thought} {Vectors}},
	url = {http://arxiv.org/abs/1506.06726},
	abstract = {We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoderdecoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classiﬁcation and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Ruslan and Zemel, Richard S. and Torralba, Antonio and Urtasun, Raquel and Fidler, Sanja},
	month = jun,
	year = {2015},
	note = {arXiv:1506.06726 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 11 pages},
	file = {Kiros et al. - 2015 - Skip-Thought Vectors.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\75QWX5PC\\Kiros et al. - 2015 - Skip-Thought Vectors.pdf:application/pdf},
}

@misc{zhang_ernie_2019,
	title = {{ERNIE}: {Enhanced} {Language} {Representation} with {Informative} {Entities}},
	shorttitle = {{ERNIE}},
	url = {http://arxiv.org/abs/1905.07129},
	abstract = {Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be ﬁne-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves signiﬁcant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code and experiment details of this paper can be obtained from https:// github.com/thunlp/ERNIE.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Zhang, Zhengyan and Han, Xu and Liu, Zhiyuan and Jiang, Xin and Sun, Maosong and Liu, Qun},
	month = jun,
	year = {2019},
	note = {arXiv:1905.07129 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted by ACL 2019},
	file = {Zhang et al. - 2019 - ERNIE Enhanced Language Representation with Infor.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\RDJ8PJ49\\Zhang et al. - 2019 - ERNIE Enhanced Language Representation with Infor.pdf:application/pdf},
}

@article{bengio_neural_nodate,
	title = {A {Neural} {Probabilistic} {Language} {Model}},
	abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difﬁcult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to ﬁght the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a signiﬁcant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach signiﬁcantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.},
	language = {en},
	author = {Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal and Jauvin, Christian},
	file = {Bengio et al. - A Neural Probabilistic Language Model.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\GE5TTNU8\\Bengio et al. - A Neural Probabilistic Language Model.pdf:application/pdf},
}

@article{radford_improving_nodate-1,
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	language = {en},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	file = {Radford et al. - Improving Language Understanding by Generative Pre.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\KTVIH528\\Radford et al. - Improving Language Understanding by Generative Pre.pdf:application/pdf},
}

@article{chen_big_nodate,
	title = {Big {Self}-{Supervised} {Models} are {Strong} {Semi}-{Supervised} {Learners}},
	language = {en},
	author = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
	file = {Chen et al. - Big Self-Supervised Models are Strong Semi-Supervi.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\9YQ6T6Q6\\Chen et al. - Big Self-Supervised Models are Strong Semi-Supervi.pdf:application/pdf},
}

@misc{liu_adversarial_2020,
	title = {Adversarial {Training} for {Large} {Neural} {Language} {Models}},
	url = {http://arxiv.org/abs/2004.08994},
	abstract = {Generalization and robustness are both key desiderata for designing machine learning methods. Adversarial training can enhance robustness, but past work often ﬁnds it hurts generalization. In natural language processing (NLP), pre-training large neural language models such as BERT have demonstrated impressive gain in generalization for a variety of tasks, with further improvement from adversarial ﬁne-tuning. However, these models are still vulnerable to adversarial attacks. In this paper, we show that adversarial pretraining can improve both generalization and robustness. We propose a general algorithm ALUM (Adversarial training for large neural LangUage Models), which regularizes the training objective by applying perturbations in the embedding space that maximizes the adversarial loss. We present the ﬁrst comprehensive study of adversarial training in all stages, including pre-training from scratch, continual pre-training on a well-trained model, and taskspeciﬁc ﬁne-tuning. ALUM obtains substantial gains over BERT on a wide range of NLP tasks, in both regular and adversarial scenarios. Even for models that have been well trained on extremely large text corpora, such as RoBERTa, ALUM can still produce signiﬁcant gains from continual pre-training, whereas conventional non-adversarial methods can not. ALUM can be further combined with task-speciﬁc ﬁne-tuning to attain additional gains. The ALUM code is publicly available at https://github.com/namisan/mt-dnn.},
	language = {en},
	urldate = {2024-01-20},
	publisher = {arXiv},
	author = {Liu, Xiaodong and Cheng, Hao and He, Pengcheng and Chen, Weizhu and Wang, Yu and Poon, Hoifung and Gao, Jianfeng},
	month = apr,
	year = {2020},
	note = {arXiv:2004.08994 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 13 pages, 9 tables, 2 figures},
	file = {Liu et al. - 2020 - Adversarial Training for Large Neural Language Mod.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\NKCZFACA\\Liu et al. - 2020 - Adversarial Training for Large Neural Language Mod.pdf:application/pdf},
}

@article{jehangir_survey_2023,
	title = {A survey on {Named} {Entity} {Recognition} — datasets, tools, and methodologies},
	volume = {3},
	issn = {2949-7191},
	url = {https://www.sciencedirect.com/science/article/pii/S2949719123000146},
	doi = {10.1016/j.nlp.2023.100017},
	abstract = {Natural language processing (NLP) is crucial in the current processing of data because it takes into account many sources, formats, and purposes of data as well as information from various sectors of our economy, government, and private and public lives. We perform a variety of NLP operations on the text in order to complete certain tasks. One of them is NER (Named Entity Recognition). An act of recognizing and categorizing named entities that are presented in a text document is known as named entity recognition. The purpose of NER is to find references of rigid designators in the text which belong to established semantic kinds like a person, place, organization, etc. It acts as a cornerstone for many Information Extraction-related activities. In this work, we present a thorough analysis of several methodologies for NER ranging from unsupervised learning, rule-based, supervised learning, and various Deep Learning based approaches. We examine the most relevant datasets, tools, and deep learning approaches like Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Bidirectional Long Short Term Memory, Transfer learning approaches, and numerous other approaches currently being used in present-day NER problem environments and their applications. Finally, we outline the difficulties NER systems encounter and future directions.},
	urldate = {2024-01-21},
	journal = {Natural Language Processing Journal},
	author = {Jehangir, Basra and Radhakrishnan, Saravanan and Agarwal, Rahul},
	month = jun,
	year = {2023},
	keywords = {Named Entity Recognition, Bidirectional Long Short Term Memory, Convolutional Neural Network, Deep Learning, Natural language processing, Recurrent Neural Networks},
	pages = {100017},
	file = {ScienceDirect Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\ACAFRM8K\\S2949719123000146.html:text/html},
}

@misc{lu_instag_2023,
	title = {\#{InsTag}: {Instruction} {Tagging} for {Analyzing} {Supervised} {Fine}-tuning of {Large} {Language} {Models}},
	shorttitle = {\#{InsTag}},
	url = {http://arxiv.org/abs/2308.07074},
	abstract = {Foundation language models obtain the instruction-following ability through supervised fine-tuning (SFT). Diversity and complexity are considered critical factors of a successful SFT dataset, while their definitions remain obscure and lack quantitative analyses. In this work, we propose INSTAG, an open-set fine-grained tagger, to tag samples within SFT datasets based on semantics and intentions and define instruction diversity and complexity regarding tags. We obtain 6.6K tags to describe comprehensive user queries. We analyze popular open-sourced SFT datasets and find that the model ability grows with more diverse and complex data. Based on this observation, we propose a data selector based on INSTAG to select 6K diverse and complex samples from open-source datasets and fine-tune models on INSTAG-selected data. The resulting models, TAGLM, outperform opensource models based on considerably larger SFT data evaluated by MT-BENCH, echoing the importance of query diversity and complexity. We open-source INSTAG in https://github.com/OFA-Sys/InsTag.},
	language = {en},
	urldate = {2024-01-21},
	publisher = {arXiv},
	author = {Lu, Keming and Yuan, Hongyi and Yuan, Zheng and Lin, Runji and Lin, Junyang and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren},
	month = aug,
	year = {2023},
	note = {arXiv:2308.07074 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {2308.07074.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\6Y237BBN\\2308.07074.pdf:application/pdf},
}

@misc{zhao_survey_2023,
	title = {A {Survey} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2303.18223},
	abstract = {Ever since the Turing Test was proposed in the 1950s, humans have explored the mastering of language intelligence by machine. Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable artificial intelligence (AI) algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pretraining Transformer models over large-scale corpora, showing strong capabilities in solving various natural language processing (NLP) tasks. Since the researchers have found that model scaling can lead to an improved model capacity, they further investigate the scaling effect by increasing the parameter scale to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement, but also exhibit some special abilities (e.g., incontext learning) that are not present in small-scale language models (e.g., BERT). To discriminate the language models in different parameter scales, the research community has coined the term large language models (LLM) for the PLMs of significant size (e.g., containing tens or hundreds of billions of parameters). Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT (a powerful AI chatbot developed based on LLMs), which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. Considering this rapid technical progress, in this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Furthermore, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions. This survey provides an up-to-date review of the literature on LLMs, which can be a useful resource for both researchers and engineers.},
	language = {en},
	urldate = {2024-01-21},
	publisher = {arXiv},
	author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and Du, Yifan and Yang, Chen and Chen, Yushuo and Chen, Zhipeng and Jiang, Jinhao and Ren, Ruiyang and Li, Yifan and Tang, Xinyu and Liu, Zikang and Liu, Peiyu and Nie, Jian-Yun and Wen, Ji-Rong},
	month = nov,
	year = {2023},
	note = {arXiv:2303.18223 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: ongoing work; 124 pages, 946 citations},
	file = {2303.18223.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\XLZ6RETW\\2303.18223.pdf:application/pdf},
}

@article{chowdhery_palm_nodate,
	title = {{PaLM}: {Scaling} {Language} {Modeling} with {Pathways}},
	abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-speciﬁc training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).},
	language = {en},
	author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Wang, Zongwei Zhou Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeﬀ and Petrov, Slav and Fiedel, Noah and Salakhutdinov, Ruslan},
	file = {Chowdhery et al. - PaLM Scaling Language Modeling with Pathways.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\MNERLM75\\Chowdhery et al. - PaLM Scaling Language Modeling with Pathways.pdf:application/pdf},
}

@misc{mao_tuning_2024,
	title = {Tuning {LLMs} with {Contrastive} {Alignment} {Instructions} for {Machine} {Translation} in {Unseen}, {Low}-resource {Languages}},
	url = {http://arxiv.org/abs/2401.05811},
	abstract = {This article introduces contrastive alignment instructions (AlignInstruct) to address two challenges in machine translation (MT) on large language models (LLMs). One is the expansion of supported languages to previously unseen ones. The second relates to the lack of data in lowresource languages. Model fine-tuning through MT instructions (MTInstruct) is a straightforward approach to the first challenge. However, MTInstruct is limited by weak cross-lingual signals inherent in the second challenge. AlignInstruct emphasizes cross-lingual supervision via a cross-lingual discriminator built using statistical word alignments. Our results based on fine-tuning the BLOOMZ models (1b1, 3b, and 7b1) in up to 24 unseen languages showed that: (1) LLMs can effectively translate unseen languages using MTInstruct; (2) AlignInstruct led to consistent improvements in translation quality across 48 translation directions involving English; (3) Discriminator-based instructions outperformed their generative counterparts as cross-lingual instructions; (4) AlignInstruct improved performance in 30 zero-shot directions.},
	language = {en},
	urldate = {2024-01-30},
	publisher = {arXiv},
	author = {Mao, Zhuoyuan and Yu, Yen},
	month = jan,
	year = {2024},
	note = {arXiv:2401.05811 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Mao und Yu - 2024 - Tuning LLMs with Contrastive Alignment Instruction.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\LSPGWBY3\\Mao und Yu - 2024 - Tuning LLMs with Contrastive Alignment Instruction.pdf:application/pdf},
}

@misc{wambsganss_bias_2022-1,
	title = {Bias at a {Second} {Glance}: {A} {Deep} {Dive} into {Bias} for {German} {Educational} {Peer}-{Review} {Data} {Modeling}},
	shorttitle = {Bias at a {Second} {Glance}},
	url = {http://arxiv.org/abs/2209.10335},
	abstract = {Natural Language Processing (NLP) has become increasingly utilized to provide adaptivity in educational applications. However, recent research has highlighted a variety of biases in pre-trained language models. While existing studies investigate bias in different domains, they are limited in addressing ﬁnegrained analysis on educational and multilingual corpora. In this work, we analyze bias across text and through multiple architectures on a corpus of 9,165 German peer-reviews collected from university students over ﬁve years. Notably, our corpus includes labels such as helpfulness, quality, and critical aspect ratings from the peer-review recipient as well as demographic attributes. We conduct a Word Embedding Association Test (WEAT) analysis on (1) our collected corpus in connection with the clustered labels, (2) the most common pre-trained German language models (T5, BERT, and GPT-2) and GloVe embeddings, and (3) the language models after ﬁnetuning on our collected data-set. In contrast to our initial expectations, we found that our collected corpus does not reveal many biases in the co-occurrence analysis or in the GloVe embeddings. However, the pre-trained German language models ﬁnd substantial conceptual, racial, and gender bias and have signiﬁcant changes in bias across conceptual and racial axes during ﬁne-tuning on the peer-review data. With our research, we aim to contribute to the fourth UN sustainability goal (quality education) with a novel dataset, an understanding of biases in natural language education data, and the potential harms of not counteracting biases in language models for educational tasks.},
	language = {en},
	urldate = {2024-01-30},
	publisher = {arXiv},
	author = {Wambsganss, Thiemo and Swamy, Vinitra and Rietsche, Roman and Käser, Tanja},
	month = sep,
	year = {2022},
	note = {arXiv:2209.10335 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
	annote = {Comment: Accepted as a full paper at COLING 2022: The 29th International Conference on Computational Linguistics, 12-17 of October 2022, Gyeongju, Republic of Korea},
	file = {Wambsganss et al. - 2022 - Bias at a Second Glance A Deep Dive into Bias for.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\9AWM78L6\\Wambsganss et al. - 2022 - Bias at a Second Glance A Deep Dive into Bias for.pdf:application/pdf},
}

@misc{chen_improving_2023,
	title = {Improving {Translation} {Faithfulness} of {Large} {Language} {Models} via {Augmenting} {Instructions}},
	url = {http://arxiv.org/abs/2308.12674},
	abstract = {Large Language Models (LLMs) present strong general capabilities, and a current compelling challenge is stimulating their specialized capabilities, such as machine translation, through low-cost instruction tuning. The standard instruction-following data is sequentially organized as the concatenation of an instruction, an input, and a response. As the attention mechanism of LLMs has limitations on local focus, LLMs tend to focus more on the words or sentences nearby at each position. This leads to a high risk of instruction forgetting during decoding. To alleviate the above issues, We propose SWIE (Segment-Weighted Instruction Embedding) and an instruction-following dataset OVERMISS. SWIE improves the model instruction understanding by adding a global instruction representation on the following input and response representations. OVERMISS improves model faithfulness by comparing over-translation and miss-translation results with the correct translation. We apply our methods to two main-stream open-source LLMs, BLOOM and LLaMA. The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk. Additionally, OVERMISS outperforms the baseline in translation performance (e.g. an increase in BLEU scores from 0.69 to 3.12 and an average improvement of 0.48 percentage comet scores for LLaMA-7b) with further enhancements seen in models combining OVERMISS and SWIE (e.g. the BLUE scores increase up to 0.56 from English to German across three different backbones), and both exhibit improvements in the faithfulness metric based on word alignment.},
	language = {en},
	urldate = {2024-01-30},
	publisher = {arXiv},
	author = {Chen, Yijie and Liu, Yijin and Meng, Fandong and Chen, Yufeng and Xu, Jinan and Zhou, Jie},
	month = aug,
	year = {2023},
	note = {arXiv:2308.12674 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: Our code and datasets are released in Github: https://github.com/pppa2019/swie\_overmiss\_llm4mt},
	file = {Chen et al. - 2023 - Improving Translation Faithfulness of Large Langua.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\JUHCWYGW\\Chen et al. - 2023 - Improving Translation Faithfulness of Large Langua.pdf:application/pdf},
}

@misc{zhang_tuning_2023-1,
	title = {Tuning {Large} language model for {End}-to-end {Speech} {Translation}},
	url = {http://arxiv.org/abs/2310.02050},
	abstract = {With the emergence of large language models (LLMs), multimodal models based on LLMs have demonstrated significant potential. Models such as LLaSM, X-LLM, and SpeechGPT exhibit an impressive ability to comprehend and generate human instructions. However, their performance often falters when faced with complex tasks like end-to-end speech translation (E2E-ST), a cross-language and cross-modal translation task. In comparison to single-modal models, multimodal models lag behind in these scenarios. This paper introduces LST, a Large multimodal model designed to excel at the E2E-ST task. LST consists of a speech frontend, an adapter, and a LLM backend. The training of LST consists of two stages: (1) Modality adjustment, where the adapter is tuned to align speech representation with text embedding space, and (2) Downstream task fine-tuning, where both the adapter and LLM model are trained to optimize performance on the E2EST task. Experimental results on the MuST-C speech translation benchmark demonstrate that LST-13B achieves BLEU scores of 30.39/41.55/35.33 on En-De/En-Fr/En-Es language pairs, surpassing previous models and establishing a new state-of-the-art. Additionally, we conduct an in-depth analysis of single-modal model selection and the impact of training strategies, which lays the foundation for future research. We will open up our code and models after review.},
	language = {en},
	urldate = {2024-01-30},
	publisher = {arXiv},
	author = {Zhang, Hao and Si, Nianwen and Chen, Yaqi and Zhang, Wenlin and Yang, Xukui and Qu, Dan and Jiao, Xiaolin},
	month = oct,
	year = {2023},
	note = {arXiv:2310.02050 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhang et al. - 2023 - Tuning Large language model for End-to-end Speech .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\A9C6R3BF\\Zhang et al. - 2023 - Tuning Large language model for End-to-end Speech .pdf:application/pdf},
}

@inproceedings{darji_german_2023-1,
	title = {German {BERT} {Model} for {Legal} {Named} {Entity} {Recognition}},
	url = {http://arxiv.org/abs/2303.05388},
	doi = {10.5220/0011749400003393},
	abstract = {The use of BERT, one of the most popular language models, has led to improvements in many Natural Language Processing (NLP) tasks. One such task is Named Entity Recognition (NER) i.e. automatic identification of named entities such as location, person, organization, etc. from a given text. It is also an important base step for many NLP tasks such as information extraction and argumentation mining. Even though there is much research done on NER using BERT and other popular language models, the same is not explored in detail when it comes to Legal NLP or Legal Tech. Legal NLP applies various NLP techniques such as sentence similarity or NER specifically on legal data. There are only a handful of models for NER tasks using BERT language models, however, none of these are aimed at legal documents in German. In this paper, we fine-tune a popular BERT language model trained on German data (German BERT) on a Legal Entity Recognition (LER) dataset. To make sure our model is not overfitting, we performed a stratified 10-fold cross-validation. The results we achieve by fine-tuning German BERT on the LER dataset outperform the BiLSTM-CRF+ model used by the authors of the same LER dataset. Finally, we make the model openly available via HuggingFace.},
	language = {en},
	urldate = {2024-01-30},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Agents} and {Artificial} {Intelligence}},
	author = {Darji, Harshil and Mitrović, Jelena and Granitzer, Michael},
	year = {2023},
	note = {arXiv:2303.05388 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	pages = {723--728},
	annote = {Comment: Presented at ICAART 2023},
	file = {Darji et al. - 2023 - German BERT Model for Legal Named Entity Recogniti.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\495WNH48\\Darji et al. - 2023 - German BERT Model for Legal Named Entity Recogniti.pdf:application/pdf},
}

@article{borchert_ggponc_nodate-1,
	title = {{GGPONC} 2.0 - {The} {German} {Clinical} {Guideline} {Corpus} for {Oncology}: {Curation} {Workflow}, {Annotation} {Policy}, {Baseline} {NER} {Taggers}},
	abstract = {Despite remarkable advances in the development of language resources over the recent years, there is still a shortage of annotated, publicly available corpora covering (German) medical language. With the initial release of the German Guideline Program in Oncology NLP Corpus (GGPONC), we have demonstrated how such corpora can be built upon clinical guidelines, a widely available resource in many natural languages with a reasonable coverage of medical terminology. In this work, we describe a major new release for GGPONC. The corpus has been substantially extended in size and re-annotated with a new annotation scheme based on SNOMED CT top level hierarchies, reaching high inter-annotator agreement (γ = .94). Moreover, we annotated elliptical coordinated noun phrases and their resolutions, a common language phenomenon in (not only German) scientiﬁc documents. We also trained BERT-based named entity recognition models on this new data set, which achieve high performance on short, coarse-grained entity spans (F1 = .89), while the rate of boundary errors increases for long entity spans. GGPONC is freely available through a data use agreement. The trained named entity recognition models, as well as the detailed annotation guide, are also made publicly available.},
	language = {en},
	author = {Borchert, Florian and Lohr, Christina and Modersohn, Luise and Witt, Jonas and Langer, Thomas and Follmann, Markus and Gietzelt, Matthias and Arnrich, Bert and Hahn, Udo and Schapranow, Matthieu-P},
	file = {Borchert et al. - GGPONC 2.0 - The German Clinical Guideline Corpus .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\LU876IVS\\Borchert et al. - GGPONC 2.0 - The German Clinical Guideline Corpus .pdf:application/pdf},
}

@article{borchert_ggponc_nodate-2,
	title = {{GGPONC} 2.0 - {The} {German} {Clinical} {Guideline} {Corpus} for {Oncology}: {Curation} {Workflow}, {Annotation} {Policy}, {Baseline} {NER} {Taggers}},
	abstract = {Despite remarkable advances in the development of language resources over the recent years, there is still a shortage of annotated, publicly available corpora covering (German) medical language. With the initial release of the German Guideline Program in Oncology NLP Corpus (GGPONC), we have demonstrated how such corpora can be built upon clinical guidelines, a widely available resource in many natural languages with a reasonable coverage of medical terminology. In this work, we describe a major new release for GGPONC. The corpus has been substantially extended in size and re-annotated with a new annotation scheme based on SNOMED CT top level hierarchies, reaching high inter-annotator agreement (γ = .94). Moreover, we annotated elliptical coordinated noun phrases and their resolutions, a common language phenomenon in (not only German) scientiﬁc documents. We also trained BERT-based named entity recognition models on this new data set, which achieve high performance on short, coarse-grained entity spans (F1 = .89), while the rate of boundary errors increases for long entity spans. GGPONC is freely available through a data use agreement. The trained named entity recognition models, as well as the detailed annotation guide, are also made publicly available.},
	language = {en},
	author = {Borchert, Florian and Lohr, Christina and Modersohn, Luise and Witt, Jonas and Langer, Thomas and Follmann, Markus and Gietzelt, Matthias and Arnrich, Bert and Hahn, Udo and Schapranow, Matthieu-P},
	file = {Borchert et al. - GGPONC 2.0 - The German Clinical Guideline Corpus .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\ICSZZX9R\\Borchert et al. - GGPONC 2.0 - The German Clinical Guideline Corpus .pdf:application/pdf},
}

@misc{noauthor_opus_nodate,
	title = {{OPUS} - {Corpora}},
	url = {https://opus.nlpl.eu/},
	urldate = {2024-02-12},
	file = {OPUS - Corpora:C\:\\Users\\bar35643\\Zotero\\storage\\EJ5LPG9G\\opus.nlpl.eu.html:text/html},
}

@inproceedings{papineni_bleu_2001,
	address = {Philadelphia, Pennsylvania},
	title = {{BLEU}: a method for automatic evaluation of machine translation},
	shorttitle = {{BLEU}},
	url = {http://portal.acm.org/citation.cfm?doid=1073083.1073135},
	doi = {10.3115/1073083.1073135},
	language = {en},
	urldate = {2024-02-15},
	booktitle = {Proceedings of the 40th {Annual} {Meeting} on {Association} for {Computational} {Linguistics}  - {ACL} '02},
	publisher = {Association for Computational Linguistics},
	author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	year = {2001},
	pages = {311},
	file = {Papineni et al. - 2001 - BLEU a method for automatic evaluation of machine.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\98IZZB6P\\Papineni et al. - 2001 - BLEU a method for automatic evaluation of machine.pdf:application/pdf},
}

@misc{noauthor_rechtsprechung_nodate,
	title = {Rechtsprechung im {Internet}},
	url = {https://www.rechtsprechung-im-internet.de/jportal/portal/page/bsjrsprod.psml},
	urldate = {2024-02-15},
	file = {Rechtsprechung im Internet:C\:\\Users\\bar35643\\Zotero\\storage\\8QBYE46Q\\bsjrsprod.html:text/html},
}

@misc{ott_fairseq_2019,
	title = {fairseq: {A} {Fast}, {Extensible} {Toolkit} for {Sequence} {Modeling}},
	shorttitle = {fairseq},
	url = {http://arxiv.org/abs/1904.01038},
	abstract = {FAIRSEQ is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found here: https://www.youtube. com/watch?v=OtgDdWtHvto.},
	language = {en},
	urldate = {2024-02-15},
	publisher = {arXiv},
	author = {Ott, Myle and Edunov, Sergey and Baevski, Alexei and Fan, Angela and Gross, Sam and Ng, Nathan and Grangier, David and Auli, Michael},
	month = apr,
	year = {2019},
	note = {arXiv:1904.01038 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: NAACL 2019 Demo paper},
	file = {Ott et al. - 2019 - fairseq A Fast, Extensible Toolkit for Sequence M.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\4ZV4ICU3\\Ott et al. - 2019 - fairseq A Fast, Extensible Toolkit for Sequence M.pdf:application/pdf},
}

@article{sutton_introduction_2012,
	title = {An {Introduction} to {Conditional} {Random} {Fields}},
	volume = {4},
	issn = {1935-8237, 1935-8245},
	url = {http://www.nowpublishers.com/article/Details/MAL-013},
	doi = {10.1561/2200000013},
	abstract = {Many tasks involve predicting a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classiﬁcation and graphical modeling. They combine the ability of graphical models to compactly model multivariate data with the ability of classiﬁcation methods to perform prediction using large sets of input features. This survey describes conditional random ﬁelds, a popular probabilistic method for structured prediction. CRFs have seen wide application in many areas, including natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large-scale CRFs. We do not assume previous knowledge of graphical modeling, so this survey is intended to be useful to practitioners in a wide variety of ﬁelds.},
	language = {en},
	number = {4},
	urldate = {2024-02-15},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Sutton, Charles},
	year = {2012},
	pages = {267--373},
	file = {Sutton - 2012 - An Introduction to Conditional Random Fields.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\V9LWBFW8\\Sutton - 2012 - An Introduction to Conditional Random Fields.pdf:application/pdf},
}

@article{zhang_bidirectional_nodate,
	title = {Bidirectional {Long} {Short}-{Term} {Memory} {Networks} for {Relation} {Classification}},
	abstract = {Relation classification is an important semantic processing, which has achieved great attention in recent years. The main challenge is the fact that important information can appear at any position in the sentence. Therefore, we propose bidirectional long short-term memory networks (BLSTM) to model the sentence with complete, sequential information about all words. At the same time, we also use features derived from the lexical resources such as WordNet or NLP systems such as dependency parser and named entity recognizers (NER). The experimental results on SemEval-2010 show that BLSTMbased method only with word embeddings as input features is sufficient to achieve state-of-the-art performance, and importing more features could further improve the performance.},
	language = {en},
	author = {Zhang, Shu and Zheng, Dequan and Hu, Xinchen and Yang, Ming},
	file = {Zhang et al. - Bidirectional Long Short-Term Memory Networks for .pdf:C\:\\Users\\bar35643\\Zotero\\storage\\ZPFWDL8Q\\Zhang et al. - Bidirectional Long Short-Term Memory Networks for .pdf:application/pdf},
}

@misc{garbacea_why_2022,
	title = {Why is constrained neural language generation particularly challenging?},
	url = {http://arxiv.org/abs/2206.05395},
	abstract = {Recent advances in deep neural language models combined with the capacity of large scale datasets have accelerated the development of natural language generation systems that produce ﬂuent and coherent texts (to various degrees of success) in a multitude of tasks and application contexts. However, controlling the output of these models for desired user and task needs is still an open challenge. This is crucial not only to customizing the content and style of the generated language, but also to their safe and reliable deployment in the real world. We present an extensive survey on the emerging topic of constrained neural language generation in which we formally deﬁne and categorize the problems of natural language generation by distinguishing between conditions and constraints (the latter being testable conditions on the output text instead of the input), present constrained text generation tasks, and review existing methods and evaluation metrics for constrained text generation. Our aim is to highlight recent progress and trends in this emerging ﬁeld, informing on the most promising directions and limitations towards advancing the state-of-the-art of constrained neural language generation research.},
	language = {en},
	urldate = {2024-02-15},
	publisher = {arXiv},
	author = {Garbacea, Cristina and Mei, Qiaozhu},
	month = jun,
	year = {2022},
	note = {arXiv:2206.05395 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: This survey is specifically focused on constrained neural language generation. For a more general survey of NLG literature, please see "Neural language generation: Formulation, methods, and evaluation" at arXiv:2007.15780},
	file = {Garbacea und Mei - 2022 - Why is constrained neural language generation part.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\EVSGE882\\Garbacea und Mei - 2022 - Why is constrained neural language generation part.pdf:application/pdf},
}

@misc{noauthor_leolmleo-hessianai-7b_2024,
	title = {{LeoLM}/leo-hessianai-7b · {Hugging} {Face}},
	url = {https://huggingface.co/LeoLM/leo-hessianai-7b},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	month = jan,
	year = {2024},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\P29FY54B\\leo-hessianai-7b.html:text/html},
}

@misc{noauthor_hugging_2024-1,
	title = {Hugging {Face} – {The} {AI} community building the future.},
	url = {https://huggingface.co/},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	month = feb,
	year = {2024},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\G4FVXCPM\\huggingface.co.html:text/html},
}

@misc{noauthor_dbmdzbert-base-german-uncased_nodate,
	title = {dbmdz/bert-base-german-uncased · {Hugging} {Face}},
	url = {https://huggingface.co/dbmdz/bert-base-german-uncased},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\28UMFXJR\\bert-base-german-uncased.html:text/html},
}

@misc{noauthor_german_nodate,
	title = {German {BERT} {\textbar} {State} of the {Art} {Language} {Model} for {German} {NLP}},
	url = {https://www.deepset.ai/german-bert},
	abstract = {deepset's original German BERT natural language processing model published in 2019 that significantly outperformed Google's multilingual BERT for German language.},
	language = {en},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\AQCH3AW2\\german-bert.html:text/html},
}

@misc{noauthor_dbmdzgerman-gpt2_nodate,
	title = {dbmdz/german-gpt2 · {Hugging} {Face}},
	url = {https://huggingface.co/dbmdz/german-gpt2},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\Q5F97Y37\\german-gpt2.html:text/html},
}

@misc{noauthor_dbmdz_2024,
	title = {dbmdz ({Bayerische} {Staatsbibliothek})},
	url = {https://huggingface.co/dbmdz},
	abstract = {Named Entity Recognition, PoS tagging, LM pre-training},
	urldate = {2024-02-15},
	month = feb,
	year = {2024},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\THT7FVUJ\\dbmdz.html:text/html},
}

@misc{noauthor_uklfrgottbert-base_nodate,
	title = {uklfr/gottbert-base · {Hugging} {Face}},
	url = {https://huggingface.co/uklfr/gottbert-base},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\6FJ9DBPH\\gottbert-base.html:text/html},
}

@misc{noauthor_helsinki-nlpopus-mt--en_nodate,
	title = {Helsinki-{NLP}/opus-mt-de-en · {Hugging} {Face}},
	url = {https://huggingface.co/Helsinki-NLP/opus-mt-de-en},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\9L24FLZW\\opus-mt-de-en.html:text/html},
}

@misc{noauthor_facebookaixlm-roberta-base_nodate,
	title = {{FacebookAI}/xlm-roberta-base · {Hugging} {Face}},
	url = {https://huggingface.co/FacebookAI/xlm-roberta-base},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\RXXZQYPG\\xlm-roberta-base.html:text/html},
}

@misc{noauthor_openaiwhisper-large-v3_nodate,
	title = {openai/whisper-large-v3 · {Hugging} {Face}},
	url = {https://huggingface.co/openai/whisper-large-v3},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
}

@misc{noauthor_mistralaimixtral-8x7b-instruct-v01_nodate,
	title = {mistralai/{Mixtral}-{8x7B}-{Instruct}-v0.1 · {Hugging} {Face}},
	url = {https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\RHUSYMVH\\Mixtral-8x7B-Instruct-v0.html:text/html},
}

@misc{noauthor_mistralai_nodate,
	title = {mistralai ({Mistral} {AI}\_)},
	url = {https://huggingface.co/mistralai},
	urldate = {2024-02-15},
	file = {mistralai (Mistral AI_):C\:\\Users\\bar35643\\Zotero\\storage\\J98WXVZI\\mistralai.html:text/html},
}

@misc{noauthor_smanjilgerman-medbert_nodate,
	title = {smanjil/{German}-{MedBERT} · {Hugging} {Face}},
	url = {https://huggingface.co/smanjil/German-MedBERT},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\Y2BBXTZK\\German-MedBERT.html:text/html},
}

@misc{noauthor_tanhimgpt2-model-_nodate,
	title = {Tanhim/gpt2-model-de · {Hugging} {Face}},
	url = {https://huggingface.co/Tanhim/gpt2-model-de},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\T78H82KT\\gpt2-model-de.html:text/html},
}

@misc{noauthor_tum-nlpgerman-gpt2_easy_nodate,
	title = {tum-nlp/german-gpt2\_easy · {Hugging} {Face}},
	url = {https://huggingface.co/tum-nlp/german-gpt2_easy},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\8JX6YCTD\\german-gpt2_easy.html:text/html},
}

@misc{noauthor_jphmellama-2-13b-chat-german_2021,
	title = {jphme/{Llama}-2-13b-chat-german · {Hugging} {Face}},
	url = {https://huggingface.co/jphme/Llama-2-13b-chat-german},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-02-15},
	month = oct,
	year = {2021},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\3IRVHM2V\\Llama-2-13b-chat-german.html:text/html},
}

@misc{noauthor_general_nodate,
	title = {General {Data} {Protection} {Regulation} ({GDPR}) – {Official} {Legal} {Text}},
	url = {https://gdpr-info.eu/},
	abstract = {General Data Protection Regulation (EU GDPR) – The official PDF of the Regulation (EU) 2016/679, its recitals \& key issues as a neatly arranged website.},
	language = {en-US},
	urldate = {2024-02-16},
	journal = {General Data Protection Regulation (GDPR)},
	file = {Snapshot:C\:\\Users\\bar35643\\Zotero\\storage\\L6I6AG39\\gdpr-info.eu.html:text/html},
}

@article{turing_computing_1950,
	title = {Computing {Machinery} and {Intelligence}},
	volume = {59},
	url = {http://www.jstor.org/stable/2251299},
	number = {236},
	journal = {Mind, New Series},
	author = {Turing, A. M.},
	year = {1950},
	pages = {433--460},
	file = {Turing - 1950 - Computing Machinery and Intelligence.pdf:C\:\\Users\\bar35643\\Zotero\\storage\\KAXMGCJA\\Turing - 1950 - Computing Machinery and Intelligence.pdf:application/pdf},
}
